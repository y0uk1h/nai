function e(e,t,n,r){Object.defineProperty(e,t,{get:n,set:r,enumerable:!0,configurable:!0})}function t(e,t){return Object.keys(t).forEach(function(n){"default"===n||"__esModule"===n||Object.prototype.hasOwnProperty.call(e,n)||Object.defineProperty(e,n,{enumerable:!0,get:function(){return t[n]}})}),e}var n,r,a,i,o,s,l,u=globalThis,c={},d={},p=u.parcelRequire94c2;null==p&&((p=function(e){if(e in c)return c[e].exports;if(e in d){var t=d[e];delete d[e];var n={id:e,exports:{}};return c[e]=n,t.call(n.exports,n,n.exports),n.exports}var r=Error("Cannot find module '"+e+"'");throw r.code="MODULE_NOT_FOUND",r}).register=function(e,t){d[e]=t},u.parcelRequire94c2=p);var f=p.register;f("59OBb",function(t,n){e(t.exports,"Fragment",()=>r,e=>r=e),e(t.exports,"jsx",()=>a,e=>a=e),e(t.exports,"jsxs",()=>i,e=>i=e);var r,a,i,o=Symbol.for("react.transitional.element");function s(e,t,n){var r=null;if(void 0!==n&&(r=""+n),void 0!==t.key&&(r=""+t.key),"key"in t)for(var a in n={},t)"key"!==a&&(n[a]=t[a]);else n=t;return{$$typeof:o,type:e,key:r,ref:void 0!==(t=n.ref)?t:null,props:n}}r=Symbol.for("react.fragment"),a=s,i=s}),f("lanIS",function(t,n){e(t.exports,"Children",()=>r,e=>r=e),e(t.exports,"Component",()=>a,e=>a=e),e(t.exports,"Fragment",()=>i,e=>i=e),e(t.exports,"Profiler",()=>o,e=>o=e),e(t.exports,"PureComponent",()=>s,e=>s=e),e(t.exports,"StrictMode",()=>l,e=>l=e),e(t.exports,"Suspense",()=>u,e=>u=e),e(t.exports,"__CLIENT_INTERNALS_DO_NOT_USE_OR_WARN_USERS_THEY_CANNOT_UPGRADE",()=>c,e=>c=e),e(t.exports,"__COMPILER_RUNTIME",()=>d,e=>d=e),e(t.exports,"cache",()=>p,e=>p=e),e(t.exports,"cloneElement",()=>f,e=>f=e),e(t.exports,"createContext",()=>m,e=>m=e),e(t.exports,"createElement",()=>h,e=>h=e),e(t.exports,"createRef",()=>g,e=>g=e),e(t.exports,"forwardRef",()=>y,e=>y=e),e(t.exports,"isValidElement",()=>b,e=>b=e),e(t.exports,"lazy",()=>v,e=>v=e),e(t.exports,"memo",()=>w,e=>w=e),e(t.exports,"startTransition",()=>_,e=>_=e),e(t.exports,"unstable_useCacheRefresh",()=>k,e=>k=e),e(t.exports,"use",()=>x,e=>x=e),e(t.exports,"useActionState",()=>S,e=>S=e),e(t.exports,"useCallback",()=>A,e=>A=e),e(t.exports,"useContext",()=>T,e=>T=e),e(t.exports,"useDebugValue",()=>E,e=>E=e),e(t.exports,"useDeferredValue",()=>I,e=>I=e),e(t.exports,"useEffect",()=>C,e=>C=e),e(t.exports,"useId",()=>P,e=>P=e),e(t.exports,"useImperativeHandle",()=>L,e=>L=e),e(t.exports,"useInsertionEffect",()=>R,e=>R=e),e(t.exports,"useLayoutEffect",()=>M,e=>M=e),e(t.exports,"useMemo",()=>N,e=>N=e),e(t.exports,"useOptimistic",()=>U,e=>U=e),e(t.exports,"useReducer",()=>O,e=>O=e),e(t.exports,"useRef",()=>$,e=>$=e),e(t.exports,"useState",()=>j,e=>j=e),e(t.exports,"useSyncExternalStore",()=>D,e=>D=e),e(t.exports,"useTransition",()=>z,e=>z=e),e(t.exports,"version",()=>F,e=>F=e);var r,a,i,o,s,l,u,c,d,p,f,m,h,g,y,b,v,w,_,k,x,S,A,T,E,I,C,P,L,R,M,N,U,O,$,j,D,z,F,B=Symbol.for("react.transitional.element"),q=Symbol.for("react.portal"),V=Symbol.for("react.fragment"),H=Symbol.for("react.strict_mode"),Q=Symbol.for("react.profiler"),W=Symbol.for("react.consumer"),G=Symbol.for("react.context"),K=Symbol.for("react.forward_ref"),X=Symbol.for("react.suspense"),Y=Symbol.for("react.memo"),J=Symbol.for("react.lazy"),Z=Symbol.iterator,ee={isMounted:function(){return!1},enqueueForceUpdate:function(){},enqueueReplaceState:function(){},enqueueSetState:function(){}},et=Object.assign,en={};function er(e,t,n){this.props=e,this.context=t,this.refs=en,this.updater=n||ee}function ea(){}function ei(e,t,n){this.props=e,this.context=t,this.refs=en,this.updater=n||ee}er.prototype.isReactComponent={},er.prototype.setState=function(e,t){if("object"!=typeof e&&"function"!=typeof e&&null!=e)throw Error("takes an object of state variables to update or a function which returns an object of state variables.");this.updater.enqueueSetState(this,e,t,"setState")},er.prototype.forceUpdate=function(e){this.updater.enqueueForceUpdate(this,e,"forceUpdate")},ea.prototype=er.prototype;var eo=ei.prototype=new ea;eo.constructor=ei,et(eo,er.prototype),eo.isPureReactComponent=!0;var es=Array.isArray,el={H:null,A:null,T:null,S:null,V:null},eu=Object.prototype.hasOwnProperty;function ec(e,t,n,r,a,i){return{$$typeof:B,type:e,key:t,ref:void 0!==(n=i.ref)?n:null,props:i}}function ed(e){return"object"==typeof e&&null!==e&&e.$$typeof===B}var ep=/\/+/g;function ef(e,t){var n,r;return"object"==typeof e&&null!==e&&null!=e.key?(n=""+e.key,r={"=":"=0",":":"=2"},"$"+n.replace(/[=:]/g,function(e){return r[e]})):t.toString(36)}function em(){}function eh(e,t,n){if(null==e)return e;var r=[],a=0;return!function e(t,n,r,a,i){var o,s,l,u=typeof t;("undefined"===u||"boolean"===u)&&(t=null);var c=!1;if(null===t)c=!0;else switch(u){case"bigint":case"string":case"number":c=!0;break;case"object":switch(t.$$typeof){case B:case q:c=!0;break;case J:return e((c=t._init)(t._payload),n,r,a,i)}}if(c)return i=i(t),c=""===a?"."+ef(t,0):a,es(i)?(r="",null!=c&&(r=c.replace(ep,"$&/")+"/"),e(i,n,r,"",function(e){return e})):null!=i&&(ed(i)&&(o=i,s=r+(null==i.key||t&&t.key===i.key?"":(""+i.key).replace(ep,"$&/")+"/")+c,i=ec(o.type,s,void 0,void 0,void 0,o.props)),n.push(i)),1;c=0;var d=""===a?".":a+":";if(es(t))for(var p=0;p<t.length;p++)u=d+ef(a=t[p],p),c+=e(a,n,r,u,i);else if("function"==typeof(p=null===(l=t)||"object"!=typeof l?null:"function"==typeof(l=Z&&l[Z]||l["@@iterator"])?l:null))for(t=p.call(t),p=0;!(a=t.next()).done;)u=d+ef(a=a.value,p++),c+=e(a,n,r,u,i);else if("object"===u){if("function"==typeof t.then)return e(function(e){switch(e.status){case"fulfilled":return e.value;case"rejected":throw e.reason;default:switch("string"==typeof e.status?e.then(em,em):(e.status="pending",e.then(function(t){"pending"===e.status&&(e.status="fulfilled",e.value=t)},function(t){"pending"===e.status&&(e.status="rejected",e.reason=t)})),e.status){case"fulfilled":return e.value;case"rejected":throw e.reason}}throw e}(t),n,r,a,i);throw Error("Objects are not valid as a React child (found: "+("[object Object]"===(n=String(t))?"object with keys {"+Object.keys(t).join(", ")+"}":n)+"). If you meant to render a collection of children, use an array instead.")}return c}(e,r,"","",function(e){return t.call(n,e,a++)}),r}function eg(e){if(-1===e._status){var t=e._result;(t=t()).then(function(t){(0===e._status||-1===e._status)&&(e._status=1,e._result=t)},function(t){(0===e._status||-1===e._status)&&(e._status=2,e._result=t)}),-1===e._status&&(e._status=0,e._result=t)}if(1===e._status)return e._result.default;throw e._result}var ey="function"==typeof reportError?reportError:function(e){if("object"==typeof window&&"function"==typeof window.ErrorEvent){var t=new window.ErrorEvent("error",{bubbles:!0,cancelable:!0,message:"object"==typeof e&&null!==e&&"string"==typeof e.message?String(e.message):String(e),error:e});if(!window.dispatchEvent(t))return}console.error(e)};function eb(){}r={map:eh,forEach:function(e,t,n){eh(e,function(){t.apply(this,arguments)},n)},count:function(e){var t=0;return eh(e,function(){t++}),t},toArray:function(e){return eh(e,function(e){return e})||[]},only:function(e){if(!ed(e))throw Error("React.Children.only expected to receive a single React element child.");return e}},a=er,i=V,o=Q,s=ei,l=H,u=X,c=el,d={__proto__:null,c:function(e){return el.H.useMemoCache(e)}},p=function(e){return function(){return e.apply(null,arguments)}},f=function(e,t,n){if(null==e)throw Error("The argument must be a React element, but you passed "+e+".");var r=et({},e.props),a=e.key,i=void 0;if(null!=t)for(o in void 0!==t.ref&&(i=void 0),void 0!==t.key&&(a=""+t.key),t)eu.call(t,o)&&"key"!==o&&"__self"!==o&&"__source"!==o&&("ref"!==o||void 0!==t.ref)&&(r[o]=t[o]);var o=arguments.length-2;if(1===o)r.children=n;else if(1<o){for(var s=Array(o),l=0;l<o;l++)s[l]=arguments[l+2];r.children=s}return ec(e.type,a,void 0,void 0,i,r)},m=function(e){return(e={$$typeof:G,_currentValue:e,_currentValue2:e,_threadCount:0,Provider:null,Consumer:null}).Provider=e,e.Consumer={$$typeof:W,_context:e},e},h=function(e,t,n){var r,a={},i=null;if(null!=t)for(r in void 0!==t.key&&(i=""+t.key),t)eu.call(t,r)&&"key"!==r&&"__self"!==r&&"__source"!==r&&(a[r]=t[r]);var o=arguments.length-2;if(1===o)a.children=n;else if(1<o){for(var s=Array(o),l=0;l<o;l++)s[l]=arguments[l+2];a.children=s}if(e&&e.defaultProps)for(r in o=e.defaultProps)void 0===a[r]&&(a[r]=o[r]);return ec(e,i,void 0,void 0,null,a)},g=function(){return{current:null}},y=function(e){return{$$typeof:K,render:e}},b=ed,v=function(e){return{$$typeof:J,_payload:{_status:-1,_result:e},_init:eg}},w=function(e,t){return{$$typeof:Y,type:e,compare:void 0===t?null:t}},_=function(e){var t=el.T,n={};el.T=n;try{var r=e(),a=el.S;null!==a&&a(n,r),"object"==typeof r&&null!==r&&"function"==typeof r.then&&r.then(eb,ey)}catch(e){ey(e)}finally{el.T=t}},k=function(){return el.H.useCacheRefresh()},x=function(e){return el.H.use(e)},S=function(e,t,n){return el.H.useActionState(e,t,n)},A=function(e,t){return el.H.useCallback(e,t)},T=function(e){return el.H.useContext(e)},E=function(){},I=function(e,t){return el.H.useDeferredValue(e,t)},C=function(e,t,n){var r=el.H;if("function"==typeof n)throw Error("useEffect CRUD overload is not enabled in this build of React.");return r.useEffect(e,t)},P=function(){return el.H.useId()},L=function(e,t,n){return el.H.useImperativeHandle(e,t,n)},R=function(e,t){return el.H.useInsertionEffect(e,t)},M=function(e,t){return el.H.useLayoutEffect(e,t)},N=function(e,t){return el.H.useMemo(e,t)},U=function(e,t){return el.H.useOptimistic(e,t)},O=function(e,t,n){return el.H.useReducer(e,t,n)},$=function(e){return el.H.useRef(e)},j=function(e){return el.H.useState(e)},D=function(e,t,n){return el.H.useSyncExternalStore(e,t,n)},z=function(){return el.H.useTransition()},F="19.1.1"}),f("bgXWC",function(t,n){e(t.exports,"createRoot",()=>tU,e=>tU=e),e(t.exports,"hydrateRoot",()=>tO,e=>tO=e),e(t.exports,"version",()=>t$,e=>t$=e);var r,a=p("6qr1r"),i=p("fYo6y"),o=p("d2L2u");function s(e){var t="https://react.dev/errors/"+e;if(1<arguments.length){t+="?args[]="+encodeURIComponent(arguments[1]);for(var n=2;n<arguments.length;n++)t+="&args[]="+encodeURIComponent(arguments[n])}return"Minified React error #"+e+"; visit "+t+" for the full message or use the non-minified dev environment for full errors and additional helpful warnings."}function l(e){return!(!e||1!==e.nodeType&&9!==e.nodeType&&11!==e.nodeType)}function u(e){var t=e,n=e;if(e.alternate)for(;t.return;)t=t.return;else{e=t;do 0!=(4098&(t=e).flags)&&(n=t.return),e=t.return;while(e)}return 3===t.tag?n:null}function c(e){if(13===e.tag){var t=e.memoizedState;if(null===t&&null!==(e=e.alternate)&&(t=e.memoizedState),null!==t)return t.dehydrated}return null}function d(e){if(u(e)!==e)throw Error(s(188))}var f=Object.assign,m=Symbol.for("react.element"),h=Symbol.for("react.transitional.element"),g=Symbol.for("react.portal"),y=Symbol.for("react.fragment"),b=Symbol.for("react.strict_mode"),v=Symbol.for("react.profiler"),w=Symbol.for("react.provider"),_=Symbol.for("react.consumer"),k=Symbol.for("react.context"),x=Symbol.for("react.forward_ref"),S=Symbol.for("react.suspense"),A=Symbol.for("react.suspense_list"),T=Symbol.for("react.memo"),E=Symbol.for("react.lazy");Symbol.for("react.scope");var I=Symbol.for("react.activity");Symbol.for("react.legacy_hidden"),Symbol.for("react.tracing_marker");var C=Symbol.for("react.memo_cache_sentinel");Symbol.for("react.view_transition");var P=Symbol.iterator;function L(e){return null===e||"object"!=typeof e?null:"function"==typeof(e=P&&e[P]||e["@@iterator"])?e:null}var R=Symbol.for("react.client.reference"),M=Array.isArray,N=i.__CLIENT_INTERNALS_DO_NOT_USE_OR_WARN_USERS_THEY_CANNOT_UPGRADE,U=o.__DOM_INTERNALS_DO_NOT_USE_OR_WARN_USERS_THEY_CANNOT_UPGRADE,O={pending:!1,data:null,method:null,action:null},$=[],j=-1;function D(e){return{current:e}}function z(e){0>j||(e.current=$[j],$[j]=null,j--)}function F(e,t){$[++j]=e.current,e.current=t}var B=D(null),q=D(null),V=D(null),H=D(null);function Q(e,t){switch(F(V,t),F(q,e),F(B,null),t.nodeType){case 9:case 11:e=(e=t.documentElement)&&(e=e.namespaceURI)?uc(e):0;break;default:if(e=t.tagName,t=t.namespaceURI)e=ud(t=uc(t),e);else switch(e){case"svg":e=1;break;case"math":e=2;break;default:e=0}}z(B),F(B,e)}function W(){z(B),z(q),z(V)}function G(e){null!==e.memoizedState&&F(H,e);var t=B.current,n=ud(t,e.type);t!==n&&(F(q,e),F(B,n))}function K(e){q.current===e&&(z(B),z(q)),H.current===e&&(z(H),u0._currentValue=O)}var X=Object.prototype.hasOwnProperty,Y=a.unstable_scheduleCallback,J=a.unstable_cancelCallback,Z=a.unstable_shouldYield,ee=a.unstable_requestPaint,et=a.unstable_now,en=a.unstable_getCurrentPriorityLevel,er=a.unstable_ImmediatePriority,ea=a.unstable_UserBlockingPriority,ei=a.unstable_NormalPriority,eo=a.unstable_LowPriority,es=a.unstable_IdlePriority,el=a.log,eu=a.unstable_setDisableYieldValue,ec=null,ed=null;function ep(e){if("function"==typeof el&&eu(e),ed&&"function"==typeof ed.setStrictMode)try{ed.setStrictMode(ec,e)}catch(e){}}var ef=Math.clz32?Math.clz32:function(e){return 0==(e>>>=0)?32:31-(em(e)/eh|0)|0},em=Math.log,eh=Math.LN2,eg=256,ey=4194304;function eb(e){var t=42&e;if(0!==t)return t;switch(e&-e){case 1:return 1;case 2:return 2;case 4:return 4;case 8:return 8;case 16:return 16;case 32:return 32;case 64:return 64;case 128:return 128;case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:return 4194048&e;case 4194304:case 8388608:case 0x1000000:case 0x2000000:return 0x3c00000&e;case 0x4000000:return 0x4000000;case 0x8000000:return 0x8000000;case 0x10000000:return 0x10000000;case 0x20000000:return 0x20000000;case 0x40000000:return 0;default:return e}}function ev(e,t,n){var r=e.pendingLanes;if(0===r)return 0;var a=0,i=e.suspendedLanes,o=e.pingedLanes;e=e.warmLanes;var s=0x7ffffff&r;return 0!==s?0!=(r=s&~i)?a=eb(r):0!=(o&=s)?a=eb(o):n||0!=(n=s&~e)&&(a=eb(n)):0!=(s=r&~i)?a=eb(s):0!==o?a=eb(o):n||0!=(n=r&~e)&&(a=eb(n)),0===a?0:0!==t&&t!==a&&0==(t&i)&&((i=a&-a)>=(n=t&-t)||32===i&&0!=(4194048&n))?t:a}function ew(e,t){return 0==(e.pendingLanes&~(e.suspendedLanes&~e.pingedLanes)&t)}function e_(){var e=eg;return 0==(4194048&(eg<<=1))&&(eg=256),e}function ek(){var e=ey;return 0==(0x3c00000&(ey<<=1))&&(ey=4194304),e}function ex(e){for(var t=[],n=0;31>n;n++)t.push(e);return t}function eS(e,t){e.pendingLanes|=t,0x10000000!==t&&(e.suspendedLanes=0,e.pingedLanes=0,e.warmLanes=0)}function eA(e,t,n){e.pendingLanes|=t,e.suspendedLanes&=~t;var r=31-ef(t);e.entangledLanes|=t,e.entanglements[r]=0x40000000|e.entanglements[r]|4194090&n}function eT(e,t){var n=e.entangledLanes|=t;for(e=e.entanglements;n;){var r=31-ef(n),a=1<<r;a&t|e[r]&t&&(e[r]|=t),n&=~a}}function eE(e){switch(e){case 2:e=1;break;case 8:e=4;break;case 32:e=16;break;case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:case 4194304:case 8388608:case 0x1000000:case 0x2000000:e=128;break;case 0x10000000:e=0x8000000;break;default:e=0}return e}function eI(e){return 2<(e&=-e)?8<e?0!=(0x7ffffff&e)?32:0x10000000:8:2}function eC(){var e=U.p;return 0!==e?e:void 0===(e=window.event)?32:ca(e.type)}var eP=Math.random().toString(36).slice(2),eL="__reactFiber$"+eP,eR="__reactProps$"+eP,eM="__reactContainer$"+eP,eN="__reactEvents$"+eP,eU="__reactListeners$"+eP,eO="__reactHandles$"+eP,e$="__reactResources$"+eP,ej="__reactMarker$"+eP;function eD(e){delete e[eL],delete e[eR],delete e[eN],delete e[eU],delete e[eO]}function ez(e){var t=e[eL];if(t)return t;for(var n=e.parentNode;n;){if(t=n[eM]||n[eL]){if(n=t.alternate,null!==t.child||null!==n&&null!==n.child)for(e=uA(e);null!==e;){if(n=e[eL])return n;e=uA(e)}return t}n=(e=n).parentNode}return null}function eF(e){if(e=e[eL]||e[eM]){var t=e.tag;if(5===t||6===t||13===t||26===t||27===t||3===t)return e}return null}function eB(e){var t=e.tag;if(5===t||26===t||27===t||6===t)return e.stateNode;throw Error(s(33))}function eq(e){var t=e[e$];return t||(t=e[e$]={hoistableStyles:new Map,hoistableScripts:new Map}),t}function eV(e){e[ej]=!0}var eH=new Set,eQ={};function eW(e,t){eG(e,t),eG(e+"Capture",t)}function eG(e,t){for(eQ[e]=t,e=0;e<t.length;e++)eH.add(t[e])}var eK=RegExp("^[:A-Z_a-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][:A-Z_a-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$"),eX={},eY={};function eJ(e,t,n){if(X.call(eY,t)||!X.call(eX,t)&&(eK.test(t)?eY[t]=!0:(eX[t]=!0,!1)))if(null===n)e.removeAttribute(t);else{switch(typeof n){case"undefined":case"function":case"symbol":e.removeAttribute(t);return;case"boolean":var r=t.toLowerCase().slice(0,5);if("data-"!==r&&"aria-"!==r)return void e.removeAttribute(t)}e.setAttribute(t,""+n)}}function eZ(e,t,n){if(null===n)e.removeAttribute(t);else{switch(typeof n){case"undefined":case"function":case"symbol":case"boolean":e.removeAttribute(t);return}e.setAttribute(t,""+n)}}function e0(e,t,n,r){if(null===r)e.removeAttribute(n);else{switch(typeof r){case"undefined":case"function":case"symbol":case"boolean":e.removeAttribute(n);return}e.setAttributeNS(t,n,""+r)}}function e1(e){if(void 0===tj)try{throw Error()}catch(e){var t=e.stack.trim().match(/\n( *(at )?)/);tj=t&&t[1]||"",tD=-1<e.stack.indexOf("\n    at")?" (<anonymous>)":-1<e.stack.indexOf("@")?"@unknown:0:0":""}return"\n"+tj+e+tD}var e2=!1;function e3(e,t){if(!e||e2)return"";e2=!0;var n=Error.prepareStackTrace;Error.prepareStackTrace=void 0;try{var r={DetermineComponentFrameRoot:function(){try{if(t){var n=function(){throw Error()};if(Object.defineProperty(n.prototype,"props",{set:function(){throw Error()}}),"object"==typeof Reflect&&Reflect.construct){try{Reflect.construct(n,[])}catch(e){var r=e}Reflect.construct(e,[],n)}else{try{n.call()}catch(e){r=e}e.call(n.prototype)}}else{try{throw Error()}catch(e){r=e}(n=e())&&"function"==typeof n.catch&&n.catch(function(){})}}catch(e){if(e&&r&&"string"==typeof e.stack)return[e.stack,r.stack]}return[null,null]}};r.DetermineComponentFrameRoot.displayName="DetermineComponentFrameRoot";var a=Object.getOwnPropertyDescriptor(r.DetermineComponentFrameRoot,"name");a&&a.configurable&&Object.defineProperty(r.DetermineComponentFrameRoot,"name",{value:"DetermineComponentFrameRoot"});var i=r.DetermineComponentFrameRoot(),o=i[0],s=i[1];if(o&&s){var l=o.split("\n"),u=s.split("\n");for(a=r=0;r<l.length&&!l[r].includes("DetermineComponentFrameRoot");)r++;for(;a<u.length&&!u[a].includes("DetermineComponentFrameRoot");)a++;if(r===l.length||a===u.length)for(r=l.length-1,a=u.length-1;1<=r&&0<=a&&l[r]!==u[a];)a--;for(;1<=r&&0<=a;r--,a--)if(l[r]!==u[a]){if(1!==r||1!==a)do if(r--,a--,0>a||l[r]!==u[a]){var c="\n"+l[r].replace(" at new "," at ");return e.displayName&&c.includes("<anonymous>")&&(c=c.replace("<anonymous>",e.displayName)),c}while(1<=r&&0<=a)break}}}finally{e2=!1,Error.prepareStackTrace=n}return(n=e?e.displayName||e.name:"")?e1(n):""}function e4(e){try{var t="";do t+=function(e){switch(e.tag){case 26:case 27:case 5:return e1(e.type);case 16:return e1("Lazy");case 13:return e1("Suspense");case 19:return e1("SuspenseList");case 0:case 15:return e3(e.type,!1);case 11:return e3(e.type.render,!1);case 1:return e3(e.type,!0);case 31:return e1("Activity");default:return""}}(e),e=e.return;while(e)return t}catch(e){return"\nError generating stack: "+e.message+"\n"+e.stack}}function e6(e){switch(typeof e){case"bigint":case"boolean":case"number":case"string":case"undefined":case"object":return e;default:return""}}function e5(e){var t=e.type;return(e=e.nodeName)&&"input"===e.toLowerCase()&&("checkbox"===t||"radio"===t)}function e8(e){e._valueTracker||(e._valueTracker=function(e){var t=e5(e)?"checked":"value",n=Object.getOwnPropertyDescriptor(e.constructor.prototype,t),r=""+e[t];if(!e.hasOwnProperty(t)&&void 0!==n&&"function"==typeof n.get&&"function"==typeof n.set){var a=n.get,i=n.set;return Object.defineProperty(e,t,{configurable:!0,get:function(){return a.call(this)},set:function(e){r=""+e,i.call(this,e)}}),Object.defineProperty(e,t,{enumerable:n.enumerable}),{getValue:function(){return r},setValue:function(e){r=""+e},stopTracking:function(){e._valueTracker=null,delete e[t]}}}}(e))}function e9(e){if(!e)return!1;var t=e._valueTracker;if(!t)return!0;var n=t.getValue(),r="";return e&&(r=e5(e)?e.checked?"true":"false":e.value),(e=r)!==n&&(t.setValue(e),!0)}function e7(e){if(void 0===(e=e||("undefined"!=typeof document?document:void 0)))return null;try{return e.activeElement||e.body}catch(t){return e.body}}var te=/[\n"\\]/g;function tt(e){return e.replace(te,function(e){return"\\"+e.charCodeAt(0).toString(16)+" "})}function tn(e,t,n,r,a,i,o,s){e.name="",null!=o&&"function"!=typeof o&&"symbol"!=typeof o&&"boolean"!=typeof o?e.type=o:e.removeAttribute("type"),null!=t?"number"===o?(0===t&&""===e.value||e.value!=t)&&(e.value=""+e6(t)):e.value!==""+e6(t)&&(e.value=""+e6(t)):"submit"!==o&&"reset"!==o||e.removeAttribute("value"),null!=t?ta(e,o,e6(t)):null!=n?ta(e,o,e6(n)):null!=r&&e.removeAttribute("value"),null==a&&null!=i&&(e.defaultChecked=!!i),null!=a&&(e.checked=a&&"function"!=typeof a&&"symbol"!=typeof a),null!=s&&"function"!=typeof s&&"symbol"!=typeof s&&"boolean"!=typeof s?e.name=""+e6(s):e.removeAttribute("name")}function tr(e,t,n,r,a,i,o,s){if(null!=i&&"function"!=typeof i&&"symbol"!=typeof i&&"boolean"!=typeof i&&(e.type=i),null!=t||null!=n){if(("submit"===i||"reset"===i)&&null==t)return;n=null!=n?""+e6(n):"",t=null!=t?""+e6(t):n,s||t===e.value||(e.value=t),e.defaultValue=t}r="function"!=typeof(r=null!=r?r:a)&&"symbol"!=typeof r&&!!r,e.checked=s?e.checked:!!r,e.defaultChecked=!!r,null!=o&&"function"!=typeof o&&"symbol"!=typeof o&&"boolean"!=typeof o&&(e.name=o)}function ta(e,t,n){"number"===t&&e7(e.ownerDocument)===e||e.defaultValue===""+n||(e.defaultValue=""+n)}function ti(e,t,n,r){if(e=e.options,t){t={};for(var a=0;a<n.length;a++)t["$"+n[a]]=!0;for(n=0;n<e.length;n++)a=t.hasOwnProperty("$"+e[n].value),e[n].selected!==a&&(e[n].selected=a),a&&r&&(e[n].defaultSelected=!0)}else{for(a=0,n=""+e6(n),t=null;a<e.length;a++){if(e[a].value===n){e[a].selected=!0,r&&(e[a].defaultSelected=!0);return}null!==t||e[a].disabled||(t=e[a])}null!==t&&(t.selected=!0)}}function to(e,t,n){if(null!=t&&((t=""+e6(t))!==e.value&&(e.value=t),null==n)){e.defaultValue!==t&&(e.defaultValue=t);return}e.defaultValue=null!=n?""+e6(n):""}function ts(e,t,n,r){if(null==t){if(null!=r){if(null!=n)throw Error(s(92));if(M(r)){if(1<r.length)throw Error(s(93));r=r[0]}n=r}null==n&&(n=""),t=n}e.defaultValue=n=e6(t),(r=e.textContent)===n&&""!==r&&null!==r&&(e.value=r)}function tl(e,t){if(t){var n=e.firstChild;if(n&&n===e.lastChild&&3===n.nodeType){n.nodeValue=t;return}}e.textContent=t}var tu=new Set("animationIterationCount aspectRatio borderImageOutset borderImageSlice borderImageWidth boxFlex boxFlexGroup boxOrdinalGroup columnCount columns flex flexGrow flexPositive flexShrink flexNegative flexOrder gridArea gridRow gridRowEnd gridRowSpan gridRowStart gridColumn gridColumnEnd gridColumnSpan gridColumnStart fontWeight lineClamp lineHeight opacity order orphans scale tabSize widows zIndex zoom fillOpacity floodOpacity stopOpacity strokeDasharray strokeDashoffset strokeMiterlimit strokeOpacity strokeWidth MozAnimationIterationCount MozBoxFlex MozBoxFlexGroup MozLineClamp msAnimationIterationCount msFlex msZoom msFlexGrow msFlexNegative msFlexOrder msFlexPositive msFlexShrink msGridColumn msGridColumnSpan msGridRow msGridRowSpan WebkitAnimationIterationCount WebkitBoxFlex WebKitBoxFlexGroup WebkitBoxOrdinalGroup WebkitColumnCount WebkitColumns WebkitFlex WebkitFlexGrow WebkitFlexPositive WebkitFlexShrink WebkitLineClamp".split(" "));function tc(e,t,n){var r=0===t.indexOf("--");null==n||"boolean"==typeof n||""===n?r?e.setProperty(t,""):"float"===t?e.cssFloat="":e[t]="":r?e.setProperty(t,n):"number"!=typeof n||0===n||tu.has(t)?"float"===t?e.cssFloat=n:e[t]=(""+n).trim():e[t]=n+"px"}function td(e,t,n){if(null!=t&&"object"!=typeof t)throw Error(s(62));if(e=e.style,null!=n){for(var r in n)!n.hasOwnProperty(r)||null!=t&&t.hasOwnProperty(r)||(0===r.indexOf("--")?e.setProperty(r,""):"float"===r?e.cssFloat="":e[r]="");for(var a in t)r=t[a],t.hasOwnProperty(a)&&n[a]!==r&&tc(e,a,r)}else for(var i in t)t.hasOwnProperty(i)&&tc(e,i,t[i])}function tp(e){if(-1===e.indexOf("-"))return!1;switch(e){case"annotation-xml":case"color-profile":case"font-face":case"font-face-src":case"font-face-uri":case"font-face-format":case"font-face-name":case"missing-glyph":return!1;default:return!0}}var tf=new Map([["acceptCharset","accept-charset"],["htmlFor","for"],["httpEquiv","http-equiv"],["crossOrigin","crossorigin"],["accentHeight","accent-height"],["alignmentBaseline","alignment-baseline"],["arabicForm","arabic-form"],["baselineShift","baseline-shift"],["capHeight","cap-height"],["clipPath","clip-path"],["clipRule","clip-rule"],["colorInterpolation","color-interpolation"],["colorInterpolationFilters","color-interpolation-filters"],["colorProfile","color-profile"],["colorRendering","color-rendering"],["dominantBaseline","dominant-baseline"],["enableBackground","enable-background"],["fillOpacity","fill-opacity"],["fillRule","fill-rule"],["floodColor","flood-color"],["floodOpacity","flood-opacity"],["fontFamily","font-family"],["fontSize","font-size"],["fontSizeAdjust","font-size-adjust"],["fontStretch","font-stretch"],["fontStyle","font-style"],["fontVariant","font-variant"],["fontWeight","font-weight"],["glyphName","glyph-name"],["glyphOrientationHorizontal","glyph-orientation-horizontal"],["glyphOrientationVertical","glyph-orientation-vertical"],["horizAdvX","horiz-adv-x"],["horizOriginX","horiz-origin-x"],["imageRendering","image-rendering"],["letterSpacing","letter-spacing"],["lightingColor","lighting-color"],["markerEnd","marker-end"],["markerMid","marker-mid"],["markerStart","marker-start"],["overlinePosition","overline-position"],["overlineThickness","overline-thickness"],["paintOrder","paint-order"],["panose-1","panose-1"],["pointerEvents","pointer-events"],["renderingIntent","rendering-intent"],["shapeRendering","shape-rendering"],["stopColor","stop-color"],["stopOpacity","stop-opacity"],["strikethroughPosition","strikethrough-position"],["strikethroughThickness","strikethrough-thickness"],["strokeDasharray","stroke-dasharray"],["strokeDashoffset","stroke-dashoffset"],["strokeLinecap","stroke-linecap"],["strokeLinejoin","stroke-linejoin"],["strokeMiterlimit","stroke-miterlimit"],["strokeOpacity","stroke-opacity"],["strokeWidth","stroke-width"],["textAnchor","text-anchor"],["textDecoration","text-decoration"],["textRendering","text-rendering"],["transformOrigin","transform-origin"],["underlinePosition","underline-position"],["underlineThickness","underline-thickness"],["unicodeBidi","unicode-bidi"],["unicodeRange","unicode-range"],["unitsPerEm","units-per-em"],["vAlphabetic","v-alphabetic"],["vHanging","v-hanging"],["vIdeographic","v-ideographic"],["vMathematical","v-mathematical"],["vectorEffect","vector-effect"],["vertAdvY","vert-adv-y"],["vertOriginX","vert-origin-x"],["vertOriginY","vert-origin-y"],["wordSpacing","word-spacing"],["writingMode","writing-mode"],["xmlnsXlink","xmlns:xlink"],["xHeight","x-height"]]),tm=/^[\u0000-\u001F ]*j[\r\n\t]*a[\r\n\t]*v[\r\n\t]*a[\r\n\t]*s[\r\n\t]*c[\r\n\t]*r[\r\n\t]*i[\r\n\t]*p[\r\n\t]*t[\r\n\t]*:/i;function th(e){return tm.test(""+e)?"javascript:throw new Error('React has blocked a javascript: URL as a security precaution.')":e}var tg=null;function ty(e){return(e=e.target||e.srcElement||window).correspondingUseElement&&(e=e.correspondingUseElement),3===e.nodeType?e.parentNode:e}var tb=null,tv=null;function tw(e){var t=eF(e);if(t&&(e=t.stateNode)){var n=e[eR]||null;switch(e=t.stateNode,t.type){case"input":if(tn(e,n.value,n.defaultValue,n.defaultValue,n.checked,n.defaultChecked,n.type,n.name),t=n.name,"radio"===n.type&&null!=t){for(n=e;n.parentNode;)n=n.parentNode;for(n=n.querySelectorAll('input[name="'+tt(""+t)+'"][type="radio"]'),t=0;t<n.length;t++){var r=n[t];if(r!==e&&r.form===e.form){var a=r[eR]||null;if(!a)throw Error(s(90));tn(r,a.value,a.defaultValue,a.defaultValue,a.checked,a.defaultChecked,a.type,a.name)}}for(t=0;t<n.length;t++)(r=n[t]).form===e.form&&e9(r)}break;case"textarea":to(e,n.value,n.defaultValue);break;case"select":null!=(t=n.value)&&ti(e,!!n.multiple,t,!1)}}}var t_=!1;function tk(e,t,n){if(t_)return e(t,n);t_=!0;try{return e(t)}finally{if(t_=!1,(null!==tb||null!==tv)&&(li(),tb&&(t=tb,e=tv,tv=tb=null,tw(t),e)))for(t=0;t<e.length;t++)tw(e[t])}}function tx(e,t){var n=e.stateNode;if(null===n)return null;var r=n[eR]||null;if(null===r)return null;switch(n=r[t],t){case"onClick":case"onClickCapture":case"onDoubleClick":case"onDoubleClickCapture":case"onMouseDown":case"onMouseDownCapture":case"onMouseMove":case"onMouseMoveCapture":case"onMouseUp":case"onMouseUpCapture":case"onMouseEnter":(r=!r.disabled)||(r="button"!==(e=e.type)&&"input"!==e&&"select"!==e&&"textarea"!==e),e=!r;break;default:e=!1}if(e)return null;if(n&&"function"!=typeof n)throw Error(s(231,t,typeof n));return n}var tS="undefined"!=typeof window&&void 0!==window.document&&void 0!==window.document.createElement,tA=!1;if(tS)try{var tT={};Object.defineProperty(tT,"passive",{get:function(){tA=!0}}),window.addEventListener("test",tT,tT),window.removeEventListener("test",tT,tT)}catch(e){tA=!1}var tE=null,tI=null,tC=null;function tP(){if(tC)return tC;var e,t,n=tI,r=n.length,a="value"in tE?tE.value:tE.textContent,i=a.length;for(e=0;e<r&&n[e]===a[e];e++);var o=r-e;for(t=1;t<=o&&n[r-t]===a[i-t];t++);return tC=a.slice(e,1<t?1-t:void 0)}function tL(e){var t=e.keyCode;return"charCode"in e?0===(e=e.charCode)&&13===t&&(e=13):e=t,10===e&&(e=13),32<=e||13===e?e:0}function tR(){return!0}function tM(){return!1}function tN(e){function t(t,n,r,a,i){for(var o in this._reactName=t,this._targetInst=r,this.type=n,this.nativeEvent=a,this.target=i,this.currentTarget=null,e)e.hasOwnProperty(o)&&(t=e[o],this[o]=t?t(a):a[o]);return this.isDefaultPrevented=(null!=a.defaultPrevented?a.defaultPrevented:!1===a.returnValue)?tR:tM,this.isPropagationStopped=tM,this}return f(t.prototype,{preventDefault:function(){this.defaultPrevented=!0;var e=this.nativeEvent;e&&(e.preventDefault?e.preventDefault():"unknown"!=typeof e.returnValue&&(e.returnValue=!1),this.isDefaultPrevented=tR)},stopPropagation:function(){var e=this.nativeEvent;e&&(e.stopPropagation?e.stopPropagation():"unknown"!=typeof e.cancelBubble&&(e.cancelBubble=!0),this.isPropagationStopped=tR)},persist:function(){},isPersistent:tR}),t}var tU,tO,t$,tj,tD,tz,tF,tB,tq={eventPhase:0,bubbles:0,cancelable:0,timeStamp:function(e){return e.timeStamp||Date.now()},defaultPrevented:0,isTrusted:0},tV=tN(tq),tH=f({},tq,{view:0,detail:0}),tQ=tN(tH),tW=f({},tH,{screenX:0,screenY:0,clientX:0,clientY:0,pageX:0,pageY:0,ctrlKey:0,shiftKey:0,altKey:0,metaKey:0,getModifierState:t4,button:0,buttons:0,relatedTarget:function(e){return void 0===e.relatedTarget?e.fromElement===e.srcElement?e.toElement:e.fromElement:e.relatedTarget},movementX:function(e){return"movementX"in e?e.movementX:(e!==tB&&(tB&&"mousemove"===e.type?(tz=e.screenX-tB.screenX,tF=e.screenY-tB.screenY):tF=tz=0,tB=e),tz)},movementY:function(e){return"movementY"in e?e.movementY:tF}}),tG=tN(tW),tK=tN(f({},tW,{dataTransfer:0})),tX=tN(f({},tH,{relatedTarget:0})),tY=tN(f({},tq,{animationName:0,elapsedTime:0,pseudoElement:0})),tJ=tN(f({},tq,{clipboardData:function(e){return"clipboardData"in e?e.clipboardData:window.clipboardData}})),tZ=tN(f({},tq,{data:0})),t0={Esc:"Escape",Spacebar:" ",Left:"ArrowLeft",Up:"ArrowUp",Right:"ArrowRight",Down:"ArrowDown",Del:"Delete",Win:"OS",Menu:"ContextMenu",Apps:"ContextMenu",Scroll:"ScrollLock",MozPrintableKey:"Unidentified"},t1={8:"Backspace",9:"Tab",12:"Clear",13:"Enter",16:"Shift",17:"Control",18:"Alt",19:"Pause",20:"CapsLock",27:"Escape",32:" ",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"ArrowLeft",38:"ArrowUp",39:"ArrowRight",40:"ArrowDown",45:"Insert",46:"Delete",112:"F1",113:"F2",114:"F3",115:"F4",116:"F5",117:"F6",118:"F7",119:"F8",120:"F9",121:"F10",122:"F11",123:"F12",144:"NumLock",145:"ScrollLock",224:"Meta"},t2={Alt:"altKey",Control:"ctrlKey",Meta:"metaKey",Shift:"shiftKey"};function t3(e){var t=this.nativeEvent;return t.getModifierState?t.getModifierState(e):!!(e=t2[e])&&!!t[e]}function t4(){return t3}var t6=tN(f({},tH,{key:function(e){if(e.key){var t=t0[e.key]||e.key;if("Unidentified"!==t)return t}return"keypress"===e.type?13===(e=tL(e))?"Enter":String.fromCharCode(e):"keydown"===e.type||"keyup"===e.type?t1[e.keyCode]||"Unidentified":""},code:0,location:0,ctrlKey:0,shiftKey:0,altKey:0,metaKey:0,repeat:0,locale:0,getModifierState:t4,charCode:function(e){return"keypress"===e.type?tL(e):0},keyCode:function(e){return"keydown"===e.type||"keyup"===e.type?e.keyCode:0},which:function(e){return"keypress"===e.type?tL(e):"keydown"===e.type||"keyup"===e.type?e.keyCode:0}})),t5=tN(f({},tW,{pointerId:0,width:0,height:0,pressure:0,tangentialPressure:0,tiltX:0,tiltY:0,twist:0,pointerType:0,isPrimary:0})),t8=tN(f({},tH,{touches:0,targetTouches:0,changedTouches:0,altKey:0,metaKey:0,ctrlKey:0,shiftKey:0,getModifierState:t4})),t9=tN(f({},tq,{propertyName:0,elapsedTime:0,pseudoElement:0})),t7=tN(f({},tW,{deltaX:function(e){return"deltaX"in e?e.deltaX:"wheelDeltaX"in e?-e.wheelDeltaX:0},deltaY:function(e){return"deltaY"in e?e.deltaY:"wheelDeltaY"in e?-e.wheelDeltaY:"wheelDelta"in e?-e.wheelDelta:0},deltaZ:0,deltaMode:0})),ne=tN(f({},tq,{newState:0,oldState:0})),nt=[9,13,27,32],nn=tS&&"CompositionEvent"in window,nr=null;tS&&"documentMode"in document&&(nr=document.documentMode);var na=tS&&"TextEvent"in window&&!nr,ni=tS&&(!nn||nr&&8<nr&&11>=nr),no=!1;function ns(e,t){switch(e){case"keyup":return -1!==nt.indexOf(t.keyCode);case"keydown":return 229!==t.keyCode;case"keypress":case"mousedown":case"focusout":return!0;default:return!1}}function nl(e){return"object"==typeof(e=e.detail)&&"data"in e?e.data:null}var nu=!1,nc={color:!0,date:!0,datetime:!0,"datetime-local":!0,email:!0,month:!0,number:!0,password:!0,range:!0,search:!0,tel:!0,text:!0,time:!0,url:!0,week:!0};function nd(e){var t=e&&e.nodeName&&e.nodeName.toLowerCase();return"input"===t?!!nc[e.type]:"textarea"===t}function np(e,t,n,r){tb?tv?tv.push(r):tv=[r]:tb=r,0<(t=l5(t,"onChange")).length&&(n=new tV("onChange","change",null,n,r),e.push({event:n,listeners:t}))}var nf=null,nm=null;function nh(e){lJ(e,0)}function ng(e){if(e9(eB(e)))return e}function ny(e,t){if("change"===e)return t}var nb=!1;if(tS){if(tS){var nv="oninput"in document;if(!nv){var nw=document.createElement("div");nw.setAttribute("oninput","return;"),nv="function"==typeof nw.oninput}r=nv}else r=!1;nb=r&&(!document.documentMode||9<document.documentMode)}function n_(){nf&&(nf.detachEvent("onpropertychange",nk),nm=nf=null)}function nk(e){if("value"===e.propertyName&&ng(nm)){var t=[];np(t,nm,e,ty(e)),tk(nh,t)}}function nx(e,t,n){"focusin"===e?(n_(),nf=t,nm=n,nf.attachEvent("onpropertychange",nk)):"focusout"===e&&n_()}function nS(e){if("selectionchange"===e||"keyup"===e||"keydown"===e)return ng(nm)}function nA(e,t){if("click"===e)return ng(t)}function nT(e,t){if("input"===e||"change"===e)return ng(t)}var nE="function"==typeof Object.is?Object.is:function(e,t){return e===t&&(0!==e||1/e==1/t)||e!=e&&t!=t};function nI(e,t){if(nE(e,t))return!0;if("object"!=typeof e||null===e||"object"!=typeof t||null===t)return!1;var n=Object.keys(e),r=Object.keys(t);if(n.length!==r.length)return!1;for(r=0;r<n.length;r++){var a=n[r];if(!X.call(t,a)||!nE(e[a],t[a]))return!1}return!0}function nC(e){for(;e&&e.firstChild;)e=e.firstChild;return e}function nP(e,t){var n,r=nC(e);for(e=0;r;){if(3===r.nodeType){if(n=e+r.textContent.length,e<=t&&n>=t)return{node:r,offset:t-e};e=n}e:{for(;r;){if(r.nextSibling){r=r.nextSibling;break e}r=r.parentNode}r=void 0}r=nC(r)}}function nL(e){e=null!=e&&null!=e.ownerDocument&&null!=e.ownerDocument.defaultView?e.ownerDocument.defaultView:window;for(var t=e7(e.document);t instanceof e.HTMLIFrameElement;){try{var n="string"==typeof t.contentWindow.location.href}catch(e){n=!1}if(n)e=t.contentWindow;else break;t=e7(e.document)}return t}function nR(e){var t=e&&e.nodeName&&e.nodeName.toLowerCase();return t&&("input"===t&&("text"===e.type||"search"===e.type||"tel"===e.type||"url"===e.type||"password"===e.type)||"textarea"===t||"true"===e.contentEditable)}var nM=tS&&"documentMode"in document&&11>=document.documentMode,nN=null,nU=null,nO=null,n$=!1;function nj(e,t,n){var r=n.window===n?n.document:9===n.nodeType?n:n.ownerDocument;n$||null==nN||nN!==e7(r)||(r="selectionStart"in(r=nN)&&nR(r)?{start:r.selectionStart,end:r.selectionEnd}:{anchorNode:(r=(r.ownerDocument&&r.ownerDocument.defaultView||window).getSelection()).anchorNode,anchorOffset:r.anchorOffset,focusNode:r.focusNode,focusOffset:r.focusOffset},nO&&nI(nO,r)||(nO=r,0<(r=l5(nU,"onSelect")).length&&(t=new tV("onSelect","select",null,t,n),e.push({event:t,listeners:r}),t.target=nN)))}function nD(e,t){var n={};return n[e.toLowerCase()]=t.toLowerCase(),n["Webkit"+e]="webkit"+t,n["Moz"+e]="moz"+t,n}var nz={animationend:nD("Animation","AnimationEnd"),animationiteration:nD("Animation","AnimationIteration"),animationstart:nD("Animation","AnimationStart"),transitionrun:nD("Transition","TransitionRun"),transitionstart:nD("Transition","TransitionStart"),transitioncancel:nD("Transition","TransitionCancel"),transitionend:nD("Transition","TransitionEnd")},nF={},nB={};function nq(e){if(nF[e])return nF[e];if(!nz[e])return e;var t,n=nz[e];for(t in n)if(n.hasOwnProperty(t)&&t in nB)return nF[e]=n[t];return e}tS&&(nB=document.createElement("div").style,"AnimationEvent"in window||(delete nz.animationend.animation,delete nz.animationiteration.animation,delete nz.animationstart.animation),"TransitionEvent"in window||delete nz.transitionend.transition);var nV=nq("animationend"),nH=nq("animationiteration"),nQ=nq("animationstart"),nW=nq("transitionrun"),nG=nq("transitionstart"),nK=nq("transitioncancel"),nX=nq("transitionend"),nY=new Map,nJ="abort auxClick beforeToggle cancel canPlay canPlayThrough click close contextMenu copy cut drag dragEnd dragEnter dragExit dragLeave dragOver dragStart drop durationChange emptied encrypted ended error gotPointerCapture input invalid keyDown keyPress keyUp load loadedData loadedMetadata loadStart lostPointerCapture mouseDown mouseMove mouseOut mouseOver mouseUp paste pause play playing pointerCancel pointerDown pointerMove pointerOut pointerOver pointerUp progress rateChange reset resize seeked seeking stalled submit suspend timeUpdate touchCancel touchEnd touchStart volumeChange scroll toggle touchMove waiting wheel".split(" ");function nZ(e,t){nY.set(e,t),eW(t,[e])}nJ.push("scrollEnd");var n0=new WeakMap;function n1(e,t){if("object"==typeof e&&null!==e){var n=n0.get(e);return void 0!==n?n:(t={value:e,source:t,stack:e4(t)},n0.set(e,t),t)}return{value:e,source:t,stack:e4(t)}}var n2=[],n3=0,n4=0;function n6(){for(var e=n3,t=n4=n3=0;t<e;){var n=n2[t];n2[t++]=null;var r=n2[t];n2[t++]=null;var a=n2[t];n2[t++]=null;var i=n2[t];if(n2[t++]=null,null!==r&&null!==a){var o=r.pending;null===o?a.next=a:(a.next=o.next,o.next=a),r.pending=a}0!==i&&n7(n,a,i)}}function n5(e,t,n,r){n2[n3++]=e,n2[n3++]=t,n2[n3++]=n,n2[n3++]=r,n4|=r,e.lanes|=r,null!==(e=e.alternate)&&(e.lanes|=r)}function n8(e,t,n,r){return n5(e,t,n,r),re(e)}function n9(e,t){return n5(e,null,null,t),re(e)}function n7(e,t,n){e.lanes|=n;var r=e.alternate;null!==r&&(r.lanes|=n);for(var a=!1,i=e.return;null!==i;)i.childLanes|=n,null!==(r=i.alternate)&&(r.childLanes|=n),22===i.tag&&(null===(e=i.stateNode)||1&e._visibility||(a=!0)),e=i,i=i.return;return 3===e.tag?(i=e.stateNode,a&&null!==t&&(a=31-ef(n),null===(r=(e=i.hiddenUpdates)[a])?e[a]=[t]:r.push(t),t.lane=0x20000000|n),i):null}function re(e){if(50<s8)throw s8=0,s9=null,Error(s(185));for(var t=e.return;null!==t;)t=(e=t).return;return 3===e.tag?e.stateNode:null}var rt={};function rn(e,t,n,r){this.tag=e,this.key=n,this.sibling=this.child=this.return=this.stateNode=this.type=this.elementType=null,this.index=0,this.refCleanup=this.ref=null,this.pendingProps=t,this.dependencies=this.memoizedState=this.updateQueue=this.memoizedProps=null,this.mode=r,this.subtreeFlags=this.flags=0,this.deletions=null,this.childLanes=this.lanes=0,this.alternate=null}function rr(e,t,n,r){return new rn(e,t,n,r)}function ra(e){return!(!(e=e.prototype)||!e.isReactComponent)}function ri(e,t){var n=e.alternate;return null===n?((n=rr(e.tag,t,e.key,e.mode)).elementType=e.elementType,n.type=e.type,n.stateNode=e.stateNode,n.alternate=e,e.alternate=n):(n.pendingProps=t,n.type=e.type,n.flags=0,n.subtreeFlags=0,n.deletions=null),n.flags=0x3e00000&e.flags,n.childLanes=e.childLanes,n.lanes=e.lanes,n.child=e.child,n.memoizedProps=e.memoizedProps,n.memoizedState=e.memoizedState,n.updateQueue=e.updateQueue,t=e.dependencies,n.dependencies=null===t?null:{lanes:t.lanes,firstContext:t.firstContext},n.sibling=e.sibling,n.index=e.index,n.ref=e.ref,n.refCleanup=e.refCleanup,n}function ro(e,t){e.flags&=0x3e00002;var n=e.alternate;return null===n?(e.childLanes=0,e.lanes=t,e.child=null,e.subtreeFlags=0,e.memoizedProps=null,e.memoizedState=null,e.updateQueue=null,e.dependencies=null,e.stateNode=null):(e.childLanes=n.childLanes,e.lanes=n.lanes,e.child=n.child,e.subtreeFlags=0,e.deletions=null,e.memoizedProps=n.memoizedProps,e.memoizedState=n.memoizedState,e.updateQueue=n.updateQueue,e.type=n.type,e.dependencies=null===(t=n.dependencies)?null:{lanes:t.lanes,firstContext:t.firstContext}),e}function rs(e,t,n,r,a,i){var o=0;if(r=e,"function"==typeof e)ra(e)&&(o=1);else if("string"==typeof e)o=!function(e,t,n){if(1===n||null!=t.itemProp)return!1;switch(e){case"meta":case"title":return!0;case"style":if("string"!=typeof t.precedence||"string"!=typeof t.href||""===t.href)break;return!0;case"link":if("string"!=typeof t.rel||"string"!=typeof t.href||""===t.href||t.onLoad||t.onError)break;if("stylesheet"===t.rel)return e=t.disabled,"string"==typeof t.precedence&&null==e;return!0;case"script":if(t.async&&"function"!=typeof t.async&&"symbol"!=typeof t.async&&!t.onLoad&&!t.onError&&t.src&&"string"==typeof t.src)return!0}return!1}(e,n,B.current)?"html"===e||"head"===e||"body"===e?27:5:26;else e:switch(e){case I:return(e=rr(31,n,t,a)).elementType=I,e.lanes=i,e;case y:return rl(n.children,a,i,t);case b:o=8,a|=24;break;case v:return(e=rr(12,n,t,2|a)).elementType=v,e.lanes=i,e;case S:return(e=rr(13,n,t,a)).elementType=S,e.lanes=i,e;case A:return(e=rr(19,n,t,a)).elementType=A,e.lanes=i,e;default:if("object"==typeof e&&null!==e)switch(e.$$typeof){case w:case k:o=10;break e;case _:o=9;break e;case x:o=11;break e;case T:o=14;break e;case E:o=16,r=null;break e}o=29,n=Error(s(130,null===e?"null":typeof e,"")),r=null}return(t=rr(o,n,t,a)).elementType=e,t.type=r,t.lanes=i,t}function rl(e,t,n,r){return(e=rr(7,e,r,t)).lanes=n,e}function ru(e,t,n){return(e=rr(6,e,null,t)).lanes=n,e}function rc(e,t,n){return(t=rr(4,null!==e.children?e.children:[],e.key,t)).lanes=n,t.stateNode={containerInfo:e.containerInfo,pendingChildren:null,implementation:e.implementation},t}var rd=[],rp=0,rf=null,rm=0,rh=[],rg=0,ry=null,rb=1,rv="";function rw(e,t){rd[rp++]=rm,rd[rp++]=rf,rf=e,rm=t}function r_(e,t,n){rh[rg++]=rb,rh[rg++]=rv,rh[rg++]=ry,ry=e;var r=rb;e=rv;var a=32-ef(r)-1;r&=~(1<<a),n+=1;var i=32-ef(t)+a;if(30<i){var o=a-a%5;i=(r&(1<<o)-1).toString(32),r>>=o,a-=o,rb=1<<32-ef(t)+a|n<<a|r,rv=i+e}else rb=1<<i|n<<a|r,rv=e}function rk(e){null!==e.return&&(rw(e,1),r_(e,1,0))}function rx(e){for(;e===rf;)rf=rd[--rp],rd[rp]=null,rm=rd[--rp],rd[rp]=null;for(;e===ry;)ry=rh[--rg],rh[rg]=null,rv=rh[--rg],rh[rg]=null,rb=rh[--rg],rh[rg]=null}var rS=null,rA=null,rT=!1,rE=null,rI=!1,rC=Error(s(519));function rP(e){throw rO(n1(Error(s(418,"")),e)),rC}function rL(e){var t=e.stateNode,n=e.type,r=e.memoizedProps;switch(t[eL]=e,t[eR]=r,n){case"dialog":lZ("cancel",t),lZ("close",t);break;case"iframe":case"object":case"embed":lZ("load",t);break;case"video":case"audio":for(n=0;n<lX.length;n++)lZ(lX[n],t);break;case"source":lZ("error",t);break;case"img":case"image":case"link":lZ("error",t),lZ("load",t);break;case"details":lZ("toggle",t);break;case"input":lZ("invalid",t),tr(t,r.value,r.defaultValue,r.checked,r.defaultChecked,r.type,r.name,!0),e8(t);break;case"select":lZ("invalid",t);break;case"textarea":lZ("invalid",t),ts(t,r.value,r.defaultValue,r.children),e8(t)}"string"!=typeof(n=r.children)&&"number"!=typeof n&&"bigint"!=typeof n||t.textContent===""+n||!0===r.suppressHydrationWarning||un(t.textContent,n)?(null!=r.popover&&(lZ("beforetoggle",t),lZ("toggle",t)),null!=r.onScroll&&lZ("scroll",t),null!=r.onScrollEnd&&lZ("scrollend",t),null!=r.onClick&&(t.onclick=ur),t=!0):t=!1,t||rP(e)}function rR(e){for(rS=e.return;rS;)switch(rS.tag){case 5:case 13:rI=!1;return;case 27:case 3:rI=!0;return;default:rS=rS.return}}function rM(e){if(e!==rS)return!1;if(!rT)return rR(e),rT=!0,!1;var t,n=e.tag;if((t=3!==n&&27!==n)&&((t=5===n)&&(t="form"===(t=e.type)||"button"===t||up(e.type,e.memoizedProps)),t=!t),t&&rA&&rP(e),rR(e),13===n){if(!(e=null!==(e=e.memoizedState)?e.dehydrated:null))throw Error(s(317));e:{for(n=0,e=e.nextSibling;e;){if(8===e.nodeType)if("/$"===(t=e.data)){if(0===n){rA=ux(e.nextSibling);break e}n--}else"$"!==t&&"$!"!==t&&"$?"!==t||n++;e=e.nextSibling}rA=null}}else 27===n?(n=rA,uv(e.type)?(e=uS,uS=null,rA=e):rA=n):rA=rS?ux(e.stateNode.nextSibling):null;return!0}function rN(){rA=rS=null,rT=!1}function rU(){var e=rE;return null!==e&&(null===sG?sG=e:sG.push.apply(sG,e),rE=null),e}function rO(e){null===rE?rE=[e]:rE.push(e)}var r$=D(null),rj=null,rD=null;function rz(e,t,n){F(r$,t._currentValue),t._currentValue=n}function rF(e){e._currentValue=r$.current,z(r$)}function rB(e,t,n){for(;null!==e;){var r=e.alternate;if((e.childLanes&t)!==t?(e.childLanes|=t,null!==r&&(r.childLanes|=t)):null!==r&&(r.childLanes&t)!==t&&(r.childLanes|=t),e===n)break;e=e.return}}function rq(e,t,n,r){var a=e.child;for(null!==a&&(a.return=e);null!==a;){var i=a.dependencies;if(null!==i){var o=a.child;i=i.firstContext;e:for(;null!==i;){var l=i;i=a;for(var u=0;u<t.length;u++)if(l.context===t[u]){i.lanes|=n,null!==(l=i.alternate)&&(l.lanes|=n),rB(i.return,n,e),r||(o=null);break e}i=l.next}}else if(18===a.tag){if(null===(o=a.return))throw Error(s(341));o.lanes|=n,null!==(i=o.alternate)&&(i.lanes|=n),rB(o,n,e),o=null}else o=a.child;if(null!==o)o.return=a;else for(o=a;null!==o;){if(o===e){o=null;break}if(null!==(a=o.sibling)){a.return=o.return,o=a;break}o=o.return}a=o}}function rV(e,t,n,r){e=null;for(var a=t,i=!1;null!==a;){if(!i){if(0!=(524288&a.flags))i=!0;else if(0!=(262144&a.flags))break}if(10===a.tag){var o=a.alternate;if(null===o)throw Error(s(387));if(null!==(o=o.memoizedProps)){var l=a.type;nE(a.pendingProps.value,o.value)||(null!==e?e.push(l):e=[l])}}else if(a===H.current){if(null===(o=a.alternate))throw Error(s(387));o.memoizedState.memoizedState!==a.memoizedState.memoizedState&&(null!==e?e.push(u0):e=[u0])}a=a.return}null!==e&&rq(t,e,n,r),t.flags|=262144}function rH(e){for(e=e.firstContext;null!==e;){if(!nE(e.context._currentValue,e.memoizedValue))return!0;e=e.next}return!1}function rQ(e){rj=e,rD=null,null!==(e=e.dependencies)&&(e.firstContext=null)}function rW(e){return rK(rj,e)}function rG(e,t){return null===rj&&rQ(e),rK(e,t)}function rK(e,t){var n=t._currentValue;if(t={context:t,memoizedValue:n,next:null},null===rD){if(null===e)throw Error(s(308));rD=t,e.dependencies={lanes:0,firstContext:t},e.flags|=524288}else rD=rD.next=t;return n}var rX="undefined"!=typeof AbortController?AbortController:function(){var e=[],t=this.signal={aborted:!1,addEventListener:function(t,n){e.push(n)}};this.abort=function(){t.aborted=!0,e.forEach(function(e){return e()})}},rY=a.unstable_scheduleCallback,rJ=a.unstable_NormalPriority,rZ={$$typeof:k,Consumer:null,Provider:null,_currentValue:null,_currentValue2:null,_threadCount:0};function r0(){return{controller:new rX,data:new Map,refCount:0}}function r1(e){e.refCount--,0===e.refCount&&rY(rJ,function(){e.controller.abort()})}var r2=null,r3=0,r4=0,r6=null;function r5(){if(0==--r3&&null!==r2){null!==r6&&(r6.status="fulfilled");var e=r2;r2=null,r4=0,r6=null;for(var t=0;t<e.length;t++)(0,e[t])()}}var r8=N.S;N.S=function(e,t){"object"==typeof t&&null!==t&&"function"==typeof t.then&&function(e,t){if(null===r2){var n=r2=[];r3=0,r4=lH(),r6={status:"pending",value:void 0,then:function(e){n.push(e)}}}r3++,t.then(r5,r5)}(0,t),null!==r8&&r8(e,t)};var r9=D(null);function r7(){var e=r9.current;return null!==e?e:sR.pooledCache}function ae(e,t){null===t?F(r9,r9.current):F(r9,t.pool)}function at(){var e=r7();return null===e?null:{parent:rZ._currentValue,pool:e}}var an=Error(s(460)),ar=Error(s(474)),aa=Error(s(542)),ai={then:function(){}};function ao(e){return"fulfilled"===(e=e.status)||"rejected"===e}function as(){}function al(e,t,n){switch(void 0===(n=e[n])?e.push(t):n!==t&&(t.then(as,as),t=n),t.status){case"fulfilled":return t.value;case"rejected":throw ad(e=t.reason),e;default:if("string"==typeof t.status)t.then(as,as);else{if(null!==(e=sR)&&100<e.shellSuspendCounter)throw Error(s(482));(e=t).status="pending",e.then(function(e){if("pending"===t.status){var n=t;n.status="fulfilled",n.value=e}},function(e){if("pending"===t.status){var n=t;n.status="rejected",n.reason=e}})}switch(t.status){case"fulfilled":return t.value;case"rejected":throw ad(e=t.reason),e}throw au=t,an}}var au=null;function ac(){if(null===au)throw Error(s(459));var e=au;return au=null,e}function ad(e){if(e===an||e===aa)throw Error(s(483))}var ap=!1;function af(e){e.updateQueue={baseState:e.memoizedState,firstBaseUpdate:null,lastBaseUpdate:null,shared:{pending:null,lanes:0,hiddenCallbacks:null},callbacks:null}}function am(e,t){e=e.updateQueue,t.updateQueue===e&&(t.updateQueue={baseState:e.baseState,firstBaseUpdate:e.firstBaseUpdate,lastBaseUpdate:e.lastBaseUpdate,shared:e.shared,callbacks:null})}function ah(e){return{lane:e,tag:0,payload:null,callback:null,next:null}}function ag(e,t,n){var r=e.updateQueue;if(null===r)return null;if(r=r.shared,0!=(2&sL)){var a=r.pending;return null===a?t.next=t:(t.next=a.next,a.next=t),r.pending=t,t=re(e),n7(e,null,n),t}return n5(e,r,t,n),re(e)}function ay(e,t,n){if(null!==(t=t.updateQueue)&&(t=t.shared,0!=(4194048&n))){var r=t.lanes;r&=e.pendingLanes,n|=r,t.lanes=n,eT(e,n)}}function ab(e,t){var n=e.updateQueue,r=e.alternate;if(null!==r&&n===(r=r.updateQueue)){var a=null,i=null;if(null!==(n=n.firstBaseUpdate)){do{var o={lane:n.lane,tag:n.tag,payload:n.payload,callback:null,next:null};null===i?a=i=o:i=i.next=o,n=n.next}while(null!==n)null===i?a=i=t:i=i.next=t}else a=i=t;n={baseState:r.baseState,firstBaseUpdate:a,lastBaseUpdate:i,shared:r.shared,callbacks:r.callbacks},e.updateQueue=n;return}null===(e=n.lastBaseUpdate)?n.firstBaseUpdate=t:e.next=t,n.lastBaseUpdate=t}var av=!1;function aw(){if(av){var e=r6;if(null!==e)throw e}}function a_(e,t,n,r){av=!1;var a=e.updateQueue;ap=!1;var i=a.firstBaseUpdate,o=a.lastBaseUpdate,s=a.shared.pending;if(null!==s){a.shared.pending=null;var l=s,u=l.next;l.next=null,null===o?i=u:o.next=u,o=l;var c=e.alternate;null!==c&&(s=(c=c.updateQueue).lastBaseUpdate)!==o&&(null===s?c.firstBaseUpdate=u:s.next=u,c.lastBaseUpdate=l)}if(null!==i){var d=a.baseState;for(o=0,c=u=l=null,s=i;;){var p=-0x20000001&s.lane,m=p!==s.lane;if(m?(sN&p)===p:(r&p)===p){0!==p&&p===r4&&(av=!0),null!==c&&(c=c.next={lane:0,tag:s.tag,payload:s.payload,callback:null,next:null});e:{var h=e,g=s;switch(p=t,g.tag){case 1:if("function"==typeof(h=g.payload)){d=h.call(n,d,p);break e}d=h;break e;case 3:h.flags=-65537&h.flags|128;case 0:if(null==(p="function"==typeof(h=g.payload)?h.call(n,d,p):h))break e;d=f({},d,p);break e;case 2:ap=!0}}null!==(p=s.callback)&&(e.flags|=64,m&&(e.flags|=8192),null===(m=a.callbacks)?a.callbacks=[p]:m.push(p))}else m={lane:p,tag:s.tag,payload:s.payload,callback:s.callback,next:null},null===c?(u=c=m,l=d):c=c.next=m,o|=p;if(null===(s=s.next))if(null===(s=a.shared.pending))break;else s=(m=s).next,m.next=null,a.lastBaseUpdate=m,a.shared.pending=null}null===c&&(l=d),a.baseState=l,a.firstBaseUpdate=u,a.lastBaseUpdate=c,null===i&&(a.shared.lanes=0),sB|=o,e.lanes=o,e.memoizedState=d}}function ak(e,t){if("function"!=typeof e)throw Error(s(191,e));e.call(t)}function ax(e,t){var n=e.callbacks;if(null!==n)for(e.callbacks=null,e=0;e<n.length;e++)ak(n[e],t)}var aS=D(null),aA=D(0);function aT(e,t){F(aA,e=sz),F(aS,t),sz=e|t.baseLanes}function aE(){F(aA,sz),F(aS,aS.current)}function aI(){sz=aA.current,z(aS),z(aA)}var aC=0,aP=null,aL=null,aR=null,aM=!1,aN=!1,aU=!1,aO=0,a$=0,aj=null,aD=0;function az(){throw Error(s(321))}function aF(e,t){if(null===t)return!1;for(var n=0;n<t.length&&n<e.length;n++)if(!nE(e[n],t[n]))return!1;return!0}function aB(e,t,n,r,a,i){return aC=i,aP=t,t.memoizedState=null,t.updateQueue=null,t.lanes=0,N.H=null===e||null===e.memoizedState?iX:iY,aU=!1,i=n(r,a),aU=!1,aN&&(i=aV(t,n,r,a)),aq(e),i}function aq(e){N.H=iK;var t=null!==aL&&null!==aL.next;if(aC=0,aR=aL=aP=null,aM=!1,a$=0,aj=null,t)throw Error(s(300));null===e||o_||null!==(e=e.dependencies)&&rH(e)&&(o_=!0)}function aV(e,t,n,r){aP=e;var a=0;do{if(aN&&(aj=null),a$=0,aN=!1,25<=a)throw Error(s(301));if(a+=1,aR=aL=null,null!=e.updateQueue){var i=e.updateQueue;i.lastEffect=null,i.events=null,i.stores=null,null!=i.memoCache&&(i.memoCache.index=0)}N.H=iJ,i=t(n,r)}while(aN)return i}function aH(){var e=N.H,t=e.useState()[0];return t="function"==typeof t.then?aJ(t):t,e=e.useState()[0],(null!==aL?aL.memoizedState:null)!==e&&(aP.flags|=1024),t}function aQ(){var e=0!==aO;return aO=0,e}function aW(e,t,n){t.updateQueue=e.updateQueue,t.flags&=-2053,e.lanes&=~n}function aG(e){if(aM){for(e=e.memoizedState;null!==e;){var t=e.queue;null!==t&&(t.pending=null),e=e.next}aM=!1}aC=0,aR=aL=aP=null,aN=!1,a$=aO=0,aj=null}function aK(){var e={memoizedState:null,baseState:null,baseQueue:null,queue:null,next:null};return null===aR?aP.memoizedState=aR=e:aR=aR.next=e,aR}function aX(){if(null===aL){var e=aP.alternate;e=null!==e?e.memoizedState:null}else e=aL.next;var t=null===aR?aP.memoizedState:aR.next;if(null!==t)aR=t,aL=e;else{if(null===e){if(null===aP.alternate)throw Error(s(467));throw Error(s(310))}e={memoizedState:(aL=e).memoizedState,baseState:aL.baseState,baseQueue:aL.baseQueue,queue:aL.queue,next:null},null===aR?aP.memoizedState=aR=e:aR=aR.next=e}return aR}function aY(){return{lastEffect:null,events:null,stores:null,memoCache:null}}function aJ(e){var t=a$;return a$+=1,null===aj&&(aj=[]),e=al(aj,e,t),t=aP,null===(null===aR?t.memoizedState:aR.next)&&(N.H=null===(t=t.alternate)||null===t.memoizedState?iX:iY),e}function aZ(e){if(null!==e&&"object"==typeof e){if("function"==typeof e.then)return aJ(e);if(e.$$typeof===k)return rW(e)}throw Error(s(438,String(e)))}function a0(e){var t=null,n=aP.updateQueue;if(null!==n&&(t=n.memoCache),null==t){var r=aP.alternate;null!==r&&null!==(r=r.updateQueue)&&null!=(r=r.memoCache)&&(t={data:r.data.map(function(e){return e.slice()}),index:0})}if(null==t&&(t={data:[],index:0}),null===n&&(n=aY(),aP.updateQueue=n),n.memoCache=t,void 0===(n=t.data[t.index]))for(n=t.data[t.index]=Array(e),r=0;r<e;r++)n[r]=C;return t.index++,n}function a1(e,t){return"function"==typeof t?t(e):t}function a2(e){return a3(aX(),aL,e)}function a3(e,t,n){var r=e.queue;if(null===r)throw Error(s(311));r.lastRenderedReducer=n;var a=e.baseQueue,i=r.pending;if(null!==i){if(null!==a){var o=a.next;a.next=i.next,i.next=o}t.baseQueue=a=i,r.pending=null}if(i=e.baseState,null===a)e.memoizedState=i;else{t=a.next;var l=o=null,u=null,c=t,d=!1;do{var p=-0x20000001&c.lane;if(p!==c.lane?(sN&p)===p:(aC&p)===p){var f=c.revertLane;if(0===f)null!==u&&(u=u.next={lane:0,revertLane:0,action:c.action,hasEagerState:c.hasEagerState,eagerState:c.eagerState,next:null}),p===r4&&(d=!0);else if((aC&f)===f){c=c.next,f===r4&&(d=!0);continue}else p={lane:0,revertLane:c.revertLane,action:c.action,hasEagerState:c.hasEagerState,eagerState:c.eagerState,next:null},null===u?(l=u=p,o=i):u=u.next=p,aP.lanes|=f,sB|=f;p=c.action,aU&&n(i,p),i=c.hasEagerState?c.eagerState:n(i,p)}else f={lane:p,revertLane:c.revertLane,action:c.action,hasEagerState:c.hasEagerState,eagerState:c.eagerState,next:null},null===u?(l=u=f,o=i):u=u.next=f,aP.lanes|=p,sB|=p;c=c.next}while(null!==c&&c!==t)if(null===u?o=i:u.next=l,!nE(i,e.memoizedState)&&(o_=!0,d&&null!==(n=r6)))throw n;e.memoizedState=i,e.baseState=o,e.baseQueue=u,r.lastRenderedState=i}return null===a&&(r.lanes=0),[e.memoizedState,r.dispatch]}function a4(e){var t=aX(),n=t.queue;if(null===n)throw Error(s(311));n.lastRenderedReducer=e;var r=n.dispatch,a=n.pending,i=t.memoizedState;if(null!==a){n.pending=null;var o=a=a.next;do i=e(i,o.action),o=o.next;while(o!==a)nE(i,t.memoizedState)||(o_=!0),t.memoizedState=i,null===t.baseQueue&&(t.baseState=i),n.lastRenderedState=i}return[i,r]}function a6(e,t,n){var r=aP,a=aX(),i=rT;if(i){if(void 0===n)throw Error(s(407));n=n()}else n=t();var o=!nE((aL||a).memoizedState,n);if(o&&(a.memoizedState=n,o_=!0),a=a.queue,i_(2048,8,a9.bind(null,r,a,e),[e]),a.getSnapshot!==t||o||null!==aR&&1&aR.memoizedState.tag){if(r.flags|=2048,iy(9,ib(),a8.bind(null,r,a,n,t),null),null===sR)throw Error(s(349));i||0!=(124&aC)||a5(r,t,n)}return n}function a5(e,t,n){e.flags|=16384,e={getSnapshot:t,value:n},null===(t=aP.updateQueue)?(t=aY(),aP.updateQueue=t,t.stores=[e]):null===(n=t.stores)?t.stores=[e]:n.push(e)}function a8(e,t,n,r){t.value=n,t.getSnapshot=r,a7(t)&&ie(e)}function a9(e,t,n){return n(function(){a7(t)&&ie(e)})}function a7(e){var t=e.getSnapshot;e=e.value;try{var n=t();return!nE(e,n)}catch(e){return!0}}function ie(e){var t=n9(e,2);null!==t&&lt(t,e,2)}function it(e){var t=aK();if("function"==typeof e){var n=e;if(e=n(),aU){ep(!0);try{n()}finally{ep(!1)}}}return t.memoizedState=t.baseState=e,t.queue={pending:null,lanes:0,dispatch:null,lastRenderedReducer:a1,lastRenderedState:e},t}function ir(e,t,n,r){return e.baseState=n,a3(e,aL,"function"==typeof r?r:a1)}function ia(e,t,n,r,a){if(iQ(e))throw Error(s(485));if(null!==(e=t.action)){var i={payload:a,action:e,next:null,isTransition:!0,status:"pending",value:null,reason:null,listeners:[],then:function(e){i.listeners.push(e)}};null!==N.T?n(!0):i.isTransition=!1,r(i),null===(n=t.pending)?(i.next=t.pending=i,ii(t,i)):(i.next=n.next,t.pending=n.next=i)}}function ii(e,t){var n=t.action,r=t.payload,a=e.state;if(t.isTransition){var i=N.T,o={};N.T=o;try{var s=n(a,r),l=N.S;null!==l&&l(o,s),io(e,t,s)}catch(n){il(e,t,n)}finally{N.T=i}}else try{i=n(a,r),io(e,t,i)}catch(n){il(e,t,n)}}function io(e,t,n){null!==n&&"object"==typeof n&&"function"==typeof n.then?n.then(function(n){is(e,t,n)},function(n){return il(e,t,n)}):is(e,t,n)}function is(e,t,n){t.status="fulfilled",t.value=n,iu(t),e.state=n,null!==(t=e.pending)&&((n=t.next)===t?e.pending=null:(n=n.next,t.next=n,ii(e,n)))}function il(e,t,n){var r=e.pending;if(e.pending=null,null!==r){r=r.next;do t.status="rejected",t.reason=n,iu(t),t=t.next;while(t!==r)}e.action=null}function iu(e){e=e.listeners;for(var t=0;t<e.length;t++)(0,e[t])()}function ic(e,t){return t}function id(e,t){if(rT){var n=sR.formState;if(null!==n){e:{var r=aP;if(rT){if(rA){t:{for(var a=rA,i=rI;8!==a.nodeType;)if(!i||null===(a=ux(a.nextSibling))){a=null;break t}a="F!"===(i=a.data)||"F"===i?a:null}if(a){rA=ux(a.nextSibling),r="F!"===a.data;break e}}rP(r)}r=!1}r&&(t=n[0])}}return(n=aK()).memoizedState=n.baseState=t,r={pending:null,lanes:0,dispatch:null,lastRenderedReducer:ic,lastRenderedState:t},n.queue=r,n=iq.bind(null,aP,r),r.dispatch=n,r=it(!1),i=iH.bind(null,aP,!1,r.queue),r=aK(),a={state:t,dispatch:null,action:e,pending:null},r.queue=a,n=ia.bind(null,aP,a,i,n),a.dispatch=n,r.memoizedState=e,[t,n,!1]}function ip(e){return im(aX(),aL,e)}function im(e,t,n){if(t=a3(e,t,ic)[0],e=a2(a1)[0],"object"==typeof t&&null!==t&&"function"==typeof t.then)try{var r=aJ(t)}catch(e){if(e===an)throw aa;throw e}else r=t;var a=(t=aX()).queue,i=a.dispatch;return n!==t.memoizedState&&(aP.flags|=2048,iy(9,ib(),ih.bind(null,a,n),null)),[r,i,e]}function ih(e,t){e.action=t}function ig(e){var t=aX(),n=aL;if(null!==n)return im(t,n,e);aX(),t=t.memoizedState;var r=(n=aX()).queue.dispatch;return n.memoizedState=e,[t,r,!1]}function iy(e,t,n,r){return e={tag:e,create:n,deps:r,inst:t,next:null},null===(t=aP.updateQueue)&&(t=aY(),aP.updateQueue=t),null===(n=t.lastEffect)?t.lastEffect=e.next=e:(r=n.next,n.next=e,e.next=r,t.lastEffect=e),e}function ib(){return{destroy:void 0,resource:void 0}}function iv(){return aX().memoizedState}function iw(e,t,n,r){var a=aK();r=void 0===r?null:r,aP.flags|=e,a.memoizedState=iy(1|t,ib(),n,r)}function i_(e,t,n,r){var a=aX();r=void 0===r?null:r;var i=a.memoizedState.inst;null!==aL&&null!==r&&aF(r,aL.memoizedState.deps)?a.memoizedState=iy(t,i,n,r):(aP.flags|=e,a.memoizedState=iy(1|t,i,n,r))}function ik(e,t){iw(8390656,8,e,t)}function ix(e,t){i_(2048,8,e,t)}function iS(e,t){return i_(4,2,e,t)}function iA(e,t){return i_(4,4,e,t)}function iT(e,t){if("function"==typeof t){var n=t(e=e());return function(){"function"==typeof n?n():t(null)}}if(null!=t)return t.current=e=e(),function(){t.current=null}}function iE(e,t,n){n=null!=n?n.concat([e]):null,i_(4,4,iT.bind(null,t,e),n)}function iI(){}function iC(e,t){var n=aX();t=void 0===t?null:t;var r=n.memoizedState;return null!==t&&aF(t,r[1])?r[0]:(n.memoizedState=[e,t],e)}function iP(e,t){var n=aX();t=void 0===t?null:t;var r=n.memoizedState;if(null!==t&&aF(t,r[1]))return r[0];if(r=e(),aU){ep(!0);try{e()}finally{ep(!1)}}return n.memoizedState=[r,t],r}function iL(e,t,n){return void 0===n||0!=(0x40000000&aC)?e.memoizedState=t:(e.memoizedState=n,e=le(),aP.lanes|=e,sB|=e,n)}function iR(e,t,n,r){return nE(n,t)?n:null!==aS.current?(nE(e=iL(e,n,r),t)||(o_=!0),e):0==(42&aC)?(o_=!0,e.memoizedState=n):(e=le(),aP.lanes|=e,sB|=e,t)}function iM(e,t,n,r,a){var i=U.p;U.p=0!==i&&8>i?i:8;var o=N.T,s={};N.T=s,iH(e,!1,t,n);try{var l=a(),u=N.S;if(null!==u&&u(s,l),null!==l&&"object"==typeof l&&"function"==typeof l.then){var c,d,p=(c=[],d={status:"pending",value:null,reason:null,then:function(e){c.push(e)}},l.then(function(){d.status="fulfilled",d.value=r;for(var e=0;e<c.length;e++)(0,c[e])(r)},function(e){for(d.status="rejected",d.reason=e,e=0;e<c.length;e++)(0,c[e])(void 0)}),d);iV(e,t,p,s7(e))}else iV(e,t,r,s7(e))}catch(n){iV(e,t,{then:function(){},status:"rejected",reason:n},s7())}finally{U.p=i,N.T=o}}function iN(){}function iU(e,t,n,r){if(5!==e.tag)throw Error(s(476));var a=iO(e).queue;iM(e,a,t,O,null===n?iN:function(){return i$(e),n(r)})}function iO(e){var t=e.memoizedState;if(null!==t)return t;var n={};return(t={memoizedState:O,baseState:O,baseQueue:null,queue:{pending:null,lanes:0,dispatch:null,lastRenderedReducer:a1,lastRenderedState:O},next:null}).next={memoizedState:n,baseState:n,baseQueue:null,queue:{pending:null,lanes:0,dispatch:null,lastRenderedReducer:a1,lastRenderedState:n},next:null},e.memoizedState=t,null!==(e=e.alternate)&&(e.memoizedState=t),t}function i$(e){var t=iO(e).next.queue;iV(e,t,{},s7())}function ij(){return rW(u0)}function iD(){return aX().memoizedState}function iz(){return aX().memoizedState}function iF(e){for(var t=e.return;null!==t;){switch(t.tag){case 24:case 3:var n=s7(),r=ag(t,e=ah(n),n);null!==r&&(lt(r,t,n),ay(r,t,n)),t={cache:r0()},e.payload=t;return}t=t.return}}function iB(e,t,n){var r=s7();n={lane:r,revertLane:0,action:n,hasEagerState:!1,eagerState:null,next:null},iQ(e)?iW(t,n):null!==(n=n8(e,t,n,r))&&(lt(n,e,r),iG(n,t,r))}function iq(e,t,n){iV(e,t,n,s7())}function iV(e,t,n,r){var a={lane:r,revertLane:0,action:n,hasEagerState:!1,eagerState:null,next:null};if(iQ(e))iW(t,a);else{var i=e.alternate;if(0===e.lanes&&(null===i||0===i.lanes)&&null!==(i=t.lastRenderedReducer))try{var o=t.lastRenderedState,s=i(o,n);if(a.hasEagerState=!0,a.eagerState=s,nE(s,o))return n5(e,t,a,0),null===sR&&n6(),!1}catch(e){}finally{}if(null!==(n=n8(e,t,a,r)))return lt(n,e,r),iG(n,t,r),!0}return!1}function iH(e,t,n,r){if(r={lane:2,revertLane:lH(),action:r,hasEagerState:!1,eagerState:null,next:null},iQ(e)){if(t)throw Error(s(479))}else null!==(t=n8(e,n,r,2))&&lt(t,e,2)}function iQ(e){var t=e.alternate;return e===aP||null!==t&&t===aP}function iW(e,t){aN=aM=!0;var n=e.pending;null===n?t.next=t:(t.next=n.next,n.next=t),e.pending=t}function iG(e,t,n){if(0!=(4194048&n)){var r=t.lanes;r&=e.pendingLanes,t.lanes=n|=r,eT(e,n)}}var iK={readContext:rW,use:aZ,useCallback:az,useContext:az,useEffect:az,useImperativeHandle:az,useLayoutEffect:az,useInsertionEffect:az,useMemo:az,useReducer:az,useRef:az,useState:az,useDebugValue:az,useDeferredValue:az,useTransition:az,useSyncExternalStore:az,useId:az,useHostTransitionStatus:az,useFormState:az,useActionState:az,useOptimistic:az,useMemoCache:az,useCacheRefresh:az},iX={readContext:rW,use:aZ,useCallback:function(e,t){return aK().memoizedState=[e,void 0===t?null:t],e},useContext:rW,useEffect:ik,useImperativeHandle:function(e,t,n){n=null!=n?n.concat([e]):null,iw(4194308,4,iT.bind(null,t,e),n)},useLayoutEffect:function(e,t){return iw(4194308,4,e,t)},useInsertionEffect:function(e,t){iw(4,2,e,t)},useMemo:function(e,t){var n=aK();t=void 0===t?null:t;var r=e();if(aU){ep(!0);try{e()}finally{ep(!1)}}return n.memoizedState=[r,t],r},useReducer:function(e,t,n){var r=aK();if(void 0!==n){var a=n(t);if(aU){ep(!0);try{n(t)}finally{ep(!1)}}}else a=t;return r.memoizedState=r.baseState=a,r.queue=e={pending:null,lanes:0,dispatch:null,lastRenderedReducer:e,lastRenderedState:a},e=e.dispatch=iB.bind(null,aP,e),[r.memoizedState,e]},useRef:function(e){return aK().memoizedState={current:e}},useState:function(e){var t=(e=it(e)).queue,n=iq.bind(null,aP,t);return t.dispatch=n,[e.memoizedState,n]},useDebugValue:iI,useDeferredValue:function(e,t){return iL(aK(),e,t)},useTransition:function(){var e=it(!1);return e=iM.bind(null,aP,e.queue,!0,!1),aK().memoizedState=e,[!1,e]},useSyncExternalStore:function(e,t,n){var r=aP,a=aK();if(rT){if(void 0===n)throw Error(s(407));n=n()}else{if(n=t(),null===sR)throw Error(s(349));0!=(124&sN)||a5(r,t,n)}a.memoizedState=n;var i={value:n,getSnapshot:t};return a.queue=i,ik(a9.bind(null,r,i,e),[e]),r.flags|=2048,iy(9,ib(),a8.bind(null,r,i,n,t),null),n},useId:function(){var e=aK(),t=sR.identifierPrefix;if(rT){var n=rv,r=rb;t=""+t+"R"+(n=(r&~(1<<32-ef(r)-1)).toString(32)+n),0<(n=aO++)&&(t+="H"+n.toString(32)),t+=""}else t=""+t+"r"+(n=aD++).toString(32)+"";return e.memoizedState=t},useHostTransitionStatus:ij,useFormState:id,useActionState:id,useOptimistic:function(e){var t=aK();t.memoizedState=t.baseState=e;var n={pending:null,lanes:0,dispatch:null,lastRenderedReducer:null,lastRenderedState:null};return t.queue=n,t=iH.bind(null,aP,!0,n),n.dispatch=t,[e,t]},useMemoCache:a0,useCacheRefresh:function(){return aK().memoizedState=iF.bind(null,aP)}},iY={readContext:rW,use:aZ,useCallback:iC,useContext:rW,useEffect:ix,useImperativeHandle:iE,useInsertionEffect:iS,useLayoutEffect:iA,useMemo:iP,useReducer:a2,useRef:iv,useState:function(){return a2(a1)},useDebugValue:iI,useDeferredValue:function(e,t){return iR(aX(),aL.memoizedState,e,t)},useTransition:function(){var e=a2(a1)[0],t=aX().memoizedState;return["boolean"==typeof e?e:aJ(e),t]},useSyncExternalStore:a6,useId:iD,useHostTransitionStatus:ij,useFormState:ip,useActionState:ip,useOptimistic:function(e,t){return ir(aX(),aL,e,t)},useMemoCache:a0,useCacheRefresh:iz},iJ={readContext:rW,use:aZ,useCallback:iC,useContext:rW,useEffect:ix,useImperativeHandle:iE,useInsertionEffect:iS,useLayoutEffect:iA,useMemo:iP,useReducer:a4,useRef:iv,useState:function(){return a4(a1)},useDebugValue:iI,useDeferredValue:function(e,t){var n=aX();return null===aL?iL(n,e,t):iR(n,aL.memoizedState,e,t)},useTransition:function(){var e=a4(a1)[0],t=aX().memoizedState;return["boolean"==typeof e?e:aJ(e),t]},useSyncExternalStore:a6,useId:iD,useHostTransitionStatus:ij,useFormState:ig,useActionState:ig,useOptimistic:function(e,t){var n=aX();return null!==aL?ir(n,aL,e,t):(n.baseState=e,[e,n.queue.dispatch])},useMemoCache:a0,useCacheRefresh:iz},iZ=null,i0=0;function i1(e){var t=i0;return i0+=1,null===iZ&&(iZ=[]),al(iZ,e,t)}function i2(e,t){e.ref=void 0!==(t=t.props.ref)?t:null}function i3(e,t){if(t.$$typeof===m)throw Error(s(525));throw Error(s(31,"[object Object]"===(e=Object.prototype.toString.call(t))?"object with keys {"+Object.keys(t).join(", ")+"}":e))}function i4(e){return(0,e._init)(e._payload)}function i6(e){function t(t,n){if(e){var r=t.deletions;null===r?(t.deletions=[n],t.flags|=16):r.push(n)}}function n(n,r){if(!e)return null;for(;null!==r;)t(n,r),r=r.sibling;return null}function r(e){for(var t=new Map;null!==e;)null!==e.key?t.set(e.key,e):t.set(e.index,e),e=e.sibling;return t}function a(e,t){return(e=ri(e,t)).index=0,e.sibling=null,e}function i(t,n,r){return(t.index=r,e)?null!==(r=t.alternate)?(r=r.index)<n?(t.flags|=0x4000002,n):r:(t.flags|=0x4000002,n):(t.flags|=1048576,n)}function o(t){return e&&null===t.alternate&&(t.flags|=0x4000002),t}function l(e,t,n,r){return null===t||6!==t.tag?(t=ru(n,e.mode,r)).return=e:(t=a(t,n)).return=e,t}function u(e,t,n,r){var i=n.type;return i===y?d(e,t,n.props.children,r,n.key):(null!==t&&(t.elementType===i||"object"==typeof i&&null!==i&&i.$$typeof===E&&i4(i)===t.type)?i2(t=a(t,n.props),n):i2(t=rs(n.type,n.key,n.props,null,e.mode,r),n),t.return=e,t)}function c(e,t,n,r){return null===t||4!==t.tag||t.stateNode.containerInfo!==n.containerInfo||t.stateNode.implementation!==n.implementation?(t=rc(n,e.mode,r)).return=e:(t=a(t,n.children||[])).return=e,t}function d(e,t,n,r,i){return null===t||7!==t.tag?(t=rl(n,e.mode,r,i)).return=e:(t=a(t,n)).return=e,t}function p(e,t,n){if("string"==typeof t&&""!==t||"number"==typeof t||"bigint"==typeof t)return(t=ru(""+t,e.mode,n)).return=e,t;if("object"==typeof t&&null!==t){switch(t.$$typeof){case h:return i2(n=rs(t.type,t.key,t.props,null,e.mode,n),t),n.return=e,n;case g:return(t=rc(t,e.mode,n)).return=e,t;case E:return p(e,t=(0,t._init)(t._payload),n)}if(M(t)||L(t))return(t=rl(t,e.mode,n,null)).return=e,t;if("function"==typeof t.then)return p(e,i1(t),n);if(t.$$typeof===k)return p(e,rG(e,t),n);i3(e,t)}return null}function f(e,t,n,r){var a=null!==t?t.key:null;if("string"==typeof n&&""!==n||"number"==typeof n||"bigint"==typeof n)return null!==a?null:l(e,t,""+n,r);if("object"==typeof n&&null!==n){switch(n.$$typeof){case h:return n.key===a?u(e,t,n,r):null;case g:return n.key===a?c(e,t,n,r):null;case E:return f(e,t,n=(a=n._init)(n._payload),r)}if(M(n)||L(n))return null!==a?null:d(e,t,n,r,null);if("function"==typeof n.then)return f(e,t,i1(n),r);if(n.$$typeof===k)return f(e,t,rG(e,n),r);i3(e,n)}return null}function m(e,t,n,r,a){if("string"==typeof r&&""!==r||"number"==typeof r||"bigint"==typeof r)return l(t,e=e.get(n)||null,""+r,a);if("object"==typeof r&&null!==r){switch(r.$$typeof){case h:return u(t,e=e.get(null===r.key?n:r.key)||null,r,a);case g:return c(t,e=e.get(null===r.key?n:r.key)||null,r,a);case E:return m(e,t,n,r=(0,r._init)(r._payload),a)}if(M(r)||L(r))return d(t,e=e.get(n)||null,r,a,null);if("function"==typeof r.then)return m(e,t,n,i1(r),a);if(r.$$typeof===k)return m(e,t,n,rG(t,r),a);i3(t,r)}return null}return function(l,u,c,d){try{i0=0;var b=function l(u,c,d,b){if("object"==typeof d&&null!==d&&d.type===y&&null===d.key&&(d=d.props.children),"object"==typeof d&&null!==d){switch(d.$$typeof){case h:e:{for(var v=d.key;null!==c;){if(c.key===v){if((v=d.type)===y){if(7===c.tag){n(u,c.sibling),(b=a(c,d.props.children)).return=u,u=b;break e}}else if(c.elementType===v||"object"==typeof v&&null!==v&&v.$$typeof===E&&i4(v)===c.type){n(u,c.sibling),i2(b=a(c,d.props),d),b.return=u,u=b;break e}n(u,c);break}t(u,c),c=c.sibling}d.type===y?(b=rl(d.props.children,u.mode,b,d.key)).return=u:(i2(b=rs(d.type,d.key,d.props,null,u.mode,b),d),b.return=u),u=b}return o(u);case g:e:{for(v=d.key;null!==c;){if(c.key===v)if(4===c.tag&&c.stateNode.containerInfo===d.containerInfo&&c.stateNode.implementation===d.implementation){n(u,c.sibling),(b=a(c,d.children||[])).return=u,u=b;break e}else{n(u,c);break}t(u,c),c=c.sibling}(b=rc(d,u.mode,b)).return=u,u=b}return o(u);case E:return l(u,c,d=(v=d._init)(d._payload),b)}if(M(d))return function(a,o,s,l){for(var u=null,c=null,d=o,h=o=0,g=null;null!==d&&h<s.length;h++){d.index>h?(g=d,d=null):g=d.sibling;var y=f(a,d,s[h],l);if(null===y){null===d&&(d=g);break}e&&d&&null===y.alternate&&t(a,d),o=i(y,o,h),null===c?u=y:c.sibling=y,c=y,d=g}if(h===s.length)return n(a,d),rT&&rw(a,h),u;if(null===d){for(;h<s.length;h++)null!==(d=p(a,s[h],l))&&(o=i(d,o,h),null===c?u=d:c.sibling=d,c=d);return rT&&rw(a,h),u}for(d=r(d);h<s.length;h++)null!==(g=m(d,a,h,s[h],l))&&(e&&null!==g.alternate&&d.delete(null===g.key?h:g.key),o=i(g,o,h),null===c?u=g:c.sibling=g,c=g);return e&&d.forEach(function(e){return t(a,e)}),rT&&rw(a,h),u}(u,c,d,b);if(L(d)){if("function"!=typeof(v=L(d)))throw Error(s(150));return function(a,o,l,u){if(null==l)throw Error(s(151));for(var c=null,d=null,h=o,g=o=0,y=null,b=l.next();null!==h&&!b.done;g++,b=l.next()){h.index>g?(y=h,h=null):y=h.sibling;var v=f(a,h,b.value,u);if(null===v){null===h&&(h=y);break}e&&h&&null===v.alternate&&t(a,h),o=i(v,o,g),null===d?c=v:d.sibling=v,d=v,h=y}if(b.done)return n(a,h),rT&&rw(a,g),c;if(null===h){for(;!b.done;g++,b=l.next())null!==(b=p(a,b.value,u))&&(o=i(b,o,g),null===d?c=b:d.sibling=b,d=b);return rT&&rw(a,g),c}for(h=r(h);!b.done;g++,b=l.next())null!==(b=m(h,a,g,b.value,u))&&(e&&null!==b.alternate&&h.delete(null===b.key?g:b.key),o=i(b,o,g),null===d?c=b:d.sibling=b,d=b);return e&&h.forEach(function(e){return t(a,e)}),rT&&rw(a,g),c}(u,c,d=v.call(d),b)}if("function"==typeof d.then)return l(u,c,i1(d),b);if(d.$$typeof===k)return l(u,c,rG(u,d),b);i3(u,d)}return"string"==typeof d&&""!==d||"number"==typeof d||"bigint"==typeof d?(d=""+d,null!==c&&6===c.tag?(n(u,c.sibling),(b=a(c,d)).return=u):(n(u,c),(b=ru(d,u.mode,b)).return=u),o(u=b)):n(u,c)}(l,u,c,d);return iZ=null,b}catch(e){if(e===an||e===aa)throw e;var v=rr(29,e,null,l.mode);return v.lanes=d,v.return=l,v}finally{}}}var i5=i6(!0),i8=i6(!1),i9=D(null),i7=null;function oe(e){var t=e.alternate;F(oa,1&oa.current),F(i9,e),null===i7&&(null===t||null!==aS.current?i7=e:null!==t.memoizedState&&(i7=e))}function ot(e){if(22===e.tag){if(F(oa,oa.current),F(i9,e),null===i7){var t=e.alternate;null!==t&&null!==t.memoizedState&&(i7=e)}}else on(e)}function on(){F(oa,oa.current),F(i9,i9.current)}function or(e){z(i9),i7===e&&(i7=null),z(oa)}var oa=D(0);function oi(e){for(var t=e;null!==t;){if(13===t.tag){var n=t.memoizedState;if(null!==n&&(null===(n=n.dehydrated)||"$?"===n.data||uk(n)))return t}else if(19===t.tag&&void 0!==t.memoizedProps.revealOrder){if(0!=(128&t.flags))return t}else if(null!==t.child){t.child.return=t,t=t.child;continue}if(t===e)break;for(;null===t.sibling;){if(null===t.return||t.return===e)return null;t=t.return}t.sibling.return=t.return,t=t.sibling}return null}function oo(e,t,n,r){n=null==(n=n(r,t=e.memoizedState))?t:f({},t,n),e.memoizedState=n,0===e.lanes&&(e.updateQueue.baseState=n)}var os={enqueueSetState:function(e,t,n){e=e._reactInternals;var r=s7(),a=ah(r);a.payload=t,null!=n&&(a.callback=n),null!==(t=ag(e,a,r))&&(lt(t,e,r),ay(t,e,r))},enqueueReplaceState:function(e,t,n){e=e._reactInternals;var r=s7(),a=ah(r);a.tag=1,a.payload=t,null!=n&&(a.callback=n),null!==(t=ag(e,a,r))&&(lt(t,e,r),ay(t,e,r))},enqueueForceUpdate:function(e,t){e=e._reactInternals;var n=s7(),r=ah(n);r.tag=2,null!=t&&(r.callback=t),null!==(t=ag(e,r,n))&&(lt(t,e,n),ay(t,e,n))}};function ol(e,t,n,r,a,i,o){return"function"==typeof(e=e.stateNode).shouldComponentUpdate?e.shouldComponentUpdate(r,i,o):!t.prototype||!t.prototype.isPureReactComponent||!nI(n,r)||!nI(a,i)}function ou(e,t,n,r){e=t.state,"function"==typeof t.componentWillReceiveProps&&t.componentWillReceiveProps(n,r),"function"==typeof t.UNSAFE_componentWillReceiveProps&&t.UNSAFE_componentWillReceiveProps(n,r),t.state!==e&&os.enqueueReplaceState(t,t.state,null)}function oc(e,t){var n=t;if("ref"in t)for(var r in n={},t)"ref"!==r&&(n[r]=t[r]);if(e=e.defaultProps)for(var a in n===t&&(n=f({},n)),e)void 0===n[a]&&(n[a]=e[a]);return n}var od="function"==typeof reportError?reportError:function(e){if("object"==typeof window&&"function"==typeof window.ErrorEvent){var t=new window.ErrorEvent("error",{bubbles:!0,cancelable:!0,message:"object"==typeof e&&null!==e&&"string"==typeof e.message?String(e.message):String(e),error:e});if(!window.dispatchEvent(t))return}console.error(e)};function op(e){od(e)}function of(e){console.error(e)}function om(e){od(e)}function oh(e,t){try{(0,e.onUncaughtError)(t.value,{componentStack:t.stack})}catch(e){setTimeout(function(){throw e})}}function og(e,t,n){try{(0,e.onCaughtError)(n.value,{componentStack:n.stack,errorBoundary:1===t.tag?t.stateNode:null})}catch(e){setTimeout(function(){throw e})}}function oy(e,t,n){return(n=ah(n)).tag=3,n.payload={element:null},n.callback=function(){oh(e,t)},n}function ob(e){return(e=ah(e)).tag=3,e}function ov(e,t,n,r){var a=n.type.getDerivedStateFromError;if("function"==typeof a){var i=r.value;e.payload=function(){return a(i)},e.callback=function(){og(t,n,r)}}var o=n.stateNode;null!==o&&"function"==typeof o.componentDidCatch&&(e.callback=function(){og(t,n,r),"function"!=typeof a&&(null===sZ?sZ=new Set([this]):sZ.add(this));var e=r.stack;this.componentDidCatch(r.value,{componentStack:null!==e?e:""})})}var ow=Error(s(461)),o_=!1;function ok(e,t,n,r){t.child=null===e?i8(t,null,n,r):i5(t,e.child,n,r)}function ox(e,t,n,r,a){n=n.render;var i=t.ref;if("ref"in r){var o={};for(var s in r)"ref"!==s&&(o[s]=r[s])}else o=r;return(rQ(t),r=aB(e,t,n,o,i,a),s=aQ(),null===e||o_)?(rT&&s&&rk(t),t.flags|=1,ok(e,t,r,a),t.child):(aW(e,t,a),oq(e,t,a))}function oS(e,t,n,r,a){if(null===e){var i=n.type;return"function"!=typeof i||ra(i)||void 0!==i.defaultProps||null!==n.compare?((e=rs(n.type,null,r,t,t.mode,a)).ref=t.ref,e.return=t,t.child=e):(t.tag=15,t.type=i,oA(e,t,i,r,a))}if(i=e.child,!oV(e,a)){var o=i.memoizedProps;if((n=null!==(n=n.compare)?n:nI)(o,r)&&e.ref===t.ref)return oq(e,t,a)}return t.flags|=1,(e=ri(i,r)).ref=t.ref,e.return=t,t.child=e}function oA(e,t,n,r,a){if(null!==e){var i=e.memoizedProps;if(nI(i,r)&&e.ref===t.ref)if(o_=!1,t.pendingProps=r=i,!oV(e,a))return t.lanes=e.lanes,oq(e,t,a);else 0!=(131072&e.flags)&&(o_=!0)}return oC(e,t,n,r,a)}function oT(e,t,n){var r=t.pendingProps,a=r.children,i=null!==e?e.memoizedState:null;if("hidden"===r.mode){if(0!=(128&t.flags)){if(r=null!==i?i.baseLanes|n:n,null!==e){for(i=0,a=t.child=e.child;null!==a;)i=i|a.lanes|a.childLanes,a=a.sibling;t.childLanes=i&~r}else t.childLanes=0,t.child=null;return oE(e,t,r,n)}if(0==(0x20000000&n))return t.lanes=t.childLanes=0x20000000,oE(e,t,null!==i?i.baseLanes|n:n,n);t.memoizedState={baseLanes:0,cachePool:null},null!==e&&ae(t,null!==i?i.cachePool:null),null!==i?aT(t,i):aE(),ot(t)}else null!==i?(ae(t,i.cachePool),aT(t,i),on(t),t.memoizedState=null):(null!==e&&ae(t,null),aE(),on(t));return ok(e,t,a,n),t.child}function oE(e,t,n,r){var a=r7();return t.memoizedState={baseLanes:n,cachePool:a=null===a?null:{parent:rZ._currentValue,pool:a}},null!==e&&ae(t,null),aE(),ot(t),null!==e&&rV(e,t,r,!0),null}function oI(e,t){var n=t.ref;if(null===n)null!==e&&null!==e.ref&&(t.flags|=4194816);else{if("function"!=typeof n&&"object"!=typeof n)throw Error(s(284));(null===e||e.ref!==n)&&(t.flags|=4194816)}}function oC(e,t,n,r,a){return(rQ(t),n=aB(e,t,n,r,void 0,a),r=aQ(),null===e||o_)?(rT&&r&&rk(t),t.flags|=1,ok(e,t,n,a),t.child):(aW(e,t,a),oq(e,t,a))}function oP(e,t,n,r,a,i){return(rQ(t),t.updateQueue=null,n=aV(t,r,n,a),aq(e),r=aQ(),null===e||o_)?(rT&&r&&rk(t),t.flags|=1,ok(e,t,n,i),t.child):(aW(e,t,i),oq(e,t,i))}function oL(e,t,n,r,a){if(rQ(t),null===t.stateNode){var i=rt,o=n.contextType;"object"==typeof o&&null!==o&&(i=rW(o)),t.memoizedState=null!==(i=new n(r,i)).state&&void 0!==i.state?i.state:null,i.updater=os,t.stateNode=i,i._reactInternals=t,(i=t.stateNode).props=r,i.state=t.memoizedState,i.refs={},af(t),o=n.contextType,i.context="object"==typeof o&&null!==o?rW(o):rt,i.state=t.memoizedState,"function"==typeof(o=n.getDerivedStateFromProps)&&(oo(t,n,o,r),i.state=t.memoizedState),"function"==typeof n.getDerivedStateFromProps||"function"==typeof i.getSnapshotBeforeUpdate||"function"!=typeof i.UNSAFE_componentWillMount&&"function"!=typeof i.componentWillMount||(o=i.state,"function"==typeof i.componentWillMount&&i.componentWillMount(),"function"==typeof i.UNSAFE_componentWillMount&&i.UNSAFE_componentWillMount(),o!==i.state&&os.enqueueReplaceState(i,i.state,null),a_(t,r,i,a),aw(),i.state=t.memoizedState),"function"==typeof i.componentDidMount&&(t.flags|=4194308),r=!0}else if(null===e){i=t.stateNode;var s=t.memoizedProps,l=oc(n,s);i.props=l;var u=i.context,c=n.contextType;o=rt,"object"==typeof c&&null!==c&&(o=rW(c));var d=n.getDerivedStateFromProps;c="function"==typeof d||"function"==typeof i.getSnapshotBeforeUpdate,s=t.pendingProps!==s,c||"function"!=typeof i.UNSAFE_componentWillReceiveProps&&"function"!=typeof i.componentWillReceiveProps||(s||u!==o)&&ou(t,i,r,o),ap=!1;var p=t.memoizedState;i.state=p,a_(t,r,i,a),aw(),u=t.memoizedState,s||p!==u||ap?("function"==typeof d&&(oo(t,n,d,r),u=t.memoizedState),(l=ap||ol(t,n,l,r,p,u,o))?(c||"function"!=typeof i.UNSAFE_componentWillMount&&"function"!=typeof i.componentWillMount||("function"==typeof i.componentWillMount&&i.componentWillMount(),"function"==typeof i.UNSAFE_componentWillMount&&i.UNSAFE_componentWillMount()),"function"==typeof i.componentDidMount&&(t.flags|=4194308)):("function"==typeof i.componentDidMount&&(t.flags|=4194308),t.memoizedProps=r,t.memoizedState=u),i.props=r,i.state=u,i.context=o,r=l):("function"==typeof i.componentDidMount&&(t.flags|=4194308),r=!1)}else{i=t.stateNode,am(e,t),c=oc(n,o=t.memoizedProps),i.props=c,d=t.pendingProps,p=i.context,u=n.contextType,l=rt,"object"==typeof u&&null!==u&&(l=rW(u)),(u="function"==typeof(s=n.getDerivedStateFromProps)||"function"==typeof i.getSnapshotBeforeUpdate)||"function"!=typeof i.UNSAFE_componentWillReceiveProps&&"function"!=typeof i.componentWillReceiveProps||(o!==d||p!==l)&&ou(t,i,r,l),ap=!1,p=t.memoizedState,i.state=p,a_(t,r,i,a),aw();var f=t.memoizedState;o!==d||p!==f||ap||null!==e&&null!==e.dependencies&&rH(e.dependencies)?("function"==typeof s&&(oo(t,n,s,r),f=t.memoizedState),(c=ap||ol(t,n,c,r,p,f,l)||null!==e&&null!==e.dependencies&&rH(e.dependencies))?(u||"function"!=typeof i.UNSAFE_componentWillUpdate&&"function"!=typeof i.componentWillUpdate||("function"==typeof i.componentWillUpdate&&i.componentWillUpdate(r,f,l),"function"==typeof i.UNSAFE_componentWillUpdate&&i.UNSAFE_componentWillUpdate(r,f,l)),"function"==typeof i.componentDidUpdate&&(t.flags|=4),"function"==typeof i.getSnapshotBeforeUpdate&&(t.flags|=1024)):("function"!=typeof i.componentDidUpdate||o===e.memoizedProps&&p===e.memoizedState||(t.flags|=4),"function"!=typeof i.getSnapshotBeforeUpdate||o===e.memoizedProps&&p===e.memoizedState||(t.flags|=1024),t.memoizedProps=r,t.memoizedState=f),i.props=r,i.state=f,i.context=l,r=c):("function"!=typeof i.componentDidUpdate||o===e.memoizedProps&&p===e.memoizedState||(t.flags|=4),"function"!=typeof i.getSnapshotBeforeUpdate||o===e.memoizedProps&&p===e.memoizedState||(t.flags|=1024),r=!1)}return i=r,oI(e,t),r=0!=(128&t.flags),i||r?(i=t.stateNode,n=r&&"function"!=typeof n.getDerivedStateFromError?null:i.render(),t.flags|=1,null!==e&&r?(t.child=i5(t,e.child,null,a),t.child=i5(t,null,n,a)):ok(e,t,n,a),t.memoizedState=i.state,e=t.child):e=oq(e,t,a),e}function oR(e,t,n,r){return rN(),t.flags|=256,ok(e,t,n,r),t.child}var oM={dehydrated:null,treeContext:null,retryLane:0,hydrationErrors:null};function oN(e){return{baseLanes:e,cachePool:at()}}function oU(e,t,n){return e=null!==e?e.childLanes&~n:0,t&&(e|=sH),e}function oO(e,t,n){var r,a=t.pendingProps,i=!1,o=0!=(128&t.flags);if((r=o)||(r=(null===e||null!==e.memoizedState)&&0!=(2&oa.current)),r&&(i=!0,t.flags&=-129),r=0!=(32&t.flags),t.flags&=-33,null===e){if(rT){if(i?oe(t):on(t),rT){var l,u=rA;if(l=u){n:{for(l=u,u=rI;8!==l.nodeType;)if(!u||null===(l=ux(l.nextSibling))){u=null;break n}u=l}null!==u?(t.memoizedState={dehydrated:u,treeContext:null!==ry?{id:rb,overflow:rv}:null,retryLane:0x20000000,hydrationErrors:null},(l=rr(18,null,null,0)).stateNode=u,l.return=t,t.child=l,rS=t,rA=null,l=!0):l=!1}l||rP(t)}if(null!==(u=t.memoizedState)&&null!==(u=u.dehydrated))return uk(u)?t.lanes=32:t.lanes=0x20000000,null;or(t)}return(u=a.children,a=a.fallback,i)?(on(t),u=oj({mode:"hidden",children:u},i=t.mode),a=rl(a,i,n,null),u.return=t,a.return=t,u.sibling=a,t.child=u,(i=t.child).memoizedState=oN(n),i.childLanes=oU(e,r,n),t.memoizedState=oM,a):(oe(t),o$(t,u))}if(null!==(l=e.memoizedState)&&null!==(u=l.dehydrated)){if(o)256&t.flags?(oe(t),t.flags&=-257,t=oD(e,t,n)):null!==t.memoizedState?(on(t),t.child=e.child,t.flags|=128,t=null):(on(t),i=a.fallback,u=t.mode,a=oj({mode:"visible",children:a.children},u),i=rl(i,u,n,null),i.flags|=2,a.return=t,i.return=t,a.sibling=i,t.child=a,i5(t,e.child,null,n),(a=t.child).memoizedState=oN(n),a.childLanes=oU(e,r,n),t.memoizedState=oM,t=i);else if(oe(t),uk(u)){if(r=u.nextSibling&&u.nextSibling.dataset)var c=r.dgst;r=c,(a=Error(s(419))).stack="",a.digest=r,rO({value:a,source:null,stack:null}),t=oD(e,t,n)}else if(o_||rV(e,t,n,!1),r=0!=(n&e.childLanes),o_||r){if(null!==(r=sR)&&0!==(a=0!=((a=0!=(42&(a=n&-n))?1:eE(a))&(r.suspendedLanes|n))?0:a)&&a!==l.retryLane)throw l.retryLane=a,n9(e,a),lt(r,e,a),ow;"$?"===u.data||ld(),t=oD(e,t,n)}else"$?"===u.data?(t.flags|=192,t.child=e.child,t=null):(e=l.treeContext,rA=ux(u.nextSibling),rS=t,rT=!0,rE=null,rI=!1,null!==e&&(rh[rg++]=rb,rh[rg++]=rv,rh[rg++]=ry,rb=e.id,rv=e.overflow,ry=t),t=o$(t,a.children),t.flags|=4096);return t}return i?(on(t),i=a.fallback,u=t.mode,c=(l=e.child).sibling,(a=ri(l,{mode:"hidden",children:a.children})).subtreeFlags=0x3e00000&l.subtreeFlags,null!==c?i=ri(c,i):(i=rl(i,u,n,null),i.flags|=2),i.return=t,a.return=t,a.sibling=i,t.child=a,a=i,i=t.child,null===(u=e.child.memoizedState)?u=oN(n):(null!==(l=u.cachePool)?(c=rZ._currentValue,l=l.parent!==c?{parent:c,pool:c}:l):l=at(),u={baseLanes:u.baseLanes|n,cachePool:l}),i.memoizedState=u,i.childLanes=oU(e,r,n),t.memoizedState=oM,a):(oe(t),e=(n=e.child).sibling,(n=ri(n,{mode:"visible",children:a.children})).return=t,n.sibling=null,null!==e&&(null===(r=t.deletions)?(t.deletions=[e],t.flags|=16):r.push(e)),t.child=n,t.memoizedState=null,n)}function o$(e,t){return(t=oj({mode:"visible",children:t},e.mode)).return=e,e.child=t}function oj(e,t){return(e=rr(22,e,null,t)).lanes=0,e.stateNode={_visibility:1,_pendingMarkers:null,_retryCache:null,_transitions:null},e}function oD(e,t,n){return i5(t,e.child,null,n),e=o$(t,t.pendingProps.children),e.flags|=2,t.memoizedState=null,e}function oz(e,t,n){e.lanes|=t;var r=e.alternate;null!==r&&(r.lanes|=t),rB(e.return,t,n)}function oF(e,t,n,r,a){var i=e.memoizedState;null===i?e.memoizedState={isBackwards:t,rendering:null,renderingStartTime:0,last:r,tail:n,tailMode:a}:(i.isBackwards=t,i.rendering=null,i.renderingStartTime=0,i.last=r,i.tail=n,i.tailMode=a)}function oB(e,t,n){var r=t.pendingProps,a=r.revealOrder,i=r.tail;if(ok(e,t,r.children,n),0!=(2&(r=oa.current)))r=1&r|2,t.flags|=128;else{if(null!==e&&0!=(128&e.flags))e:for(e=t.child;null!==e;){if(13===e.tag)null!==e.memoizedState&&oz(e,n,t);else if(19===e.tag)oz(e,n,t);else if(null!==e.child){e.child.return=e,e=e.child;continue}if(e===t)break;for(;null===e.sibling;){if(null===e.return||e.return===t)break e;e=e.return}e.sibling.return=e.return,e=e.sibling}r&=1}switch(F(oa,r),a){case"forwards":for(a=null,n=t.child;null!==n;)null!==(e=n.alternate)&&null===oi(e)&&(a=n),n=n.sibling;null===(n=a)?(a=t.child,t.child=null):(a=n.sibling,n.sibling=null),oF(t,!1,a,n,i);break;case"backwards":for(n=null,a=t.child,t.child=null;null!==a;){if(null!==(e=a.alternate)&&null===oi(e)){t.child=a;break}e=a.sibling,a.sibling=n,n=a,a=e}oF(t,!0,n,null,i);break;case"together":oF(t,!1,null,null,void 0);break;default:t.memoizedState=null}return t.child}function oq(e,t,n){if(null!==e&&(t.dependencies=e.dependencies),sB|=t.lanes,0==(n&t.childLanes)){if(null===e)return null;else if(rV(e,t,n,!1),0==(n&t.childLanes))return null}if(null!==e&&t.child!==e.child)throw Error(s(153));if(null!==t.child){for(n=ri(e=t.child,e.pendingProps),t.child=n,n.return=t;null!==e.sibling;)e=e.sibling,(n=n.sibling=ri(e,e.pendingProps)).return=t;n.sibling=null}return t.child}function oV(e,t){return 0!=(e.lanes&t)||!!(null!==(e=e.dependencies)&&rH(e))}function oH(e,t,n){if(null!==e)if(e.memoizedProps!==t.pendingProps)o_=!0;else{if(!oV(e,n)&&0==(128&t.flags))return o_=!1,function(e,t,n){switch(t.tag){case 3:Q(t,t.stateNode.containerInfo),rz(t,rZ,e.memoizedState.cache),rN();break;case 27:case 5:G(t);break;case 4:Q(t,t.stateNode.containerInfo);break;case 10:rz(t,t.type,t.memoizedProps.value);break;case 13:var r=t.memoizedState;if(null!==r){if(null!==r.dehydrated)return oe(t),t.flags|=128,null;if(0!=(n&t.child.childLanes))return oO(e,t,n);return oe(t),null!==(e=oq(e,t,n))?e.sibling:null}oe(t);break;case 19:var a=0!=(128&e.flags);if((r=0!=(n&t.childLanes))||(rV(e,t,n,!1),r=0!=(n&t.childLanes)),a){if(r)return oB(e,t,n);t.flags|=128}if(null!==(a=t.memoizedState)&&(a.rendering=null,a.tail=null,a.lastEffect=null),F(oa,oa.current),!r)return null;break;case 22:case 23:return t.lanes=0,oT(e,t,n);case 24:rz(t,rZ,e.memoizedState.cache)}return oq(e,t,n)}(e,t,n);o_=0!=(131072&e.flags)}else o_=!1,rT&&0!=(1048576&t.flags)&&r_(t,rm,t.index);switch(t.lanes=0,t.tag){case 16:e:{e=t.pendingProps;var r=t.elementType,a=r._init;if(r=a(r._payload),t.type=r,"function"==typeof r)ra(r)?(e=oc(r,e),t.tag=1,t=oL(null,t,r,e,n)):(t.tag=0,t=oC(null,t,r,e,n));else{if(null!=r){if((a=r.$$typeof)===x){t.tag=11,t=ox(null,t,r,e,n);break e}else if(a===T){t.tag=14,t=oS(null,t,r,e,n);break e}}throw Error(s(306,t=function e(t){if(null==t)return null;if("function"==typeof t)return t.$$typeof===R?null:t.displayName||t.name||null;if("string"==typeof t)return t;switch(t){case y:return"Fragment";case v:return"Profiler";case b:return"StrictMode";case S:return"Suspense";case A:return"SuspenseList";case I:return"Activity"}if("object"==typeof t)switch(t.$$typeof){case g:return"Portal";case k:return(t.displayName||"Context")+".Provider";case _:return(t._context.displayName||"Context")+".Consumer";case x:var n=t.render;return(t=t.displayName)||(t=""!==(t=n.displayName||n.name||"")?"ForwardRef("+t+")":"ForwardRef"),t;case T:return null!==(n=t.displayName||null)?n:e(t.type)||"Memo";case E:n=t._payload,t=t._init;try{return e(t(n))}catch(e){}}return null}(r)||r,""))}}return t;case 0:return oC(e,t,t.type,t.pendingProps,n);case 1:return a=oc(r=t.type,t.pendingProps),oL(e,t,r,a,n);case 3:e:{if(Q(t,t.stateNode.containerInfo),null===e)throw Error(s(387));r=t.pendingProps;var i=t.memoizedState;a=i.element,am(e,t),a_(t,r,null,n);var o=t.memoizedState;if(rz(t,rZ,r=o.cache),r!==i.cache&&rq(t,[rZ],n,!0),aw(),r=o.element,i.isDehydrated)if(i={element:r,isDehydrated:!1,cache:o.cache},t.updateQueue.baseState=i,t.memoizedState=i,256&t.flags){t=oR(e,t,r,n);break e}else if(r!==a){rO(a=n1(Error(s(424)),t)),t=oR(e,t,r,n);break e}else for(rA=ux((e=9===(e=t.stateNode.containerInfo).nodeType?e.body:"HTML"===e.nodeName?e.ownerDocument.body:e).firstChild),rS=t,rT=!0,rE=null,rI=!0,n=i8(t,null,r,n),t.child=n;n;)n.flags=-3&n.flags|4096,n=n.sibling;else{if(rN(),r===a){t=oq(e,t,n);break e}ok(e,t,r,n)}t=t.child}return t;case 26:return oI(e,t),null===e?(n=uN(t.type,null,t.pendingProps,null))?t.memoizedState=n:rT||(n=t.type,e=t.pendingProps,(r=uu(V.current).createElement(n))[eL]=t,r[eR]=e,uo(r,n,e),eV(r),t.stateNode=r):t.memoizedState=uN(t.type,e.memoizedProps,t.pendingProps,e.memoizedState),null;case 27:return G(t),null===e&&rT&&(r=t.stateNode=uT(t.type,t.pendingProps,V.current),rS=t,rI=!0,a=rA,uv(t.type)?(uS=a,rA=ux(r.firstChild)):rA=a),ok(e,t,t.pendingProps.children,n),oI(e,t),null===e&&(t.flags|=4194304),t.child;case 5:return null===e&&rT&&((a=r=rA)&&(null!==(r=function(e,t,n,r){for(;1===e.nodeType;){if(e.nodeName.toLowerCase()!==t.toLowerCase()){if(!r&&("INPUT"!==e.nodeName||"hidden"!==e.type))break}else if(r){if(!e[ej])switch(t){case"meta":if(!e.hasAttribute("itemprop"))break;return e;case"link":if("stylesheet"===(a=e.getAttribute("rel"))&&e.hasAttribute("data-precedence")||a!==n.rel||e.getAttribute("href")!==(null==n.href||""===n.href?null:n.href)||e.getAttribute("crossorigin")!==(null==n.crossOrigin?null:n.crossOrigin)||e.getAttribute("title")!==(null==n.title?null:n.title))break;return e;case"style":if(e.hasAttribute("data-precedence"))break;return e;case"script":if(((a=e.getAttribute("src"))!==(null==n.src?null:n.src)||e.getAttribute("type")!==(null==n.type?null:n.type)||e.getAttribute("crossorigin")!==(null==n.crossOrigin?null:n.crossOrigin))&&a&&e.hasAttribute("async")&&!e.hasAttribute("itemprop"))break;return e;default:return e}}else{if("input"!==t||"hidden"!==e.type)return e;var a=null==n.name?null:""+n.name;if("hidden"===n.type&&e.getAttribute("name")===a)return e}if(null===(e=ux(e.nextSibling)))break}return null}(r,t.type,t.pendingProps,rI))?(t.stateNode=r,rS=t,rA=ux(r.firstChild),rI=!1,a=!0):a=!1),a||rP(t)),G(t),a=t.type,i=t.pendingProps,o=null!==e?e.memoizedProps:null,r=i.children,up(a,i)?r=null:null!==o&&up(a,o)&&(t.flags|=32),null!==t.memoizedState&&(u0._currentValue=a=aB(e,t,aH,null,null,n)),oI(e,t),ok(e,t,r,n),t.child;case 6:return null===e&&rT&&((e=n=rA)&&(null!==(n=function(e,t,n){if(""===t)return null;for(;3!==e.nodeType;)if((1!==e.nodeType||"INPUT"!==e.nodeName||"hidden"!==e.type)&&!n||null===(e=ux(e.nextSibling)))return null;return e}(n,t.pendingProps,rI))?(t.stateNode=n,rS=t,rA=null,e=!0):e=!1),e||rP(t)),null;case 13:return oO(e,t,n);case 4:return Q(t,t.stateNode.containerInfo),r=t.pendingProps,null===e?t.child=i5(t,null,r,n):ok(e,t,r,n),t.child;case 11:return ox(e,t,t.type,t.pendingProps,n);case 7:return ok(e,t,t.pendingProps,n),t.child;case 8:case 12:return ok(e,t,t.pendingProps.children,n),t.child;case 10:return r=t.pendingProps,rz(t,t.type,r.value),ok(e,t,r.children,n),t.child;case 9:return a=t.type._context,r=t.pendingProps.children,rQ(t),r=r(a=rW(a)),t.flags|=1,ok(e,t,r,n),t.child;case 14:return oS(e,t,t.type,t.pendingProps,n);case 15:return oA(e,t,t.type,t.pendingProps,n);case 19:return oB(e,t,n);case 31:return r=t.pendingProps,n=t.mode,r={mode:r.mode,children:r.children},null===e?(n=oj(r,n)).ref=t.ref:(n=ri(e.child,r)).ref=t.ref,t.child=n,n.return=t,t=n;case 22:return oT(e,t,n);case 24:return rQ(t),r=rW(rZ),null===e?(null===(a=r7())&&(a=sR,i=r0(),a.pooledCache=i,i.refCount++,null!==i&&(a.pooledCacheLanes|=n),a=i),t.memoizedState={parent:r,cache:a},af(t),rz(t,rZ,a)):(0!=(e.lanes&n)&&(am(e,t),a_(t,null,null,n),aw()),a=e.memoizedState,i=t.memoizedState,a.parent!==r?(a={parent:r,cache:r},t.memoizedState=a,0===t.lanes&&(t.memoizedState=t.updateQueue.baseState=a),rz(t,rZ,r)):(rz(t,rZ,r=i.cache),r!==a.cache&&rq(t,[rZ],n,!0))),ok(e,t,t.pendingProps.children,n),t.child;case 29:throw t.pendingProps}throw Error(s(156,t.tag))}function oQ(e){e.flags|=4}function oW(e,t){if("stylesheet"!==t.type||0!=(4&t.state.loading))e.flags&=-0x1000001;else if(e.flags|=0x1000000,!uW(t)){if(null!==(t=i9.current)&&((4194048&sN)===sN?null!==i7:(0x3c00000&sN)!==sN&&0==(0x20000000&sN)||t!==i7))throw au=ai,ar;e.flags|=8192}}function oG(e,t){null!==t&&(e.flags|=4),16384&e.flags&&(t=22!==e.tag?ek():0x20000000,e.lanes|=t,sQ|=t)}function oK(e,t){if(!rT)switch(e.tailMode){case"hidden":t=e.tail;for(var n=null;null!==t;)null!==t.alternate&&(n=t),t=t.sibling;null===n?e.tail=null:n.sibling=null;break;case"collapsed":n=e.tail;for(var r=null;null!==n;)null!==n.alternate&&(r=n),n=n.sibling;null===r?t||null===e.tail?e.tail=null:e.tail.sibling=null:r.sibling=null}}function oX(e){var t=null!==e.alternate&&e.alternate.child===e.child,n=0,r=0;if(t)for(var a=e.child;null!==a;)n|=a.lanes|a.childLanes,r|=0x3e00000&a.subtreeFlags,r|=0x3e00000&a.flags,a.return=e,a=a.sibling;else for(a=e.child;null!==a;)n|=a.lanes|a.childLanes,r|=a.subtreeFlags,r|=a.flags,a.return=e,a=a.sibling;return e.subtreeFlags|=r,e.childLanes=n,t}function oY(e,t){switch(rx(t),t.tag){case 3:rF(rZ),W();break;case 26:case 27:case 5:K(t);break;case 4:W();break;case 13:or(t);break;case 19:z(oa);break;case 10:rF(t.type);break;case 22:case 23:or(t),aI(),null!==e&&z(r9);break;case 24:rF(rZ)}}function oJ(e,t){try{var n=t.updateQueue,r=null!==n?n.lastEffect:null;if(null!==r){var a=r.next;n=a;do{if((n.tag&e)===e){r=void 0;var i=n.create;n.inst.destroy=r=i()}n=n.next}while(n!==a)}}catch(e){lT(t,t.return,e)}}function oZ(e,t,n){try{var r=t.updateQueue,a=null!==r?r.lastEffect:null;if(null!==a){var i=a.next;r=i;do{if((r.tag&e)===e){var o=r.inst,s=o.destroy;if(void 0!==s){o.destroy=void 0,a=t;try{s()}catch(e){lT(a,n,e)}}}r=r.next}while(r!==i)}}catch(e){lT(t,t.return,e)}}function o0(e){var t=e.updateQueue;if(null!==t){var n=e.stateNode;try{ax(t,n)}catch(t){lT(e,e.return,t)}}}function o1(e,t,n){n.props=oc(e.type,e.memoizedProps),n.state=e.memoizedState;try{n.componentWillUnmount()}catch(n){lT(e,t,n)}}function o2(e,t){try{var n=e.ref;if(null!==n){switch(e.tag){case 26:case 27:case 5:var r=e.stateNode;break;default:r=e.stateNode}"function"==typeof n?e.refCleanup=n(r):n.current=r}}catch(n){lT(e,t,n)}}function o3(e,t){var n=e.ref,r=e.refCleanup;if(null!==n)if("function"==typeof r)try{r()}catch(n){lT(e,t,n)}finally{e.refCleanup=null,null!=(e=e.alternate)&&(e.refCleanup=null)}else if("function"==typeof n)try{n(null)}catch(n){lT(e,t,n)}else n.current=null}function o4(e){var t=e.type,n=e.memoizedProps,r=e.stateNode;try{switch(t){case"button":case"input":case"select":case"textarea":n.autoFocus&&r.focus();break;case"img":n.src?r.src=n.src:n.srcSet&&(r.srcset=n.srcSet)}}catch(t){lT(e,e.return,t)}}function o6(e,t,n){try{var r=e.stateNode;(function(e,t,n,r){switch(t){case"div":case"span":case"svg":case"path":case"a":case"g":case"p":case"li":break;case"input":var a=null,i=null,o=null,l=null,u=null,c=null,d=null;for(m in n){var p=n[m];if(n.hasOwnProperty(m)&&null!=p)switch(m){case"checked":case"value":break;case"defaultValue":u=p;default:r.hasOwnProperty(m)||ua(e,t,m,null,r,p)}}for(var f in r){var m=r[f];if(p=n[f],r.hasOwnProperty(f)&&(null!=m||null!=p))switch(f){case"type":i=m;break;case"name":a=m;break;case"checked":c=m;break;case"defaultChecked":d=m;break;case"value":o=m;break;case"defaultValue":l=m;break;case"children":case"dangerouslySetInnerHTML":if(null!=m)throw Error(s(137,t));break;default:m!==p&&ua(e,t,f,m,r,p)}}tn(e,o,l,u,c,d,i,a);return;case"select":for(i in m=o=l=f=null,n)if(u=n[i],n.hasOwnProperty(i)&&null!=u)switch(i){case"value":break;case"multiple":m=u;default:r.hasOwnProperty(i)||ua(e,t,i,null,r,u)}for(a in r)if(i=r[a],u=n[a],r.hasOwnProperty(a)&&(null!=i||null!=u))switch(a){case"value":f=i;break;case"defaultValue":l=i;break;case"multiple":o=i;default:i!==u&&ua(e,t,a,i,r,u)}t=l,n=o,r=m,null!=f?ti(e,!!n,f,!1):!!r!=!!n&&(null!=t?ti(e,!!n,t,!0):ti(e,!!n,n?[]:"",!1));return;case"textarea":for(l in m=f=null,n)if(a=n[l],n.hasOwnProperty(l)&&null!=a&&!r.hasOwnProperty(l))switch(l){case"value":case"children":break;default:ua(e,t,l,null,r,a)}for(o in r)if(a=r[o],i=n[o],r.hasOwnProperty(o)&&(null!=a||null!=i))switch(o){case"value":f=a;break;case"defaultValue":m=a;break;case"children":break;case"dangerouslySetInnerHTML":if(null!=a)throw Error(s(91));break;default:a!==i&&ua(e,t,o,a,r,i)}to(e,f,m);return;case"option":for(var h in n)f=n[h],n.hasOwnProperty(h)&&null!=f&&!r.hasOwnProperty(h)&&("selected"===h?e.selected=!1:ua(e,t,h,null,r,f));for(u in r)f=r[u],m=n[u],r.hasOwnProperty(u)&&f!==m&&(null!=f||null!=m)&&("selected"===u?e.selected=f&&"function"!=typeof f&&"symbol"!=typeof f:ua(e,t,u,f,r,m));return;case"img":case"link":case"area":case"base":case"br":case"col":case"embed":case"hr":case"keygen":case"meta":case"param":case"source":case"track":case"wbr":case"menuitem":for(var g in n)f=n[g],n.hasOwnProperty(g)&&null!=f&&!r.hasOwnProperty(g)&&ua(e,t,g,null,r,f);for(c in r)if(f=r[c],m=n[c],r.hasOwnProperty(c)&&f!==m&&(null!=f||null!=m))switch(c){case"children":case"dangerouslySetInnerHTML":if(null!=f)throw Error(s(137,t));break;default:ua(e,t,c,f,r,m)}return;default:if(tp(t)){for(var y in n)f=n[y],n.hasOwnProperty(y)&&void 0!==f&&!r.hasOwnProperty(y)&&ui(e,t,y,void 0,r,f);for(d in r)f=r[d],m=n[d],r.hasOwnProperty(d)&&f!==m&&(void 0!==f||void 0!==m)&&ui(e,t,d,f,r,m);return}}for(var b in n)f=n[b],n.hasOwnProperty(b)&&null!=f&&!r.hasOwnProperty(b)&&ua(e,t,b,null,r,f);for(p in r)f=r[p],m=n[p],r.hasOwnProperty(p)&&f!==m&&(null!=f||null!=m)&&ua(e,t,p,f,r,m)})(r,e.type,n,t),r[eR]=t}catch(t){lT(e,e.return,t)}}function o5(e){return 5===e.tag||3===e.tag||26===e.tag||27===e.tag&&uv(e.type)||4===e.tag}function o8(e){e:for(;;){for(;null===e.sibling;){if(null===e.return||o5(e.return))return null;e=e.return}for(e.sibling.return=e.return,e=e.sibling;5!==e.tag&&6!==e.tag&&18!==e.tag;){if(27===e.tag&&uv(e.type)||2&e.flags||null===e.child||4===e.tag)continue e;e.child.return=e,e=e.child}if(!(2&e.flags))return e.stateNode}}function o9(e,t,n){var r=e.tag;if(5===r||6===r)e=e.stateNode,t?n.insertBefore(e,t):n.appendChild(e);else if(4!==r&&(27===r&&uv(e.type)&&(n=e.stateNode),null!==(e=e.child)))for(o9(e,t,n),e=e.sibling;null!==e;)o9(e,t,n),e=e.sibling}function o7(e){var t=e.stateNode,n=e.memoizedProps;try{for(var r=e.type,a=t.attributes;a.length;)t.removeAttributeNode(a[0]);uo(t,r,n),t[eL]=e,t[eR]=n}catch(t){lT(e,e.return,t)}}var se=!1,st=!1,sn=!1,sr="function"==typeof WeakSet?WeakSet:Set,sa=null;function si(e,t,n){var r=n.flags;switch(n.tag){case 0:case 11:case 15:sg(e,n),4&r&&oJ(5,n);break;case 1:if(sg(e,n),4&r)if(e=n.stateNode,null===t)try{e.componentDidMount()}catch(e){lT(n,n.return,e)}else{var a=oc(n.type,t.memoizedProps);t=t.memoizedState;try{e.componentDidUpdate(a,t,e.__reactInternalSnapshotBeforeUpdate)}catch(e){lT(n,n.return,e)}}64&r&&o0(n),512&r&&o2(n,n.return);break;case 3:if(sg(e,n),64&r&&null!==(e=n.updateQueue)){if(t=null,null!==n.child)switch(n.child.tag){case 27:case 5:case 1:t=n.child.stateNode}try{ax(e,t)}catch(e){lT(n,n.return,e)}}break;case 27:null===t&&4&r&&o7(n);case 26:case 5:sg(e,n),null===t&&4&r&&o4(n),512&r&&o2(n,n.return);break;case 12:default:sg(e,n);break;case 13:sg(e,n),4&r&&sc(e,n),64&r&&null!==(e=n.memoizedState)&&null!==(e=e.dehydrated)&&function(e,t){var n=e.ownerDocument;if("$?"!==e.data||"complete"===n.readyState)t();else{var r=function(){t(),n.removeEventListener("DOMContentLoaded",r)};n.addEventListener("DOMContentLoaded",r),e._reactRetry=r}}(e,n=lP.bind(null,n));break;case 22:if(!(r=null!==n.memoizedState||se)){t=null!==t&&null!==t.memoizedState||st,a=se;var i=st;se=r,(st=t)&&!i?function e(t,n,r){for(r=r&&0!=(8772&n.subtreeFlags),n=n.child;null!==n;){var a=n.alternate,i=t,o=n,s=o.flags;switch(o.tag){case 0:case 11:case 15:e(i,o,r),oJ(4,o);break;case 1:if(e(i,o,r),"function"==typeof(i=(a=o).stateNode).componentDidMount)try{i.componentDidMount()}catch(e){lT(a,a.return,e)}if(null!==(i=(a=o).updateQueue)){var l=a.stateNode;try{var u=i.shared.hiddenCallbacks;if(null!==u)for(i.shared.hiddenCallbacks=null,i=0;i<u.length;i++)ak(u[i],l)}catch(e){lT(a,a.return,e)}}r&&64&s&&o0(o),o2(o,o.return);break;case 27:o7(o);case 26:case 5:e(i,o,r),r&&null===a&&4&s&&o4(o),o2(o,o.return);break;case 12:default:e(i,o,r);break;case 13:e(i,o,r),r&&4&s&&sc(i,o);break;case 22:null===o.memoizedState&&e(i,o,r),o2(o,o.return);case 30:}n=n.sibling}}(e,n,0!=(8772&n.subtreeFlags)):sg(e,n),se=a,st=i}case 30:}}var so=null,ss=!1;function sl(e,t,n){for(n=n.child;null!==n;)su(e,t,n),n=n.sibling}function su(e,t,n){if(ed&&"function"==typeof ed.onCommitFiberUnmount)try{ed.onCommitFiberUnmount(ec,n)}catch(e){}switch(n.tag){case 26:st||o3(n,t),sl(e,t,n),n.memoizedState?n.memoizedState.count--:n.stateNode&&(n=n.stateNode).parentNode.removeChild(n);break;case 27:st||o3(n,t);var r=so,a=ss;uv(n.type)&&(so=n.stateNode,ss=!1),sl(e,t,n),uE(n.stateNode),so=r,ss=a;break;case 5:st||o3(n,t);case 6:if(r=so,a=ss,so=null,sl(e,t,n),so=r,ss=a,null!==so)if(ss)try{(9===so.nodeType?so.body:"HTML"===so.nodeName?so.ownerDocument.body:so).removeChild(n.stateNode)}catch(e){lT(n,t,e)}else try{so.removeChild(n.stateNode)}catch(e){lT(n,t,e)}break;case 18:null!==so&&(ss?(uw(9===(e=so).nodeType?e.body:"HTML"===e.nodeName?e.ownerDocument.body:e,n.stateNode),ck(e)):uw(so,n.stateNode));break;case 4:r=so,a=ss,so=n.stateNode.containerInfo,ss=!0,sl(e,t,n),so=r,ss=a;break;case 0:case 11:case 14:case 15:st||oZ(2,n,t),st||oZ(4,n,t),sl(e,t,n);break;case 1:st||(o3(n,t),"function"==typeof(r=n.stateNode).componentWillUnmount&&o1(n,t,r)),sl(e,t,n);break;case 21:default:sl(e,t,n);break;case 22:st=(r=st)||null!==n.memoizedState,sl(e,t,n),st=r}}function sc(e,t){if(null===t.memoizedState&&null!==(e=t.alternate)&&null!==(e=e.memoizedState)&&null!==(e=e.dehydrated))try{ck(e)}catch(e){lT(t,t.return,e)}}function sd(e,t){var n=function(e){switch(e.tag){case 13:case 19:var t=e.stateNode;return null===t&&(t=e.stateNode=new sr),t;case 22:return null===(t=(e=e.stateNode)._retryCache)&&(t=e._retryCache=new sr),t;default:throw Error(s(435,e.tag))}}(e);t.forEach(function(t){var r=lL.bind(null,e,t);n.has(t)||(n.add(t),t.then(r,r))})}function sp(e,t){var n=t.deletions;if(null!==n)for(var r=0;r<n.length;r++){var a=n[r],i=e,o=t,l=o;e:for(;null!==l;){switch(l.tag){case 27:if(uv(l.type)){so=l.stateNode,ss=!1;break e}break;case 5:so=l.stateNode,ss=!1;break e;case 3:case 4:so=l.stateNode.containerInfo,ss=!0;break e}l=l.return}if(null===so)throw Error(s(160));su(i,o,a),so=null,ss=!1,null!==(i=a.alternate)&&(i.return=null),a.return=null}if(13878&t.subtreeFlags)for(t=t.child;null!==t;)sm(t,e),t=t.sibling}var sf=null;function sm(e,t){var n=e.alternate,r=e.flags;switch(e.tag){case 0:case 11:case 14:case 15:sp(t,e),sh(e),4&r&&(oZ(3,e,e.return),oJ(3,e),oZ(5,e,e.return));break;case 1:sp(t,e),sh(e),512&r&&(st||null===n||o3(n,n.return)),64&r&&se&&null!==(e=e.updateQueue)&&null!==(r=e.callbacks)&&(n=e.shared.hiddenCallbacks,e.shared.hiddenCallbacks=null===n?r:n.concat(r));break;case 26:var a=sf;if(sp(t,e),sh(e),512&r&&(st||null===n||o3(n,n.return)),4&r){var i=null!==n?n.memoizedState:null;if(r=e.memoizedState,null===n)if(null===r)if(null===e.stateNode){e:{r=e.type,n=e.memoizedProps,a=a.ownerDocument||a;t:switch(r){case"title":(!(i=a.getElementsByTagName("title")[0])||i[ej]||i[eL]||"http://www.w3.org/2000/svg"===i.namespaceURI||i.hasAttribute("itemprop"))&&(i=a.createElement(r),a.head.insertBefore(i,a.querySelector("head > title"))),uo(i,r,n),i[eL]=e,eV(i),r=i;break e;case"link":var o=uH("link","href",a).get(r+(n.href||""));if(o){for(var l=0;l<o.length;l++)if((i=o[l]).getAttribute("href")===(null==n.href||""===n.href?null:n.href)&&i.getAttribute("rel")===(null==n.rel?null:n.rel)&&i.getAttribute("title")===(null==n.title?null:n.title)&&i.getAttribute("crossorigin")===(null==n.crossOrigin?null:n.crossOrigin)){o.splice(l,1);break t}}uo(i=a.createElement(r),r,n),a.head.appendChild(i);break;case"meta":if(o=uH("meta","content",a).get(r+(n.content||""))){for(l=0;l<o.length;l++)if((i=o[l]).getAttribute("content")===(null==n.content?null:""+n.content)&&i.getAttribute("name")===(null==n.name?null:n.name)&&i.getAttribute("property")===(null==n.property?null:n.property)&&i.getAttribute("http-equiv")===(null==n.httpEquiv?null:n.httpEquiv)&&i.getAttribute("charset")===(null==n.charSet?null:n.charSet)){o.splice(l,1);break t}}uo(i=a.createElement(r),r,n),a.head.appendChild(i);break;default:throw Error(s(468,r))}i[eL]=e,eV(i),r=i}e.stateNode=r}else uQ(a,e.type,e.stateNode);else e.stateNode=uz(a,r,e.memoizedProps);else i!==r?(null===i?null!==n.stateNode&&(n=n.stateNode).parentNode.removeChild(n):i.count--,null===r?uQ(a,e.type,e.stateNode):uz(a,r,e.memoizedProps)):null===r&&null!==e.stateNode&&o6(e,e.memoizedProps,n.memoizedProps)}break;case 27:sp(t,e),sh(e),512&r&&(st||null===n||o3(n,n.return)),null!==n&&4&r&&o6(e,e.memoizedProps,n.memoizedProps);break;case 5:if(sp(t,e),sh(e),512&r&&(st||null===n||o3(n,n.return)),32&e.flags){a=e.stateNode;try{tl(a,"")}catch(t){lT(e,e.return,t)}}4&r&&null!=e.stateNode&&(a=e.memoizedProps,o6(e,a,null!==n?n.memoizedProps:a)),1024&r&&(sn=!0);break;case 6:if(sp(t,e),sh(e),4&r){if(null===e.stateNode)throw Error(s(162));r=e.memoizedProps,n=e.stateNode;try{n.nodeValue=r}catch(t){lT(e,e.return,t)}}break;case 3:if(uV=null,a=sf,sf=uP(t.containerInfo),sp(t,e),sf=a,sh(e),4&r&&null!==n&&n.memoizedState.isDehydrated)try{ck(t.containerInfo)}catch(t){lT(e,e.return,t)}sn&&(sn=!1,function e(t){if(1024&t.subtreeFlags)for(t=t.child;null!==t;){var n=t;e(n),5===n.tag&&1024&n.flags&&n.stateNode.reset(),t=t.sibling}}(e));break;case 4:r=sf,sf=uP(e.stateNode.containerInfo),sp(t,e),sh(e),sf=r;break;case 12:default:sp(t,e),sh(e);break;case 13:sp(t,e),sh(e),8192&e.child.flags&&null!==e.memoizedState!=(null!==n&&null!==n.memoizedState)&&(sX=et()),4&r&&null!==(r=e.updateQueue)&&(e.updateQueue=null,sd(e,r));break;case 22:a=null!==e.memoizedState;var u=null!==n&&null!==n.memoizedState,c=se,d=st;if(se=c||a,st=d||u,sp(t,e),st=d,se=c,sh(e),8192&r)e:for((t=e.stateNode)._visibility=a?-2&t._visibility:1|t._visibility,a&&(null===n||u||se||st||function e(t){for(t=t.child;null!==t;){var n=t;switch(n.tag){case 0:case 11:case 14:case 15:oZ(4,n,n.return),e(n);break;case 1:o3(n,n.return);var r=n.stateNode;"function"==typeof r.componentWillUnmount&&o1(n,n.return,r),e(n);break;case 27:uE(n.stateNode);case 26:case 5:o3(n,n.return),e(n);break;case 22:null===n.memoizedState&&e(n);break;default:e(n)}t=t.sibling}}(e)),n=null,t=e;;){if(5===t.tag||26===t.tag){if(null===n){u=n=t;try{if(i=u.stateNode,a)o=i.style,"function"==typeof o.setProperty?o.setProperty("display","none","important"):o.display="none";else{l=u.stateNode;var p=u.memoizedProps.style,f=null!=p&&p.hasOwnProperty("display")?p.display:null;l.style.display=null==f||"boolean"==typeof f?"":(""+f).trim()}}catch(e){lT(u,u.return,e)}}}else if(6===t.tag){if(null===n){u=t;try{u.stateNode.nodeValue=a?"":u.memoizedProps}catch(e){lT(u,u.return,e)}}}else if((22!==t.tag&&23!==t.tag||null===t.memoizedState||t===e)&&null!==t.child){t.child.return=t,t=t.child;continue}if(t===e)break;for(;null===t.sibling;){if(null===t.return||t.return===e)break e;n===t&&(n=null),t=t.return}n===t&&(n=null),t.sibling.return=t.return,t=t.sibling}4&r&&null!==(r=e.updateQueue)&&null!==(n=r.retryQueue)&&(r.retryQueue=null,sd(e,n));break;case 19:sp(t,e),sh(e),4&r&&null!==(r=e.updateQueue)&&(e.updateQueue=null,sd(e,r));case 30:case 21:}}function sh(e){var t=e.flags;if(2&t){try{for(var n,r=e.return;null!==r;){if(o5(r)){n=r;break}r=r.return}if(null==n)throw Error(s(160));switch(n.tag){case 27:var a=n.stateNode,i=o8(e);o9(e,i,a);break;case 5:var o=n.stateNode;32&n.flags&&(tl(o,""),n.flags&=-33);var l=o8(e);o9(e,l,o);break;case 3:case 4:var u=n.stateNode.containerInfo,c=o8(e);!function e(t,n,r){var a=t.tag;if(5===a||6===a)t=t.stateNode,n?(9===r.nodeType?r.body:"HTML"===r.nodeName?r.ownerDocument.body:r).insertBefore(t,n):((n=9===r.nodeType?r.body:"HTML"===r.nodeName?r.ownerDocument.body:r).appendChild(t),null!=(r=r._reactRootContainer)||null!==n.onclick||(n.onclick=ur));else if(4!==a&&(27===a&&uv(t.type)&&(r=t.stateNode,n=null),null!==(t=t.child)))for(e(t,n,r),t=t.sibling;null!==t;)e(t,n,r),t=t.sibling}(e,c,u);break;default:throw Error(s(161))}}catch(t){lT(e,e.return,t)}e.flags&=-3}4096&t&&(e.flags&=-4097)}function sg(e,t){if(8772&t.subtreeFlags)for(t=t.child;null!==t;)si(e,t.alternate,t),t=t.sibling}function sy(e,t){var n=null;null!==e&&null!==e.memoizedState&&null!==e.memoizedState.cachePool&&(n=e.memoizedState.cachePool.pool),e=null,null!==t.memoizedState&&null!==t.memoizedState.cachePool&&(e=t.memoizedState.cachePool.pool),e!==n&&(null!=e&&e.refCount++,null!=n&&r1(n))}function sb(e,t){e=null,null!==t.alternate&&(e=t.alternate.memoizedState.cache),(t=t.memoizedState.cache)!==e&&(t.refCount++,null!=e&&r1(e))}function sv(e,t,n,r){if(10256&t.subtreeFlags)for(t=t.child;null!==t;)sw(e,t,n,r),t=t.sibling}function sw(e,t,n,r){var a=t.flags;switch(t.tag){case 0:case 11:case 15:sv(e,t,n,r),2048&a&&oJ(9,t);break;case 1:case 13:default:sv(e,t,n,r);break;case 3:sv(e,t,n,r),2048&a&&(e=null,null!==t.alternate&&(e=t.alternate.memoizedState.cache),(t=t.memoizedState.cache)!==e&&(t.refCount++,null!=e&&r1(e)));break;case 12:if(2048&a){sv(e,t,n,r),e=t.stateNode;try{var i=t.memoizedProps,o=i.id,s=i.onPostCommit;"function"==typeof s&&s(o,null===t.alternate?"mount":"update",e.passiveEffectDuration,-0)}catch(e){lT(t,t.return,e)}}else sv(e,t,n,r);break;case 23:break;case 22:i=t.stateNode,o=t.alternate,null!==t.memoizedState?2&i._visibility?sv(e,t,n,r):s_(e,t):2&i._visibility?sv(e,t,n,r):(i._visibility|=2,function e(t,n,r,a,i){for(i=i&&0!=(10256&n.subtreeFlags),n=n.child;null!==n;){var o=n,s=o.flags;switch(o.tag){case 0:case 11:case 15:e(t,o,r,a,i),oJ(8,o);break;case 23:break;case 22:var l=o.stateNode;null!==o.memoizedState?2&l._visibility?e(t,o,r,a,i):s_(t,o):(l._visibility|=2,e(t,o,r,a,i)),i&&2048&s&&sy(o.alternate,o);break;case 24:e(t,o,r,a,i),i&&2048&s&&sb(o.alternate,o);break;default:e(t,o,r,a,i)}n=n.sibling}}(e,t,n,r,0!=(10256&t.subtreeFlags))),2048&a&&sy(o,t);break;case 24:sv(e,t,n,r),2048&a&&sb(t.alternate,t)}}function s_(e,t){if(10256&t.subtreeFlags)for(t=t.child;null!==t;){var n=t,r=n.flags;switch(n.tag){case 22:s_(e,n),2048&r&&sy(n.alternate,n);break;case 24:s_(e,n),2048&r&&sb(n.alternate,n);break;default:s_(e,n)}t=t.sibling}}var sk=8192;function sx(e){if(e.subtreeFlags&sk)for(e=e.child;null!==e;)sS(e),e=e.sibling}function sS(e){switch(e.tag){case 26:sx(e),e.flags&sk&&null!==e.memoizedState&&function(e,t,n){if(null===uG)throw Error(s(475));var r=uG;if("stylesheet"===t.type&&("string"!=typeof n.media||!1!==matchMedia(n.media).matches)&&0==(4&t.state.loading)){if(null===t.instance){var a=uU(n.href),i=e.querySelector(uO(a));if(i){null!==(e=i._p)&&"object"==typeof e&&"function"==typeof e.then&&(r.count++,r=uX.bind(r),e.then(r,r)),t.state.loading|=4,t.instance=i,eV(i);return}i=e.ownerDocument||e,n=u$(n),(a=uI.get(a))&&uB(n,a),eV(i=i.createElement("link"));var o=i;o._p=new Promise(function(e,t){o.onload=e,o.onerror=t}),uo(i,"link",n),t.instance=i}null===r.stylesheets&&(r.stylesheets=new Map),r.stylesheets.set(t,e),(e=t.state.preload)&&0==(3&t.state.loading)&&(r.count++,t=uX.bind(r),e.addEventListener("load",t),e.addEventListener("error",t))}}(sf,e.memoizedState,e.memoizedProps);break;case 5:default:sx(e);break;case 3:case 4:var t=sf;sf=uP(e.stateNode.containerInfo),sx(e),sf=t;break;case 22:null===e.memoizedState&&(null!==(t=e.alternate)&&null!==t.memoizedState?(t=sk,sk=0x1000000,sx(e),sk=t):sx(e))}}function sA(e){var t=e.alternate;if(null!==t&&null!==(e=t.child)){t.child=null;do t=e.sibling,e.sibling=null,e=t;while(null!==e)}}function sT(e){var t=e.deletions;if(0!=(16&e.flags)){if(null!==t)for(var n=0;n<t.length;n++){var r=t[n];sa=r,sI(r,e)}sA(e)}if(10256&e.subtreeFlags)for(e=e.child;null!==e;)sE(e),e=e.sibling}function sE(e){switch(e.tag){case 0:case 11:case 15:sT(e),2048&e.flags&&oZ(9,e,e.return);break;case 3:case 12:default:sT(e);break;case 22:var t=e.stateNode;null!==e.memoizedState&&2&t._visibility&&(null===e.return||13!==e.return.tag)?(t._visibility&=-3,function e(t){var n=t.deletions;if(0!=(16&t.flags)){if(null!==n)for(var r=0;r<n.length;r++){var a=n[r];sa=a,sI(a,t)}sA(t)}for(t=t.child;null!==t;){switch((n=t).tag){case 0:case 11:case 15:oZ(8,n,n.return),e(n);break;case 22:2&(r=n.stateNode)._visibility&&(r._visibility&=-3,e(n));break;default:e(n)}t=t.sibling}}(e)):sT(e)}}function sI(e,t){for(;null!==sa;){var n=sa;switch(n.tag){case 0:case 11:case 15:oZ(8,n,t);break;case 23:case 22:if(null!==n.memoizedState&&null!==n.memoizedState.cachePool){var r=n.memoizedState.cachePool.pool;null!=r&&r.refCount++}break;case 24:r1(n.memoizedState.cache)}if(null!==(r=n.child))r.return=n,sa=r;else for(n=e;null!==sa;){var a=(r=sa).sibling,i=r.return;if(!function e(t){var n=t.alternate;null!==n&&(t.alternate=null,e(n)),t.child=null,t.deletions=null,t.sibling=null,5===t.tag&&null!==(n=t.stateNode)&&eD(n),t.stateNode=null,t.return=null,t.dependencies=null,t.memoizedProps=null,t.memoizedState=null,t.pendingProps=null,t.stateNode=null,t.updateQueue=null}(r),r===n){sa=null;break}if(null!==a){a.return=i,sa=a;break}sa=i}}}var sC={getCacheForType:function(e){var t=rW(rZ),n=t.data.get(e);return void 0===n&&(n=e(),t.data.set(e,n)),n}},sP="function"==typeof WeakMap?WeakMap:Map,sL=0,sR=null,sM=null,sN=0,sU=0,sO=null,s$=!1,sj=!1,sD=!1,sz=0,sF=0,sB=0,sq=0,sV=0,sH=0,sQ=0,sW=null,sG=null,sK=!1,sX=0,sY=1/0,sJ=null,sZ=null,s0=0,s1=null,s2=null,s3=0,s4=0,s6=null,s5=null,s8=0,s9=null;function s7(){if(0!=(2&sL)&&0!==sN)return sN&-sN;if(null!==N.T){var e=r4;return 0!==e?e:lH()}return eC()}function le(){0===sH&&(sH=0==(0x20000000&sN)||rT?e_():0x20000000);var e=i9.current;return null!==e&&(e.flags|=32),sH}function lt(e,t,n){(e===sR&&(2===sU||9===sU)||null!==e.cancelPendingCommit)&&(ls(e,0),la(e,sN,sH,!1)),eS(e,n),(0==(2&sL)||e!==sR)&&(e===sR&&(0==(2&sL)&&(sq|=n),4===sF&&la(e,sN,sH,!1)),lj(e))}function ln(e,t,n){if(0!=(6&sL))throw Error(s(327));for(var r=!n&&0==(124&t)&&0==(t&e.expiredLanes)||ew(e,t),a=r?function(e,t){var n=sL;sL|=2;var r=lu(),a=lc();sR!==e||sN!==t?(sJ=null,sY=et()+500,ls(e,t)):sj=ew(e,t);e:for(;;)try{if(0!==sU&&null!==sM){t=sM;var i=sO;t:switch(sU){case 1:sU=0,sO=null,lh(e,t,i,1);break;case 2:case 9:if(ao(i)){sU=0,sO=null,lm(t);break}t=function(){2!==sU&&9!==sU||sR!==e||(sU=7),lj(e)},i.then(t,t);break e;case 3:sU=7;break e;case 4:sU=5;break e;case 7:ao(i)?(sU=0,sO=null,lm(t)):(sU=0,sO=null,lh(e,t,i,7));break;case 5:var o=null;switch(sM.tag){case 26:o=sM.memoizedState;case 5:case 27:var l=sM;if(o?uW(o):1){sU=0,sO=null;var u=l.sibling;if(null!==u)sM=u;else{var c=l.return;null!==c?(sM=c,lg(c)):sM=null}break t}}sU=0,sO=null,lh(e,t,i,5);break;case 6:sU=0,sO=null,lh(e,t,i,6);break;case 8:lo(),sF=6;break e;default:throw Error(s(462))}}for(;null!==sM&&!Z();)lf(sM);break}catch(t){ll(e,t)}return(rD=rj=null,N.H=r,N.A=a,sL=n,null!==sM)?0:(sR=null,sN=0,n6(),sF)}(e,t):lp(e,t,!0),i=r;;){if(0===a)sj&&!r&&la(e,t,0,!1);else{if(n=e.current.alternate,i&&!function(e){for(var t=e;;){var n=t.tag;if((0===n||11===n||15===n)&&16384&t.flags&&null!==(n=t.updateQueue)&&null!==(n=n.stores))for(var r=0;r<n.length;r++){var a=n[r],i=a.getSnapshot;a=a.value;try{if(!nE(i(),a))return!1}catch(e){return!1}}if(n=t.child,16384&t.subtreeFlags&&null!==n)n.return=t,t=n;else{if(t===e)break;for(;null===t.sibling;){if(null===t.return||t.return===e)return!0;t=t.return}t.sibling.return=t.return,t=t.sibling}}return!0}(n)){a=lp(e,t,!1),i=!1;continue}if(2===a){if(i=t,e.errorRecoveryDisabledLanes&i)var o=0;else o=0!=(o=-0x20000001&e.pendingLanes)?o:0x20000000&o?0x20000000:0;if(0!==o){t=o;e:{a=sW;var l=e.current.memoizedState.isDehydrated;if(l&&(ls(e,o).flags|=256),2!==(o=lp(e,o,!1))){if(sD&&!l){e.errorRecoveryDisabledLanes|=i,sq|=i,a=4;break e}i=sG,sG=a,null!==i&&(null===sG?sG=i:sG.push.apply(sG,i))}a=o}if(i=!1,2!==a)continue}}if(1===a){ls(e,0),la(e,t,0,!0);break}e:{switch(r=e,i=a){case 0:case 1:throw Error(s(345));case 4:if((4194048&t)!==t)break;case 6:la(r,t,sH,!s$);break e;case 2:sG=null;break;case 3:case 5:break;default:throw Error(s(329))}if((0x3c00000&t)===t&&10<(a=sX+300-et())){if(la(r,t,sH,!s$),0!==ev(r,0,!0))break e;r.timeoutHandle=um(lr.bind(null,r,n,sG,sJ,sK,t,sH,sq,sQ,s$,i,2,-0,0),a);break e}lr(r,n,sG,sJ,sK,t,sH,sq,sQ,s$,i,0,-0,0)}}break}lj(e)}function lr(e,t,n,r,a,i,o,l,u,c,d,p,f,m){if(e.timeoutHandle=-1,(8192&(p=t.subtreeFlags)||0x1002000==(0x1002000&p))&&(uG={stylesheets:null,count:0,unsuspend:uK},sS(t),null!==(p=function(){if(null===uG)throw Error(s(475));var e=uG;return e.stylesheets&&0===e.count&&uJ(e,e.stylesheets),0<e.count?function(t){var n=setTimeout(function(){if(e.stylesheets&&uJ(e,e.stylesheets),e.unsuspend){var t=e.unsuspend;e.unsuspend=null,t()}},6e4);return e.unsuspend=t,function(){e.unsuspend=null,clearTimeout(n)}}:null}()))){e.cancelPendingCommit=p(lb.bind(null,e,t,i,n,r,a,o,l,u,d,1,f,m)),la(e,i,o,!c);return}lb(e,t,i,n,r,a,o,l,u)}function la(e,t,n,r){t&=~sV,t&=~sq,e.suspendedLanes|=t,e.pingedLanes&=~t,r&&(e.warmLanes|=t),r=e.expirationTimes;for(var a=t;0<a;){var i=31-ef(a),o=1<<i;r[i]=-1,a&=~o}0!==n&&eA(e,n,t)}function li(){return 0!=(6&sL)||(lD(0,!1),!1)}function lo(){if(null!==sM){if(0===sU)var e=sM.return;else e=sM,rD=rj=null,aG(e),iZ=null,i0=0,e=sM;for(;null!==e;)oY(e.alternate,e),e=e.return;sM=null}}function ls(e,t){var n=e.timeoutHandle;-1!==n&&(e.timeoutHandle=-1,uh(n)),null!==(n=e.cancelPendingCommit)&&(e.cancelPendingCommit=null,n()),lo(),sR=e,sM=n=ri(e.current,null),sN=t,sU=0,sO=null,s$=!1,sj=ew(e,t),sD=!1,sQ=sH=sV=sq=sB=sF=0,sG=sW=null,sK=!1,0!=(8&t)&&(t|=32&t);var r=e.entangledLanes;if(0!==r)for(e=e.entanglements,r&=t;0<r;){var a=31-ef(r),i=1<<a;t|=e[a],r&=~i}return sz=t,n6(),n}function ll(e,t){aP=null,N.H=iK,t===an||t===aa?(t=ac(),sU=3):t===ar?(t=ac(),sU=4):sU=t===ow?8:null!==t&&"object"==typeof t&&"function"==typeof t.then?6:1,sO=t,null===sM&&(sF=1,oh(e,n1(t,e.current)))}function lu(){var e=N.H;return N.H=iK,null===e?iK:e}function lc(){var e=N.A;return N.A=sC,e}function ld(){sF=4,s$||(4194048&sN)!==sN&&null!==i9.current||(sj=!0),0==(0x7ffffff&sB)&&0==(0x7ffffff&sq)||null===sR||la(sR,sN,sH,!1)}function lp(e,t,n){var r=sL;sL|=2;var a=lu(),i=lc();(sR!==e||sN!==t)&&(sJ=null,ls(e,t)),t=!1;var o=sF;e:for(;;)try{if(0!==sU&&null!==sM){var s=sM,l=sO;switch(sU){case 8:lo(),o=6;break e;case 3:case 2:case 9:case 6:null===i9.current&&(t=!0);var u=sU;if(sU=0,sO=null,lh(e,s,l,u),n&&sj){o=0;break e}break;default:u=sU,sU=0,sO=null,lh(e,s,l,u)}}(function(){for(;null!==sM;)lf(sM)})(),o=sF;break}catch(t){ll(e,t)}return t&&e.shellSuspendCounter++,rD=rj=null,sL=r,N.H=a,N.A=i,null===sM&&(sR=null,sN=0,n6()),o}function lf(e){var t=oH(e.alternate,e,sz);e.memoizedProps=e.pendingProps,null===t?lg(e):sM=t}function lm(e){var t=e,n=t.alternate;switch(t.tag){case 15:case 0:t=oP(n,t,t.pendingProps,t.type,void 0,sN);break;case 11:t=oP(n,t,t.pendingProps,t.type.render,t.ref,sN);break;case 5:aG(t);default:oY(n,t),t=oH(n,t=sM=ro(t,sz),sz)}e.memoizedProps=e.pendingProps,null===t?lg(e):sM=t}function lh(e,t,n,r){rD=rj=null,aG(t),iZ=null,i0=0;var a=t.return;try{if(function(e,t,n,r,a){if(n.flags|=32768,null!==r&&"object"==typeof r&&"function"==typeof r.then){if(null!==(t=n.alternate)&&rV(t,n,a,!0),null!==(n=i9.current)){switch(n.tag){case 13:return null===i7?ld():null===n.alternate&&0===sF&&(sF=3),n.flags&=-257,n.flags|=65536,n.lanes=a,r===ai?n.flags|=16384:(null===(t=n.updateQueue)?n.updateQueue=new Set([r]):t.add(r),lE(e,r,a)),!1;case 22:return n.flags|=65536,r===ai?n.flags|=16384:(null===(t=n.updateQueue)?(t={transitions:null,markerInstances:null,retryQueue:new Set([r])},n.updateQueue=t):null===(n=t.retryQueue)?t.retryQueue=new Set([r]):n.add(r),lE(e,r,a)),!1}throw Error(s(435,n.tag))}return lE(e,r,a),ld(),!1}if(rT)return null!==(t=i9.current)?(0==(65536&t.flags)&&(t.flags|=256),t.flags|=65536,t.lanes=a,r!==rC&&rO(n1(e=Error(s(422),{cause:r}),n))):(r!==rC&&rO(n1(t=Error(s(423),{cause:r}),n)),e=e.current.alternate,e.flags|=65536,a&=-a,e.lanes|=a,r=n1(r,n),a=oy(e.stateNode,r,a),ab(e,a),4!==sF&&(sF=2)),!1;var i=Error(s(520),{cause:r});if(i=n1(i,n),null===sW?sW=[i]:sW.push(i),4!==sF&&(sF=2),null===t)return!0;r=n1(r,n),n=t;do{switch(n.tag){case 3:return n.flags|=65536,e=a&-a,n.lanes|=e,e=oy(n.stateNode,r,e),ab(n,e),!1;case 1:if(t=n.type,i=n.stateNode,0==(128&n.flags)&&("function"==typeof t.getDerivedStateFromError||null!==i&&"function"==typeof i.componentDidCatch&&(null===sZ||!sZ.has(i))))return n.flags|=65536,a&=-a,n.lanes|=a,ov(a=ob(a),e,n,r),ab(n,a),!1}n=n.return}while(null!==n)return!1}(e,a,t,n,sN)){sF=1,oh(e,n1(n,e.current)),sM=null;return}}catch(t){if(null!==a)throw sM=a,t;sF=1,oh(e,n1(n,e.current)),sM=null;return}32768&t.flags?(rT||1===r?e=!0:sj||0!=(0x20000000&sN)?e=!1:(s$=e=!0,(2===r||9===r||3===r||6===r)&&null!==(r=i9.current)&&13===r.tag&&(r.flags|=16384)),ly(t,e)):lg(t)}function lg(e){var t=e;do{if(0!=(32768&t.flags))return void ly(t,s$);e=t.return;var n=function(e,t,n){var r=t.pendingProps;switch(rx(t),t.tag){case 31:case 16:case 15:case 0:case 11:case 7:case 8:case 12:case 9:case 14:case 1:return oX(t),null;case 3:return n=t.stateNode,r=null,null!==e&&(r=e.memoizedState.cache),t.memoizedState.cache!==r&&(t.flags|=2048),rF(rZ),W(),n.pendingContext&&(n.context=n.pendingContext,n.pendingContext=null),(null===e||null===e.child)&&(rM(t)?oQ(t):null===e||e.memoizedState.isDehydrated&&0==(256&t.flags)||(t.flags|=1024,rU())),oX(t),null;case 26:return n=t.memoizedState,null===e?(oQ(t),null!==n?(oX(t),oW(t,n)):(oX(t),t.flags&=-0x1000001)):n?n!==e.memoizedState?(oQ(t),oX(t),oW(t,n)):(oX(t),t.flags&=-0x1000001):(e.memoizedProps!==r&&oQ(t),oX(t),t.flags&=-0x1000001),null;case 27:K(t),n=V.current;var a=t.type;if(null!==e&&null!=t.stateNode)e.memoizedProps!==r&&oQ(t);else{if(!r){if(null===t.stateNode)throw Error(s(166));return oX(t),null}e=B.current,rM(t)?rL(t,e):(e=uT(a,r,n),t.stateNode=e,oQ(t))}return oX(t),null;case 5:if(K(t),n=t.type,null!==e&&null!=t.stateNode)e.memoizedProps!==r&&oQ(t);else{if(!r){if(null===t.stateNode)throw Error(s(166));return oX(t),null}if(e=B.current,rM(t))rL(t,e);else{switch(a=uu(V.current),e){case 1:e=a.createElementNS("http://www.w3.org/2000/svg",n);break;case 2:e=a.createElementNS("http://www.w3.org/1998/Math/MathML",n);break;default:switch(n){case"svg":e=a.createElementNS("http://www.w3.org/2000/svg",n);break;case"math":e=a.createElementNS("http://www.w3.org/1998/Math/MathML",n);break;case"script":(e=a.createElement("div")).innerHTML="<script><\/script>",e=e.removeChild(e.firstChild);break;case"select":e="string"==typeof r.is?a.createElement("select",{is:r.is}):a.createElement("select"),r.multiple?e.multiple=!0:r.size&&(e.size=r.size);break;default:e="string"==typeof r.is?a.createElement(n,{is:r.is}):a.createElement(n)}}e[eL]=t,e[eR]=r;e:for(a=t.child;null!==a;){if(5===a.tag||6===a.tag)e.appendChild(a.stateNode);else if(4!==a.tag&&27!==a.tag&&null!==a.child){a.child.return=a,a=a.child;continue}if(a===t)break;for(;null===a.sibling;){if(null===a.return||a.return===t)break e;a=a.return}a.sibling.return=a.return,a=a.sibling}switch(t.stateNode=e,uo(e,n,r),n){case"button":case"input":case"select":case"textarea":e=!!r.autoFocus;break;case"img":e=!0;break;default:e=!1}e&&oQ(t)}}return oX(t),t.flags&=-0x1000001,null;case 6:if(e&&null!=t.stateNode)e.memoizedProps!==r&&oQ(t);else{if("string"!=typeof r&&null===t.stateNode)throw Error(s(166));if(e=V.current,rM(t)){if(e=t.stateNode,n=t.memoizedProps,r=null,null!==(a=rS))switch(a.tag){case 27:case 5:r=a.memoizedProps}e[eL]=t,(e=!!(e.nodeValue===n||null!==r&&!0===r.suppressHydrationWarning||un(e.nodeValue,n)))||rP(t)}else(e=uu(e).createTextNode(r))[eL]=t,t.stateNode=e}return oX(t),null;case 13:if(r=t.memoizedState,null===e||null!==e.memoizedState&&null!==e.memoizedState.dehydrated){if(a=rM(t),null!==r&&null!==r.dehydrated){if(null===e){if(!a)throw Error(s(318));if(!(a=null!==(a=t.memoizedState)?a.dehydrated:null))throw Error(s(317));a[eL]=t}else rN(),0==(128&t.flags)&&(t.memoizedState=null),t.flags|=4;oX(t),a=!1}else a=rU(),null!==e&&null!==e.memoizedState&&(e.memoizedState.hydrationErrors=a),a=!0;if(!a){if(256&t.flags)return or(t),t;return or(t),null}}if(or(t),0!=(128&t.flags))return t.lanes=n,t;if(n=null!==r,e=null!==e&&null!==e.memoizedState,n){r=t.child,a=null,null!==r.alternate&&null!==r.alternate.memoizedState&&null!==r.alternate.memoizedState.cachePool&&(a=r.alternate.memoizedState.cachePool.pool);var i=null;null!==r.memoizedState&&null!==r.memoizedState.cachePool&&(i=r.memoizedState.cachePool.pool),i!==a&&(r.flags|=2048)}return n!==e&&n&&(t.child.flags|=8192),oG(t,t.updateQueue),oX(t),null;case 4:return W(),null===e&&l2(t.stateNode.containerInfo),oX(t),null;case 10:return rF(t.type),oX(t),null;case 19:if(z(oa),null===(a=t.memoizedState))return oX(t),null;if(r=0!=(128&t.flags),null===(i=a.rendering))if(r)oK(a,!1);else{if(0!==sF||null!==e&&0!=(128&e.flags))for(e=t.child;null!==e;){if(null!==(i=oi(e))){for(t.flags|=128,oK(a,!1),e=i.updateQueue,t.updateQueue=e,oG(t,e),t.subtreeFlags=0,e=n,n=t.child;null!==n;)ro(n,e),n=n.sibling;return F(oa,1&oa.current|2),t.child}e=e.sibling}null!==a.tail&&et()>sY&&(t.flags|=128,r=!0,oK(a,!1),t.lanes=4194304)}else{if(!r)if(null!==(e=oi(i))){if(t.flags|=128,r=!0,e=e.updateQueue,t.updateQueue=e,oG(t,e),oK(a,!0),null===a.tail&&"hidden"===a.tailMode&&!i.alternate&&!rT)return oX(t),null}else 2*et()-a.renderingStartTime>sY&&0x20000000!==n&&(t.flags|=128,r=!0,oK(a,!1),t.lanes=4194304);a.isBackwards?(i.sibling=t.child,t.child=i):(null!==(e=a.last)?e.sibling=i:t.child=i,a.last=i)}if(null!==a.tail)return t=a.tail,a.rendering=t,a.tail=t.sibling,a.renderingStartTime=et(),t.sibling=null,e=oa.current,F(oa,r?1&e|2:1&e),t;return oX(t),null;case 22:case 23:return or(t),aI(),r=null!==t.memoizedState,null!==e?null!==e.memoizedState!==r&&(t.flags|=8192):r&&(t.flags|=8192),r?0!=(0x20000000&n)&&0==(128&t.flags)&&(oX(t),6&t.subtreeFlags&&(t.flags|=8192)):oX(t),null!==(n=t.updateQueue)&&oG(t,n.retryQueue),n=null,null!==e&&null!==e.memoizedState&&null!==e.memoizedState.cachePool&&(n=e.memoizedState.cachePool.pool),r=null,null!==t.memoizedState&&null!==t.memoizedState.cachePool&&(r=t.memoizedState.cachePool.pool),r!==n&&(t.flags|=2048),null!==e&&z(r9),null;case 24:return n=null,null!==e&&(n=e.memoizedState.cache),t.memoizedState.cache!==n&&(t.flags|=2048),rF(rZ),oX(t),null;case 25:case 30:return null}throw Error(s(156,t.tag))}(t.alternate,t,sz);if(null!==n){sM=n;return}if(null!==(t=t.sibling)){sM=t;return}sM=t=e}while(null!==t)0===sF&&(sF=5)}function ly(e,t){do{var n=function(e,t){switch(rx(t),t.tag){case 1:return 65536&(e=t.flags)?(t.flags=-65537&e|128,t):null;case 3:return rF(rZ),W(),0!=(65536&(e=t.flags))&&0==(128&e)?(t.flags=-65537&e|128,t):null;case 26:case 27:case 5:return K(t),null;case 13:if(or(t),null!==(e=t.memoizedState)&&null!==e.dehydrated){if(null===t.alternate)throw Error(s(340));rN()}return 65536&(e=t.flags)?(t.flags=-65537&e|128,t):null;case 19:return z(oa),null;case 4:return W(),null;case 10:return rF(t.type),null;case 22:case 23:return or(t),aI(),null!==e&&z(r9),65536&(e=t.flags)?(t.flags=-65537&e|128,t):null;case 24:return rF(rZ),null;default:return null}}(e.alternate,e);if(null!==n){n.flags&=32767,sM=n;return}if(null!==(n=e.return)&&(n.flags|=32768,n.subtreeFlags=0,n.deletions=null),!t&&null!==(e=e.sibling)){sM=e;return}sM=e=n}while(null!==e)sF=6,sM=null}function lb(e,t,n,r,a,i,o,l,u){e.cancelPendingCommit=null;do lx();while(0!==s0)if(0!=(6&sL))throw Error(s(327));if(null!==t){if(t===e.current)throw Error(s(177));if(!function(e,t,n,r,a,i){var o=e.pendingLanes;e.pendingLanes=n,e.suspendedLanes=0,e.pingedLanes=0,e.warmLanes=0,e.expiredLanes&=n,e.entangledLanes&=n,e.errorRecoveryDisabledLanes&=n,e.shellSuspendCounter=0;var s=e.entanglements,l=e.expirationTimes,u=e.hiddenUpdates;for(n=o&~n;0<n;){var c=31-ef(n),d=1<<c;s[c]=0,l[c]=-1;var p=u[c];if(null!==p)for(u[c]=null,c=0;c<p.length;c++){var f=p[c];null!==f&&(f.lane&=-0x20000001)}n&=~d}0!==r&&eA(e,r,0),0!==i&&0===a&&0!==e.tag&&(e.suspendedLanes|=i&~(o&~t))}(e,n,i=t.lanes|t.childLanes|n4,o,l,u),e===sR&&(sM=sR=null,sN=0),s2=t,s1=e,s3=n,s4=i,s6=a,s5=r,0!=(10256&t.subtreeFlags)||0!=(10256&t.flags)?(e.callbackNode=null,e.callbackPriority=0,Y(ei,function(){return lS(!0),null})):(e.callbackNode=null,e.callbackPriority=0),r=0!=(13878&t.flags),0!=(13878&t.subtreeFlags)||r){r=N.T,N.T=null,a=U.p,U.p=2,o=sL,sL|=4;try{!function(e,t){if(e=e.containerInfo,us=u8,nR(e=nL(e))){if("selectionStart"in e)var n={start:e.selectionStart,end:e.selectionEnd};else e:{var r=(n=(n=e.ownerDocument)&&n.defaultView||window).getSelection&&n.getSelection();if(r&&0!==r.rangeCount){n=r.anchorNode;var a,i=r.anchorOffset,o=r.focusNode;r=r.focusOffset;try{n.nodeType,o.nodeType}catch(e){n=null;break e}var l=0,u=-1,c=-1,d=0,p=0,f=e,m=null;t:for(;;){for(;f!==n||0!==i&&3!==f.nodeType||(u=l+i),f!==o||0!==r&&3!==f.nodeType||(c=l+r),3===f.nodeType&&(l+=f.nodeValue.length),null!==(a=f.firstChild);)m=f,f=a;for(;;){if(f===e)break t;if(m===n&&++d===i&&(u=l),m===o&&++p===r&&(c=l),null!==(a=f.nextSibling))break;m=(f=m).parentNode}f=a}n=-1===u||-1===c?null:{start:u,end:c}}else n=null}n=n||{start:0,end:0}}else n=null;for(ul={focusedElem:e,selectionRange:n},u8=!1,sa=t;null!==sa;)if(e=(t=sa).child,0!=(1024&t.subtreeFlags)&&null!==e)e.return=t,sa=e;else for(;null!==sa;){switch(o=(t=sa).alternate,e=t.flags,t.tag){case 0:case 11:case 15:case 5:case 26:case 27:case 6:case 4:case 17:break;case 1:if(0!=(1024&e)&&null!==o){e=void 0,n=t,i=o.memoizedProps,o=o.memoizedState,r=n.stateNode;try{var h=oc(n.type,i,n.elementType===n.type);e=r.getSnapshotBeforeUpdate(h,o),r.__reactInternalSnapshotBeforeUpdate=e}catch(e){lT(n,n.return,e)}}break;case 3:if(0!=(1024&e)){if(9===(n=(e=t.stateNode.containerInfo).nodeType))u_(e);else if(1===n)switch(e.nodeName){case"HEAD":case"HTML":case"BODY":u_(e);break;default:e.textContent=""}}break;default:if(0!=(1024&e))throw Error(s(163))}if(null!==(e=t.sibling)){e.return=t.return,sa=e;break}sa=t.return}}(e,t,n)}finally{sL=o,U.p=a,N.T=r}}s0=1,lv(),lw(),l_()}}function lv(){if(1===s0){s0=0;var e=s1,t=s2,n=0!=(13878&t.flags);if(0!=(13878&t.subtreeFlags)||n){n=N.T,N.T=null;var r=U.p;U.p=2;var a=sL;sL|=4;try{sm(t,e);var i=ul,o=nL(e.containerInfo),s=i.focusedElem,l=i.selectionRange;if(o!==s&&s&&s.ownerDocument&&function e(t,n){return!!t&&!!n&&(t===n||(!t||3!==t.nodeType)&&(n&&3===n.nodeType?e(t,n.parentNode):"contains"in t?t.contains(n):!!t.compareDocumentPosition&&!!(16&t.compareDocumentPosition(n))))}(s.ownerDocument.documentElement,s)){if(null!==l&&nR(s)){var u=l.start,c=l.end;if(void 0===c&&(c=u),"selectionStart"in s)s.selectionStart=u,s.selectionEnd=Math.min(c,s.value.length);else{var d=s.ownerDocument||document,p=d&&d.defaultView||window;if(p.getSelection){var f=p.getSelection(),m=s.textContent.length,h=Math.min(l.start,m),g=void 0===l.end?h:Math.min(l.end,m);!f.extend&&h>g&&(o=g,g=h,h=o);var y=nP(s,h),b=nP(s,g);if(y&&b&&(1!==f.rangeCount||f.anchorNode!==y.node||f.anchorOffset!==y.offset||f.focusNode!==b.node||f.focusOffset!==b.offset)){var v=d.createRange();v.setStart(y.node,y.offset),f.removeAllRanges(),h>g?(f.addRange(v),f.extend(b.node,b.offset)):(v.setEnd(b.node,b.offset),f.addRange(v))}}}}for(d=[],f=s;f=f.parentNode;)1===f.nodeType&&d.push({element:f,left:f.scrollLeft,top:f.scrollTop});for("function"==typeof s.focus&&s.focus(),s=0;s<d.length;s++){var w=d[s];w.element.scrollLeft=w.left,w.element.scrollTop=w.top}}u8=!!us,ul=us=null}finally{sL=a,U.p=r,N.T=n}}e.current=t,s0=2}}function lw(){if(2===s0){s0=0;var e=s1,t=s2,n=0!=(8772&t.flags);if(0!=(8772&t.subtreeFlags)||n){n=N.T,N.T=null;var r=U.p;U.p=2;var a=sL;sL|=4;try{si(e,t.alternate,t)}finally{sL=a,U.p=r,N.T=n}}s0=3}}function l_(){if(4===s0||3===s0){s0=0,ee();var e=s1,t=s2,n=s3,r=s5;0!=(10256&t.subtreeFlags)||0!=(10256&t.flags)?s0=5:(s0=0,s2=s1=null,lk(e,e.pendingLanes));var a=e.pendingLanes;if(0===a&&(sZ=null),eI(n),t=t.stateNode,ed&&"function"==typeof ed.onCommitFiberRoot)try{ed.onCommitFiberRoot(ec,t,void 0,128==(128&t.current.flags))}catch(e){}if(null!==r){t=N.T,a=U.p,U.p=2,N.T=null;try{for(var i=e.onRecoverableError,o=0;o<r.length;o++){var s=r[o];i(s.value,{componentStack:s.stack})}}finally{N.T=t,U.p=a}}0!=(3&s3)&&lx(),lj(e),a=e.pendingLanes,0!=(4194090&n)&&0!=(42&a)?e===s9?s8++:(s8=0,s9=e):s8=0,lD(0,!1)}}function lk(e,t){0==(e.pooledCacheLanes&=t)&&null!=(t=e.pooledCache)&&(e.pooledCache=null,r1(t))}function lx(e){return lv(),lw(),l_(),lS(e)}function lS(){if(5!==s0)return!1;var e=s1,t=s4;s4=0;var n=eI(s3),r=N.T,a=U.p;try{U.p=32>n?32:n,N.T=null,n=s6,s6=null;var i=s1,o=s3;if(s0=0,s2=s1=null,s3=0,0!=(6&sL))throw Error(s(331));var l=sL;if(sL|=4,sE(i.current),sw(i,i.current,o,n),sL=l,lD(0,!1),ed&&"function"==typeof ed.onPostCommitFiberRoot)try{ed.onPostCommitFiberRoot(ec,i)}catch(e){}return!0}finally{U.p=a,N.T=r,lk(e,t)}}function lA(e,t,n){t=n1(n,t),t=oy(e.stateNode,t,2),null!==(e=ag(e,t,2))&&(eS(e,2),lj(e))}function lT(e,t,n){if(3===e.tag)lA(e,e,n);else for(;null!==t;){if(3===t.tag){lA(t,e,n);break}if(1===t.tag){var r=t.stateNode;if("function"==typeof t.type.getDerivedStateFromError||"function"==typeof r.componentDidCatch&&(null===sZ||!sZ.has(r))){e=n1(n,e),null!==(r=ag(t,n=ob(2),2))&&(ov(n,r,t,e),eS(r,2),lj(r));break}}t=t.return}}function lE(e,t,n){var r=e.pingCache;if(null===r){r=e.pingCache=new sP;var a=new Set;r.set(t,a)}else void 0===(a=r.get(t))&&(a=new Set,r.set(t,a));a.has(n)||(sD=!0,a.add(n),e=lI.bind(null,e,t,n),t.then(e,e))}function lI(e,t,n){var r=e.pingCache;null!==r&&r.delete(t),e.pingedLanes|=e.suspendedLanes&n,e.warmLanes&=~n,sR===e&&(sN&n)===n&&(4===sF||3===sF&&(0x3c00000&sN)===sN&&300>et()-sX?0==(2&sL)&&ls(e,0):sV|=n,sQ===sN&&(sQ=0)),lj(e)}function lC(e,t){0===t&&(t=ek()),null!==(e=n9(e,t))&&(eS(e,t),lj(e))}function lP(e){var t=e.memoizedState,n=0;null!==t&&(n=t.retryLane),lC(e,n)}function lL(e,t){var n=0;switch(e.tag){case 13:var r=e.stateNode,a=e.memoizedState;null!==a&&(n=a.retryLane);break;case 19:r=e.stateNode;break;case 22:r=e.stateNode._retryCache;break;default:throw Error(s(314))}null!==r&&r.delete(t),lC(e,n)}var lR=null,lM=null,lN=!1,lU=!1,lO=!1,l$=0;function lj(e){e!==lM&&null===e.next&&(null===lM?lR=lM=e:lM=lM.next=e),lU=!0,lN||(lN=!0,uy(function(){0!=(6&sL)?Y(er,lz):lF()}))}function lD(e,t){if(!lO&&lU){lO=!0;do for(var n=!1,r=lR;null!==r;){if(!t)if(0!==e){var a=r.pendingLanes;if(0===a)var i=0;else{var o=r.suspendedLanes,s=r.pingedLanes;i=0xc000095&(i=(1<<31-ef(42|e)+1)-1&(a&~(o&~s)))?0xc000095&i|1:i?2|i:0}0!==i&&(n=!0,lV(r,i))}else i=sN,0==(3&(i=ev(r,r===sR?i:0,null!==r.cancelPendingCommit||-1!==r.timeoutHandle)))||ew(r,i)||(n=!0,lV(r,i));r=r.next}while(n)lO=!1}}function lz(){lF()}function lF(){lU=lN=!1;var e,t=0;0!==l$&&(((e=window.event)&&"popstate"===e.type?e===uf||(uf=e,0):(uf=null,1))||(t=l$),l$=0);for(var n=et(),r=null,a=lR;null!==a;){var i=a.next,o=lB(a,n);0===o?(a.next=null,null===r?lR=i:r.next=i,null===i&&(lM=r)):(r=a,(0!==t||0!=(3&o))&&(lU=!0)),a=i}lD(t,!1)}function lB(e,t){for(var n=e.suspendedLanes,r=e.pingedLanes,a=e.expirationTimes,i=-0x3c00001&e.pendingLanes;0<i;){var o=31-ef(i),s=1<<o,l=a[o];-1===l?(0==(s&n)||0!=(s&r))&&(a[o]=function(e,t){switch(e){case 1:case 2:case 4:case 8:case 64:return t+250;case 16:case 32:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:return t+5e3;default:return -1}}(s,t)):l<=t&&(e.expiredLanes|=s),i&=~s}if(t=sR,n=sN,n=ev(e,e===t?n:0,null!==e.cancelPendingCommit||-1!==e.timeoutHandle),r=e.callbackNode,0===n||e===t&&(2===sU||9===sU)||null!==e.cancelPendingCommit)return null!==r&&null!==r&&J(r),e.callbackNode=null,e.callbackPriority=0;if(0==(3&n)||ew(e,n)){if((t=n&-n)===e.callbackPriority)return t;switch(null!==r&&J(r),eI(n)){case 2:case 8:n=ea;break;case 32:default:n=ei;break;case 0x10000000:n=es}return n=Y(n,r=lq.bind(null,e)),e.callbackPriority=t,e.callbackNode=n,t}return null!==r&&null!==r&&J(r),e.callbackPriority=2,e.callbackNode=null,2}function lq(e,t){if(0!==s0&&5!==s0)return e.callbackNode=null,e.callbackPriority=0,null;var n=e.callbackNode;if(lx(!0)&&e.callbackNode!==n)return null;var r=sN;return 0===(r=ev(e,e===sR?r:0,null!==e.cancelPendingCommit||-1!==e.timeoutHandle))?null:(ln(e,r,t),lB(e,et()),null!=e.callbackNode&&e.callbackNode===n?lq.bind(null,e):null)}function lV(e,t){if(lx())return null;ln(e,t,!0)}function lH(){return 0===l$&&(l$=e_()),l$}function lQ(e){return null==e||"symbol"==typeof e||"boolean"==typeof e?null:"function"==typeof e?e:th(""+e)}function lW(e,t){var n=t.ownerDocument.createElement("input");return n.name=t.name,n.value=t.value,e.id&&n.setAttribute("form",e.id),t.parentNode.insertBefore(n,t),e=new FormData(e),n.parentNode.removeChild(n),e}for(var lG=0;lG<nJ.length;lG++){var lK=nJ[lG];nZ(lK.toLowerCase(),"on"+(lK[0].toUpperCase()+lK.slice(1)))}nZ(nV,"onAnimationEnd"),nZ(nH,"onAnimationIteration"),nZ(nQ,"onAnimationStart"),nZ("dblclick","onDoubleClick"),nZ("focusin","onFocus"),nZ("focusout","onBlur"),nZ(nW,"onTransitionRun"),nZ(nG,"onTransitionStart"),nZ(nK,"onTransitionCancel"),nZ(nX,"onTransitionEnd"),eG("onMouseEnter",["mouseout","mouseover"]),eG("onMouseLeave",["mouseout","mouseover"]),eG("onPointerEnter",["pointerout","pointerover"]),eG("onPointerLeave",["pointerout","pointerover"]),eW("onChange","change click focusin focusout input keydown keyup selectionchange".split(" ")),eW("onSelect","focusout contextmenu dragend focusin keydown keyup mousedown mouseup selectionchange".split(" ")),eW("onBeforeInput",["compositionend","keypress","textInput","paste"]),eW("onCompositionEnd","compositionend focusout keydown keypress keyup mousedown".split(" ")),eW("onCompositionStart","compositionstart focusout keydown keypress keyup mousedown".split(" ")),eW("onCompositionUpdate","compositionupdate focusout keydown keypress keyup mousedown".split(" "));var lX="abort canplay canplaythrough durationchange emptied encrypted ended error loadeddata loadedmetadata loadstart pause play playing progress ratechange resize seeked seeking stalled suspend timeupdate volumechange waiting".split(" "),lY=new Set("beforetoggle cancel close invalid load scroll scrollend toggle".split(" ").concat(lX));function lJ(e,t){t=0!=(4&t);for(var n=0;n<e.length;n++){var r=e[n],a=r.event;r=r.listeners;e:{var i=void 0;if(t)for(var o=r.length-1;0<=o;o--){var s=r[o],l=s.instance,u=s.currentTarget;if(s=s.listener,l!==i&&a.isPropagationStopped())break e;i=s,a.currentTarget=u;try{i(a)}catch(e){od(e)}a.currentTarget=null,i=l}else for(o=0;o<r.length;o++){if(l=(s=r[o]).instance,u=s.currentTarget,s=s.listener,l!==i&&a.isPropagationStopped())break e;i=s,a.currentTarget=u;try{i(a)}catch(e){od(e)}a.currentTarget=null,i=l}}}}function lZ(e,t){var n=t[eN];void 0===n&&(n=t[eN]=new Set);var r=e+"__bubble";n.has(r)||(l3(t,e,2,!1),n.add(r))}function l0(e,t,n){var r=0;t&&(r|=4),l3(n,e,r,t)}var l1="_reactListening"+Math.random().toString(36).slice(2);function l2(e){if(!e[l1]){e[l1]=!0,eH.forEach(function(t){"selectionchange"!==t&&(lY.has(t)||l0(t,!1,e),l0(t,!0,e))});var t=9===e.nodeType?e:e.ownerDocument;null===t||t[l1]||(t[l1]=!0,l0("selectionchange",!1,t))}}function l3(e,t,n,r){switch(ca(t)){case 2:var a=u9;break;case 8:a=u7;break;default:a=ce}n=a.bind(null,t,n,e),a=void 0,tA&&("touchstart"===t||"touchmove"===t||"wheel"===t)&&(a=!0),r?void 0!==a?e.addEventListener(t,n,{capture:!0,passive:a}):e.addEventListener(t,n,!0):void 0!==a?e.addEventListener(t,n,{passive:a}):e.addEventListener(t,n,!1)}function l4(e,t,n,r,a){var i=r;if(0==(1&t)&&0==(2&t)&&null!==r)e:for(;;){if(null===r)return;var o=r.tag;if(3===o||4===o){var s=r.stateNode.containerInfo;if(s===a)break;if(4===o)for(o=r.return;null!==o;){var l=o.tag;if((3===l||4===l)&&o.stateNode.containerInfo===a)return;o=o.return}for(;null!==s;){if(null===(o=ez(s)))return;if(5===(l=o.tag)||6===l||26===l||27===l){r=i=o;continue e}s=s.parentNode}}r=r.return}tk(function(){var r=i,a=ty(n),o=[];e:{var s=nY.get(e);if(void 0!==s){var l=tV,c=e;switch(e){case"keypress":if(0===tL(n))break e;case"keydown":case"keyup":l=t6;break;case"focusin":c="focus",l=tX;break;case"focusout":c="blur",l=tX;break;case"beforeblur":case"afterblur":l=tX;break;case"click":if(2===n.button)break e;case"auxclick":case"dblclick":case"mousedown":case"mousemove":case"mouseup":case"mouseout":case"mouseover":case"contextmenu":l=tG;break;case"drag":case"dragend":case"dragenter":case"dragexit":case"dragleave":case"dragover":case"dragstart":case"drop":l=tK;break;case"touchcancel":case"touchend":case"touchmove":case"touchstart":l=t8;break;case nV:case nH:case nQ:l=tY;break;case nX:l=t9;break;case"scroll":case"scrollend":l=tQ;break;case"wheel":l=t7;break;case"copy":case"cut":case"paste":l=tJ;break;case"gotpointercapture":case"lostpointercapture":case"pointercancel":case"pointerdown":case"pointermove":case"pointerout":case"pointerover":case"pointerup":l=t5;break;case"toggle":case"beforetoggle":l=ne}var d=0!=(4&t),p=!d&&("scroll"===e||"scrollend"===e),f=d?null!==s?s+"Capture":null:s;d=[];for(var m,h=r;null!==h;){var g=h;if(m=g.stateNode,5!==(g=g.tag)&&26!==g&&27!==g||null===m||null===f||null!=(g=tx(h,f))&&d.push(l6(h,g,m)),p)break;h=h.return}0<d.length&&(s=new l(s,c,null,n,a),o.push({event:s,listeners:d}))}}if(0==(7&t)){if((s="mouseover"===e||"pointerover"===e,l="mouseout"===e||"pointerout"===e,!(s&&n!==tg&&(c=n.relatedTarget||n.fromElement)&&(ez(c)||c[eM])))&&(l||s)&&(s=a.window===a?a:(s=a.ownerDocument)?s.defaultView||s.parentWindow:window,l?(c=n.relatedTarget||n.toElement,l=r,null!==(c=c?ez(c):null)&&(p=u(c),d=c.tag,c!==p||5!==d&&27!==d&&6!==d)&&(c=null)):(l=null,c=r),l!==c)){if(d=tG,g="onMouseLeave",f="onMouseEnter",h="mouse",("pointerout"===e||"pointerover"===e)&&(d=t5,g="onPointerLeave",f="onPointerEnter",h="pointer"),p=null==l?s:eB(l),m=null==c?s:eB(c),(s=new d(g,h+"leave",l,n,a)).target=p,s.relatedTarget=m,g=null,ez(a)===r&&((d=new d(f,h+"enter",c,n,a)).target=m,d.relatedTarget=p,g=d),p=g,l&&c)t:{for(d=l,f=c,h=0,m=d;m;m=l8(m))h++;for(m=0,g=f;g;g=l8(g))m++;for(;0<h-m;)d=l8(d),h--;for(;0<m-h;)f=l8(f),m--;for(;h--;){if(d===f||null!==f&&d===f.alternate)break t;d=l8(d),f=l8(f)}d=null}else d=null;null!==l&&l9(o,s,l,d,!1),null!==c&&null!==p&&l9(o,p,c,d,!0)}e:{if("select"===(l=(s=r?eB(r):window).nodeName&&s.nodeName.toLowerCase())||"input"===l&&"file"===s.type)var y,b=ny;else if(nd(s))if(nb)b=nT;else{b=nS;var v=nx}else(l=s.nodeName)&&"input"===l.toLowerCase()&&("checkbox"===s.type||"radio"===s.type)?b=nA:r&&tp(r.elementType)&&(b=ny);if(b&&(b=b(e,r))){np(o,b,n,a);break e}v&&v(e,s,r),"focusout"===e&&r&&"number"===s.type&&null!=r.memoizedProps.value&&ta(s,"number",s.value)}switch(v=r?eB(r):window,e){case"focusin":(nd(v)||"true"===v.contentEditable)&&(nN=v,nU=r,nO=null);break;case"focusout":nO=nU=nN=null;break;case"mousedown":n$=!0;break;case"contextmenu":case"mouseup":case"dragend":n$=!1,nj(o,n,a);break;case"selectionchange":if(nM)break;case"keydown":case"keyup":nj(o,n,a)}if(nn)t:{switch(e){case"compositionstart":var w="onCompositionStart";break t;case"compositionend":w="onCompositionEnd";break t;case"compositionupdate":w="onCompositionUpdate";break t}w=void 0}else nu?ns(e,n)&&(w="onCompositionEnd"):"keydown"===e&&229===n.keyCode&&(w="onCompositionStart");w&&(ni&&"ko"!==n.locale&&(nu||"onCompositionStart"!==w?"onCompositionEnd"===w&&nu&&(y=tP()):(tI="value"in(tE=a)?tE.value:tE.textContent,nu=!0)),0<(v=l5(r,w)).length&&(w=new tZ(w,e,null,n,a),o.push({event:w,listeners:v}),y?w.data=y:null!==(y=nl(n))&&(w.data=y))),(y=na?function(e,t){switch(e){case"compositionend":return nl(t);case"keypress":if(32!==t.which)return null;return no=!0," ";case"textInput":return" "===(e=t.data)&&no?null:e;default:return null}}(e,n):function(e,t){if(nu)return"compositionend"===e||!nn&&ns(e,t)?(e=tP(),tC=tI=tE=null,nu=!1,e):null;switch(e){case"paste":default:return null;case"keypress":if(!(t.ctrlKey||t.altKey||t.metaKey)||t.ctrlKey&&t.altKey){if(t.char&&1<t.char.length)return t.char;if(t.which)return String.fromCharCode(t.which)}return null;case"compositionend":return ni&&"ko"!==t.locale?null:t.data}}(e,n))&&0<(w=l5(r,"onBeforeInput")).length&&(v=new tZ("onBeforeInput","beforeinput",null,n,a),o.push({event:v,listeners:w}),v.data=y);var _=e;if("submit"===_&&r&&r.stateNode===a){var k=lQ((a[eR]||null).action),x=n.submitter;x&&null!==(_=(_=x[eR]||null)?lQ(_.formAction):x.getAttribute("formAction"))&&(k=_,x=null);var S=new tV("action","action",null,n,a);o.push({event:S,listeners:[{instance:null,listener:function(){if(n.defaultPrevented){if(0!==l$){var e=x?lW(a,x):new FormData(a);iU(r,{pending:!0,data:e,method:a.method,action:k},null,e)}}else"function"==typeof k&&(S.preventDefault(),iU(r,{pending:!0,data:e=x?lW(a,x):new FormData(a),method:a.method,action:k},k,e))},currentTarget:a}]})}}lJ(o,t)})}function l6(e,t,n){return{instance:e,listener:t,currentTarget:n}}function l5(e,t){for(var n=t+"Capture",r=[];null!==e;){var a=e,i=a.stateNode;if(5!==(a=a.tag)&&26!==a&&27!==a||null===i||(null!=(a=tx(e,n))&&r.unshift(l6(e,a,i)),null!=(a=tx(e,t))&&r.push(l6(e,a,i))),3===e.tag)return r;e=e.return}return[]}function l8(e){if(null===e)return null;do e=e.return;while(e&&5!==e.tag&&27!==e.tag)return e||null}function l9(e,t,n,r,a){for(var i=t._reactName,o=[];null!==n&&n!==r;){var s=n,l=s.alternate,u=s.stateNode;if(s=s.tag,null!==l&&l===r)break;5!==s&&26!==s&&27!==s||null===u||(l=u,a?null!=(u=tx(n,i))&&o.unshift(l6(n,u,l)):a||null!=(u=tx(n,i))&&o.push(l6(n,u,l))),n=n.return}0!==o.length&&e.push({event:t,listeners:o})}var l7=/\r\n?/g,ue=/\u0000|\uFFFD/g;function ut(e){return("string"==typeof e?e:""+e).replace(l7,"\n").replace(ue,"")}function un(e,t){return t=ut(t),ut(e)===t}function ur(){}function ua(e,t,n,r,a,i){switch(n){case"children":"string"==typeof r?"body"===t||"textarea"===t&&""===r||tl(e,r):("number"==typeof r||"bigint"==typeof r)&&"body"!==t&&tl(e,""+r);break;case"className":eZ(e,"class",r);break;case"tabIndex":eZ(e,"tabindex",r);break;case"dir":case"role":case"viewBox":case"width":case"height":eZ(e,n,r);break;case"style":td(e,r,i);break;case"data":if("object"!==t){eZ(e,"data",r);break}case"src":case"href":if(""===r&&("a"!==t||"href"!==n)||null==r||"function"==typeof r||"symbol"==typeof r||"boolean"==typeof r){e.removeAttribute(n);break}r=th(""+r),e.setAttribute(n,r);break;case"action":case"formAction":if("function"==typeof r){e.setAttribute(n,"javascript:throw new Error('A React form was unexpectedly submitted. If you called form.submit() manually, consider using form.requestSubmit() instead. If you\\'re trying to use event.stopPropagation() in a submit event handler, consider also calling event.preventDefault().')");break}if("function"==typeof i&&("formAction"===n?("input"!==t&&ua(e,t,"name",a.name,a,null),ua(e,t,"formEncType",a.formEncType,a,null),ua(e,t,"formMethod",a.formMethod,a,null),ua(e,t,"formTarget",a.formTarget,a,null)):(ua(e,t,"encType",a.encType,a,null),ua(e,t,"method",a.method,a,null),ua(e,t,"target",a.target,a,null))),null==r||"symbol"==typeof r||"boolean"==typeof r){e.removeAttribute(n);break}r=th(""+r),e.setAttribute(n,r);break;case"onClick":null!=r&&(e.onclick=ur);break;case"onScroll":null!=r&&lZ("scroll",e);break;case"onScrollEnd":null!=r&&lZ("scrollend",e);break;case"dangerouslySetInnerHTML":if(null!=r){if("object"!=typeof r||!("__html"in r))throw Error(s(61));if(null!=(n=r.__html)){if(null!=a.children)throw Error(s(60));e.innerHTML=n}}break;case"multiple":e.multiple=r&&"function"!=typeof r&&"symbol"!=typeof r;break;case"muted":e.muted=r&&"function"!=typeof r&&"symbol"!=typeof r;break;case"suppressContentEditableWarning":case"suppressHydrationWarning":case"defaultValue":case"defaultChecked":case"innerHTML":case"ref":case"autoFocus":case"innerText":case"textContent":break;case"xlinkHref":if(null==r||"function"==typeof r||"boolean"==typeof r||"symbol"==typeof r){e.removeAttribute("xlink:href");break}n=th(""+r),e.setAttributeNS("http://www.w3.org/1999/xlink","xlink:href",n);break;case"contentEditable":case"spellCheck":case"draggable":case"value":case"autoReverse":case"externalResourcesRequired":case"focusable":case"preserveAlpha":null!=r&&"function"!=typeof r&&"symbol"!=typeof r?e.setAttribute(n,""+r):e.removeAttribute(n);break;case"inert":case"allowFullScreen":case"async":case"autoPlay":case"controls":case"default":case"defer":case"disabled":case"disablePictureInPicture":case"disableRemotePlayback":case"formNoValidate":case"hidden":case"loop":case"noModule":case"noValidate":case"open":case"playsInline":case"readOnly":case"required":case"reversed":case"scoped":case"seamless":case"itemScope":r&&"function"!=typeof r&&"symbol"!=typeof r?e.setAttribute(n,""):e.removeAttribute(n);break;case"capture":case"download":!0===r?e.setAttribute(n,""):!1!==r&&null!=r&&"function"!=typeof r&&"symbol"!=typeof r?e.setAttribute(n,r):e.removeAttribute(n);break;case"cols":case"rows":case"size":case"span":null!=r&&"function"!=typeof r&&"symbol"!=typeof r&&!isNaN(r)&&1<=r?e.setAttribute(n,r):e.removeAttribute(n);break;case"rowSpan":case"start":null==r||"function"==typeof r||"symbol"==typeof r||isNaN(r)?e.removeAttribute(n):e.setAttribute(n,r);break;case"popover":lZ("beforetoggle",e),lZ("toggle",e),eJ(e,"popover",r);break;case"xlinkActuate":e0(e,"http://www.w3.org/1999/xlink","xlink:actuate",r);break;case"xlinkArcrole":e0(e,"http://www.w3.org/1999/xlink","xlink:arcrole",r);break;case"xlinkRole":e0(e,"http://www.w3.org/1999/xlink","xlink:role",r);break;case"xlinkShow":e0(e,"http://www.w3.org/1999/xlink","xlink:show",r);break;case"xlinkTitle":e0(e,"http://www.w3.org/1999/xlink","xlink:title",r);break;case"xlinkType":e0(e,"http://www.w3.org/1999/xlink","xlink:type",r);break;case"xmlBase":e0(e,"http://www.w3.org/XML/1998/namespace","xml:base",r);break;case"xmlLang":e0(e,"http://www.w3.org/XML/1998/namespace","xml:lang",r);break;case"xmlSpace":e0(e,"http://www.w3.org/XML/1998/namespace","xml:space",r);break;case"is":eJ(e,"is",r);break;default:2<n.length&&("o"===n[0]||"O"===n[0])&&("n"===n[1]||"N"===n[1])||eJ(e,n=tf.get(n)||n,r)}}function ui(e,t,n,r,a,i){switch(n){case"style":td(e,r,i);break;case"dangerouslySetInnerHTML":if(null!=r){if("object"!=typeof r||!("__html"in r))throw Error(s(61));if(null!=(n=r.__html)){if(null!=a.children)throw Error(s(60));e.innerHTML=n}}break;case"children":"string"==typeof r?tl(e,r):("number"==typeof r||"bigint"==typeof r)&&tl(e,""+r);break;case"onScroll":null!=r&&lZ("scroll",e);break;case"onScrollEnd":null!=r&&lZ("scrollend",e);break;case"onClick":null!=r&&(e.onclick=ur);break;case"suppressContentEditableWarning":case"suppressHydrationWarning":case"innerHTML":case"ref":case"innerText":case"textContent":break;default:if(!eQ.hasOwnProperty(n))e:{if("o"===n[0]&&"n"===n[1]&&(a=n.endsWith("Capture"),t=n.slice(2,a?n.length-7:void 0),"function"==typeof(i=null!=(i=e[eR]||null)?i[n]:null)&&e.removeEventListener(t,i,a),"function"==typeof r)){"function"!=typeof i&&null!==i&&(n in e?e[n]=null:e.hasAttribute(n)&&e.removeAttribute(n)),e.addEventListener(t,r,a);break e}n in e?e[n]=r:!0===r?e.setAttribute(n,""):eJ(e,n,r)}}}function uo(e,t,n){switch(t){case"div":case"span":case"svg":case"path":case"a":case"g":case"p":case"li":break;case"img":lZ("error",e),lZ("load",e);var r,a=!1,i=!1;for(r in n)if(n.hasOwnProperty(r)){var o=n[r];if(null!=o)switch(r){case"src":a=!0;break;case"srcSet":i=!0;break;case"children":case"dangerouslySetInnerHTML":throw Error(s(137,t));default:ua(e,t,r,o,n,null)}}i&&ua(e,t,"srcSet",n.srcSet,n,null),a&&ua(e,t,"src",n.src,n,null);return;case"input":lZ("invalid",e);var l=r=o=i=null,u=null,c=null;for(a in n)if(n.hasOwnProperty(a)){var d=n[a];if(null!=d)switch(a){case"name":i=d;break;case"type":o=d;break;case"checked":u=d;break;case"defaultChecked":c=d;break;case"value":r=d;break;case"defaultValue":l=d;break;case"children":case"dangerouslySetInnerHTML":if(null!=d)throw Error(s(137,t));break;default:ua(e,t,a,d,n,null)}}tr(e,r,l,u,c,o,i,!1),e8(e);return;case"select":for(i in lZ("invalid",e),a=o=r=null,n)if(n.hasOwnProperty(i)&&null!=(l=n[i]))switch(i){case"value":r=l;break;case"defaultValue":o=l;break;case"multiple":a=l;default:ua(e,t,i,l,n,null)}t=r,n=o,e.multiple=!!a,null!=t?ti(e,!!a,t,!1):null!=n&&ti(e,!!a,n,!0);return;case"textarea":for(o in lZ("invalid",e),r=i=a=null,n)if(n.hasOwnProperty(o)&&null!=(l=n[o]))switch(o){case"value":a=l;break;case"defaultValue":i=l;break;case"children":r=l;break;case"dangerouslySetInnerHTML":if(null!=l)throw Error(s(91));break;default:ua(e,t,o,l,n,null)}ts(e,a,i,r),e8(e);return;case"option":for(u in n)n.hasOwnProperty(u)&&null!=(a=n[u])&&("selected"===u?e.selected=a&&"function"!=typeof a&&"symbol"!=typeof a:ua(e,t,u,a,n,null));return;case"dialog":lZ("beforetoggle",e),lZ("toggle",e),lZ("cancel",e),lZ("close",e);break;case"iframe":case"object":lZ("load",e);break;case"video":case"audio":for(a=0;a<lX.length;a++)lZ(lX[a],e);break;case"image":lZ("error",e),lZ("load",e);break;case"details":lZ("toggle",e);break;case"embed":case"source":case"link":lZ("error",e),lZ("load",e);case"area":case"base":case"br":case"col":case"hr":case"keygen":case"meta":case"param":case"track":case"wbr":case"menuitem":for(c in n)if(n.hasOwnProperty(c)&&null!=(a=n[c]))switch(c){case"children":case"dangerouslySetInnerHTML":throw Error(s(137,t));default:ua(e,t,c,a,n,null)}return;default:if(tp(t)){for(d in n)n.hasOwnProperty(d)&&void 0!==(a=n[d])&&ui(e,t,d,a,n,void 0);return}}for(l in n)n.hasOwnProperty(l)&&null!=(a=n[l])&&ua(e,t,l,a,n,null)}var us=null,ul=null;function uu(e){return 9===e.nodeType?e:e.ownerDocument}function uc(e){switch(e){case"http://www.w3.org/2000/svg":return 1;case"http://www.w3.org/1998/Math/MathML":return 2;default:return 0}}function ud(e,t){if(0===e)switch(t){case"svg":return 1;case"math":return 2;default:return 0}return 1===e&&"foreignObject"===t?0:e}function up(e,t){return"textarea"===e||"noscript"===e||"string"==typeof t.children||"number"==typeof t.children||"bigint"==typeof t.children||"object"==typeof t.dangerouslySetInnerHTML&&null!==t.dangerouslySetInnerHTML&&null!=t.dangerouslySetInnerHTML.__html}var uf=null,um="function"==typeof setTimeout?setTimeout:void 0,uh="function"==typeof clearTimeout?clearTimeout:void 0,ug="function"==typeof Promise?Promise:void 0,uy="function"==typeof queueMicrotask?queueMicrotask:void 0!==ug?function(e){return ug.resolve(null).then(e).catch(ub)}:um;function ub(e){setTimeout(function(){throw e})}function uv(e){return"head"===e}function uw(e,t){var n=t,r=0,a=0;do{var i=n.nextSibling;if(e.removeChild(n),i&&8===i.nodeType)if("/$"===(n=i.data)){if(0<r&&8>r){n=r;var o=e.ownerDocument;if(1&n&&uE(o.documentElement),2&n&&uE(o.body),4&n)for(uE(n=o.head),o=n.firstChild;o;){var s=o.nextSibling,l=o.nodeName;o[ej]||"SCRIPT"===l||"STYLE"===l||"LINK"===l&&"stylesheet"===o.rel.toLowerCase()||n.removeChild(o),o=s}}if(0===a){e.removeChild(i),ck(t);return}a--}else"$"===n||"$?"===n||"$!"===n?a++:r=n.charCodeAt(0)-48;else r=0;n=i}while(n)ck(t)}function u_(e){var t=e.firstChild;for(t&&10===t.nodeType&&(t=t.nextSibling);t;){var n=t;switch(t=t.nextSibling,n.nodeName){case"HTML":case"HEAD":case"BODY":u_(n),eD(n);continue;case"SCRIPT":case"STYLE":continue;case"LINK":if("stylesheet"===n.rel.toLowerCase())continue}e.removeChild(n)}}function uk(e){return"$!"===e.data||"$?"===e.data&&"complete"===e.ownerDocument.readyState}function ux(e){for(;null!=e;e=e.nextSibling){var t=e.nodeType;if(1===t||3===t)break;if(8===t){if("$"===(t=e.data)||"$!"===t||"$?"===t||"F!"===t||"F"===t)break;if("/$"===t)return null}}return e}var uS=null;function uA(e){e=e.previousSibling;for(var t=0;e;){if(8===e.nodeType){var n=e.data;if("$"===n||"$!"===n||"$?"===n){if(0===t)return e;t--}else"/$"===n&&t++}e=e.previousSibling}return null}function uT(e,t,n){switch(t=uu(n),e){case"html":if(!(e=t.documentElement))throw Error(s(452));return e;case"head":if(!(e=t.head))throw Error(s(453));return e;case"body":if(!(e=t.body))throw Error(s(454));return e;default:throw Error(s(451))}}function uE(e){for(var t=e.attributes;t.length;)e.removeAttributeNode(t[0]);eD(e)}var uI=new Map,uC=new Set;function uP(e){return"function"==typeof e.getRootNode?e.getRootNode():9===e.nodeType?e:e.ownerDocument}var uL=U.d;U.d={f:function(){var e=uL.f(),t=li();return e||t},r:function(e){var t=eF(e);null!==t&&5===t.tag&&"form"===t.type?i$(t):uL.r(e)},D:function(e){uL.D(e),uM("dns-prefetch",e,null)},C:function(e,t){uL.C(e,t),uM("preconnect",e,t)},L:function(e,t,n){if(uL.L(e,t,n),uR&&e&&t){var r='link[rel="preload"][as="'+tt(t)+'"]';"image"===t&&n&&n.imageSrcSet?(r+='[imagesrcset="'+tt(n.imageSrcSet)+'"]',"string"==typeof n.imageSizes&&(r+='[imagesizes="'+tt(n.imageSizes)+'"]')):r+='[href="'+tt(e)+'"]';var a=r;switch(t){case"style":a=uU(e);break;case"script":a=uj(e)}uI.has(a)||(e=f({rel:"preload",href:"image"===t&&n&&n.imageSrcSet?void 0:e,as:t},n),uI.set(a,e),null!==uR.querySelector(r)||"style"===t&&uR.querySelector(uO(a))||"script"===t&&uR.querySelector(uD(a))||(uo(t=uR.createElement("link"),"link",e),eV(t),uR.head.appendChild(t)))}},m:function(e,t){if(uL.m(e,t),uR&&e){var n=t&&"string"==typeof t.as?t.as:"script",r='link[rel="modulepreload"][as="'+tt(n)+'"][href="'+tt(e)+'"]',a=r;switch(n){case"audioworklet":case"paintworklet":case"serviceworker":case"sharedworker":case"worker":case"script":a=uj(e)}if(!uI.has(a)&&(e=f({rel:"modulepreload",href:e},t),uI.set(a,e),null===uR.querySelector(r))){switch(n){case"audioworklet":case"paintworklet":case"serviceworker":case"sharedworker":case"worker":case"script":if(uR.querySelector(uD(a)))return}uo(n=uR.createElement("link"),"link",e),eV(n),uR.head.appendChild(n)}}},X:function(e,t){if(uL.X(e,t),uR&&e){var n=eq(uR).hoistableScripts,r=uj(e),a=n.get(r);a||((a=uR.querySelector(uD(r)))||(e=f({src:e,async:!0},t),(t=uI.get(r))&&uq(e,t),eV(a=uR.createElement("script")),uo(a,"link",e),uR.head.appendChild(a)),a={type:"script",instance:a,count:1,state:null},n.set(r,a))}},S:function(e,t,n){if(uL.S(e,t,n),uR&&e){var r=eq(uR).hoistableStyles,a=uU(e);t=t||"default";var i=r.get(a);if(!i){var o={loading:0,preload:null};if(i=uR.querySelector(uO(a)))o.loading=5;else{e=f({rel:"stylesheet",href:e,"data-precedence":t},n),(n=uI.get(a))&&uB(e,n);var s=i=uR.createElement("link");eV(s),uo(s,"link",e),s._p=new Promise(function(e,t){s.onload=e,s.onerror=t}),s.addEventListener("load",function(){o.loading|=1}),s.addEventListener("error",function(){o.loading|=2}),o.loading|=4,uF(i,t,uR)}i={type:"stylesheet",instance:i,count:1,state:o},r.set(a,i)}}},M:function(e,t){if(uL.M(e,t),uR&&e){var n=eq(uR).hoistableScripts,r=uj(e),a=n.get(r);a||((a=uR.querySelector(uD(r)))||(e=f({src:e,async:!0,type:"module"},t),(t=uI.get(r))&&uq(e,t),eV(a=uR.createElement("script")),uo(a,"link",e),uR.head.appendChild(a)),a={type:"script",instance:a,count:1,state:null},n.set(r,a))}}};var uR="undefined"==typeof document?null:document;function uM(e,t,n){if(uR&&"string"==typeof t&&t){var r=tt(t);r='link[rel="'+e+'"][href="'+r+'"]',"string"==typeof n&&(r+='[crossorigin="'+n+'"]'),uC.has(r)||(uC.add(r),e={rel:e,crossOrigin:n,href:t},null===uR.querySelector(r)&&(uo(t=uR.createElement("link"),"link",e),eV(t),uR.head.appendChild(t)))}}function uN(e,t,n,r){var a=(a=V.current)?uP(a):null;if(!a)throw Error(s(446));switch(e){case"meta":case"title":return null;case"style":return"string"==typeof n.precedence&&"string"==typeof n.href?(t=uU(n.href),(r=(n=eq(a).hoistableStyles).get(t))||(r={type:"style",instance:null,count:0,state:null},n.set(t,r)),r):{type:"void",instance:null,count:0,state:null};case"link":if("stylesheet"===n.rel&&"string"==typeof n.href&&"string"==typeof n.precedence){e=uU(n.href);var i,o,l,u,c=eq(a).hoistableStyles,d=c.get(e);if(d||(a=a.ownerDocument||a,d={type:"stylesheet",instance:null,count:0,state:{loading:0,preload:null}},c.set(e,d),(c=a.querySelector(uO(e)))&&!c._p&&(d.instance=c,d.state.loading=5),uI.has(e)||(n={rel:"preload",as:"style",href:n.href,crossOrigin:n.crossOrigin,integrity:n.integrity,media:n.media,hrefLang:n.hrefLang,referrerPolicy:n.referrerPolicy},uI.set(e,n),c||(i=a,o=e,l=n,u=d.state,i.querySelector('link[rel="preload"][as="style"]['+o+"]")?u.loading=1:(u.preload=o=i.createElement("link"),o.addEventListener("load",function(){return u.loading|=1}),o.addEventListener("error",function(){return u.loading|=2}),uo(o,"link",l),eV(o),i.head.appendChild(o))))),t&&null===r)throw Error(s(528,""));return d}if(t&&null!==r)throw Error(s(529,""));return null;case"script":return t=n.async,"string"==typeof(n=n.src)&&t&&"function"!=typeof t&&"symbol"!=typeof t?(t=uj(n),(r=(n=eq(a).hoistableScripts).get(t))||(r={type:"script",instance:null,count:0,state:null},n.set(t,r)),r):{type:"void",instance:null,count:0,state:null};default:throw Error(s(444,e))}}function uU(e){return'href="'+tt(e)+'"'}function uO(e){return'link[rel="stylesheet"]['+e+"]"}function u$(e){return f({},e,{"data-precedence":e.precedence,precedence:null})}function uj(e){return'[src="'+tt(e)+'"]'}function uD(e){return"script[async]"+e}function uz(e,t,n){if(t.count++,null===t.instance)switch(t.type){case"style":var r=e.querySelector('style[data-href~="'+tt(n.href)+'"]');if(r)return t.instance=r,eV(r),r;var a=f({},n,{"data-href":n.href,"data-precedence":n.precedence,href:null,precedence:null});return eV(r=(e.ownerDocument||e).createElement("style")),uo(r,"style",a),uF(r,n.precedence,e),t.instance=r;case"stylesheet":a=uU(n.href);var i=e.querySelector(uO(a));if(i)return t.state.loading|=4,t.instance=i,eV(i),i;r=u$(n),(a=uI.get(a))&&uB(r,a),eV(i=(e.ownerDocument||e).createElement("link"));var o=i;return o._p=new Promise(function(e,t){o.onload=e,o.onerror=t}),uo(i,"link",r),t.state.loading|=4,uF(i,n.precedence,e),t.instance=i;case"script":if(i=uj(n.src),a=e.querySelector(uD(i)))return t.instance=a,eV(a),a;return r=n,(a=uI.get(i))&&uq(r=f({},n),a),eV(a=(e=e.ownerDocument||e).createElement("script")),uo(a,"link",r),e.head.appendChild(a),t.instance=a;case"void":return null;default:throw Error(s(443,t.type))}return"stylesheet"===t.type&&0==(4&t.state.loading)&&(r=t.instance,t.state.loading|=4,uF(r,n.precedence,e)),t.instance}function uF(e,t,n){for(var r=n.querySelectorAll('link[rel="stylesheet"][data-precedence],style[data-precedence]'),a=r.length?r[r.length-1]:null,i=a,o=0;o<r.length;o++){var s=r[o];if(s.dataset.precedence===t)i=s;else if(i!==a)break}i?i.parentNode.insertBefore(e,i.nextSibling):(t=9===n.nodeType?n.head:n).insertBefore(e,t.firstChild)}function uB(e,t){null==e.crossOrigin&&(e.crossOrigin=t.crossOrigin),null==e.referrerPolicy&&(e.referrerPolicy=t.referrerPolicy),null==e.title&&(e.title=t.title)}function uq(e,t){null==e.crossOrigin&&(e.crossOrigin=t.crossOrigin),null==e.referrerPolicy&&(e.referrerPolicy=t.referrerPolicy),null==e.integrity&&(e.integrity=t.integrity)}var uV=null;function uH(e,t,n){if(null===uV){var r=new Map,a=uV=new Map;a.set(n,r)}else(r=(a=uV).get(n))||(r=new Map,a.set(n,r));if(r.has(e))return r;for(r.set(e,null),n=n.getElementsByTagName(e),a=0;a<n.length;a++){var i=n[a];if(!(i[ej]||i[eL]||"link"===e&&"stylesheet"===i.getAttribute("rel"))&&"http://www.w3.org/2000/svg"!==i.namespaceURI){var o=i.getAttribute(t)||"";o=e+o;var s=r.get(o);s?s.push(i):r.set(o,[i])}}return r}function uQ(e,t,n){(e=e.ownerDocument||e).head.insertBefore(n,"title"===t?e.querySelector("head > title"):null)}function uW(e){return"stylesheet"!==e.type||0!=(3&e.state.loading)}var uG=null;function uK(){}function uX(){if(this.count--,0===this.count){if(this.stylesheets)uJ(this,this.stylesheets);else if(this.unsuspend){var e=this.unsuspend;this.unsuspend=null,e()}}}var uY=null;function uJ(e,t){e.stylesheets=null,null!==e.unsuspend&&(e.count++,uY=new Map,t.forEach(uZ,e),uY=null,uX.call(e))}function uZ(e,t){if(!(4&t.state.loading)){var n=uY.get(e);if(n)var r=n.get(null);else{n=new Map,uY.set(e,n);for(var a=e.querySelectorAll("link[data-precedence],style[data-precedence]"),i=0;i<a.length;i++){var o=a[i];("LINK"===o.nodeName||"not all"!==o.getAttribute("media"))&&(n.set(o.dataset.precedence,o),r=o)}r&&n.set(null,r)}o=(a=t.instance).getAttribute("data-precedence"),(i=n.get(o)||r)===r&&n.set(null,a),n.set(o,a),this.count++,r=uX.bind(this),a.addEventListener("load",r),a.addEventListener("error",r),i?i.parentNode.insertBefore(a,i.nextSibling):(e=9===e.nodeType?e.head:e).insertBefore(a,e.firstChild),t.state.loading|=4}}var u0={$$typeof:k,Provider:null,Consumer:null,_currentValue:O,_currentValue2:O,_threadCount:0};function u1(e,t,n,r,a,i,o,s){this.tag=1,this.containerInfo=e,this.pingCache=this.current=this.pendingChildren=null,this.timeoutHandle=-1,this.callbackNode=this.next=this.pendingContext=this.context=this.cancelPendingCommit=null,this.callbackPriority=0,this.expirationTimes=ex(-1),this.entangledLanes=this.shellSuspendCounter=this.errorRecoveryDisabledLanes=this.expiredLanes=this.warmLanes=this.pingedLanes=this.suspendedLanes=this.pendingLanes=0,this.entanglements=ex(0),this.hiddenUpdates=ex(null),this.identifierPrefix=r,this.onUncaughtError=a,this.onCaughtError=i,this.onRecoverableError=o,this.pooledCache=null,this.pooledCacheLanes=0,this.formState=s,this.incompleteTransitions=new Map}function u2(e,t,n,r,a,i,o,s,l,u,c,d){return e=new u1(e,t,n,o,s,l,u,d),t=1,!0===i&&(t|=24),i=rr(3,null,null,t),e.current=i,i.stateNode=e,t=r0(),t.refCount++,e.pooledCache=t,t.refCount++,i.memoizedState={element:r,isDehydrated:n,cache:t},af(i),e}function u3(e,t,n,r,a,i){a=a?rt:rt,null===r.context?r.context=a:r.pendingContext=a,(r=ah(t)).payload={element:n},null!==(i=void 0===i?null:i)&&(r.callback=i),null!==(n=ag(e,r,t))&&(lt(n,e,t),ay(n,e,t))}function u4(e,t){if(null!==(e=e.memoizedState)&&null!==e.dehydrated){var n=e.retryLane;e.retryLane=0!==n&&n<t?n:t}}function u6(e,t){u4(e,t),(e=e.alternate)&&u4(e,t)}function u5(e){if(13===e.tag){var t=n9(e,0x4000000);null!==t&&lt(t,e,0x4000000),u6(e,0x4000000)}}var u8=!0;function u9(e,t,n,r){var a=N.T;N.T=null;var i=U.p;try{U.p=2,ce(e,t,n,r)}finally{U.p=i,N.T=a}}function u7(e,t,n,r){var a=N.T;N.T=null;var i=U.p;try{U.p=8,ce(e,t,n,r)}finally{U.p=i,N.T=a}}function ce(e,t,n,r){if(u8){var a=ct(r);if(null===a)l4(e,t,r,cn,n),cf(e,r);else if(function(e,t,n,r,a){switch(t){case"focusin":return co=cm(co,e,t,n,r,a),!0;case"dragenter":return cs=cm(cs,e,t,n,r,a),!0;case"mouseover":return cl=cm(cl,e,t,n,r,a),!0;case"pointerover":var i=a.pointerId;return cu.set(i,cm(cu.get(i)||null,e,t,n,r,a)),!0;case"gotpointercapture":return i=a.pointerId,cc.set(i,cm(cc.get(i)||null,e,t,n,r,a)),!0}return!1}(a,e,t,n,r))r.stopPropagation();else if(cf(e,r),4&t&&-1<cp.indexOf(e)){for(;null!==a;){var i=eF(a);if(null!==i)switch(i.tag){case 3:if((i=i.stateNode).current.memoizedState.isDehydrated){var o=eb(i.pendingLanes);if(0!==o){var s=i;for(s.pendingLanes|=2,s.entangledLanes|=2;o;){var l=1<<31-ef(o);s.entanglements[1]|=l,o&=~l}lj(i),0==(6&sL)&&(sY=et()+500,lD(0,!1))}}break;case 13:null!==(s=n9(i,2))&&lt(s,i,2),li(),u6(i,2)}if(null===(i=ct(r))&&l4(e,t,r,cn,n),i===a)break;a=i}null!==a&&r.stopPropagation()}else l4(e,t,r,null,n)}}function ct(e){return cr(e=ty(e))}var cn=null;function cr(e){if(cn=null,null!==(e=ez(e))){var t=u(e);if(null===t)e=null;else{var n=t.tag;if(13===n){if(null!==(e=c(t)))return e;e=null}else if(3===n){if(t.stateNode.current.memoizedState.isDehydrated)return 3===t.tag?t.stateNode.containerInfo:null;e=null}else t!==e&&(e=null)}}return cn=e,null}function ca(e){switch(e){case"beforetoggle":case"cancel":case"click":case"close":case"contextmenu":case"copy":case"cut":case"auxclick":case"dblclick":case"dragend":case"dragstart":case"drop":case"focusin":case"focusout":case"input":case"invalid":case"keydown":case"keypress":case"keyup":case"mousedown":case"mouseup":case"paste":case"pause":case"play":case"pointercancel":case"pointerdown":case"pointerup":case"ratechange":case"reset":case"resize":case"seeked":case"submit":case"toggle":case"touchcancel":case"touchend":case"touchstart":case"volumechange":case"change":case"selectionchange":case"textInput":case"compositionstart":case"compositionend":case"compositionupdate":case"beforeblur":case"afterblur":case"beforeinput":case"blur":case"fullscreenchange":case"focus":case"hashchange":case"popstate":case"select":case"selectstart":return 2;case"drag":case"dragenter":case"dragexit":case"dragleave":case"dragover":case"mousemove":case"mouseout":case"mouseover":case"pointermove":case"pointerout":case"pointerover":case"scroll":case"touchmove":case"wheel":case"mouseenter":case"mouseleave":case"pointerenter":case"pointerleave":return 8;case"message":switch(en()){case er:return 2;case ea:return 8;case ei:case eo:return 32;case es:return 0x10000000;default:return 32}default:return 32}}var ci=!1,co=null,cs=null,cl=null,cu=new Map,cc=new Map,cd=[],cp="mousedown mouseup touchcancel touchend touchstart auxclick dblclick pointercancel pointerdown pointerup dragend dragstart drop compositionend compositionstart keydown keypress keyup input textInput copy cut paste click change contextmenu reset".split(" ");function cf(e,t){switch(e){case"focusin":case"focusout":co=null;break;case"dragenter":case"dragleave":cs=null;break;case"mouseover":case"mouseout":cl=null;break;case"pointerover":case"pointerout":cu.delete(t.pointerId);break;case"gotpointercapture":case"lostpointercapture":cc.delete(t.pointerId)}}function cm(e,t,n,r,a,i){return null===e||e.nativeEvent!==i?(e={blockedOn:t,domEventName:n,eventSystemFlags:r,nativeEvent:i,targetContainers:[a]},null!==t&&null!==(t=eF(t))&&u5(t)):(e.eventSystemFlags|=r,t=e.targetContainers,null!==a&&-1===t.indexOf(a)&&t.push(a)),e}function ch(e){var t=ez(e.target);if(null!==t){var n=u(t);if(null!==n){if(13===(t=n.tag)){if(null!==(t=c(n))){e.blockedOn=t,function(e,t){var n=U.p;try{return U.p=e,t()}finally{U.p=n}}(e.priority,function(){if(13===n.tag){var e=s7(),t=n9(n,e=eE(e));null!==t&&lt(t,n,e),u6(n,e)}});return}}else if(3===t&&n.stateNode.current.memoizedState.isDehydrated){e.blockedOn=3===n.tag?n.stateNode.containerInfo:null;return}}}e.blockedOn=null}function cg(e){if(null!==e.blockedOn)return!1;for(var t=e.targetContainers;0<t.length;){var n=ct(e.nativeEvent);if(null!==n)return null!==(t=eF(n))&&u5(t),e.blockedOn=n,!1;var r=new(n=e.nativeEvent).constructor(n.type,n);tg=r,n.target.dispatchEvent(r),tg=null,t.shift()}return!0}function cy(e,t,n){cg(e)&&n.delete(t)}function cb(){ci=!1,null!==co&&cg(co)&&(co=null),null!==cs&&cg(cs)&&(cs=null),null!==cl&&cg(cl)&&(cl=null),cu.forEach(cy),cc.forEach(cy)}function cv(e,t){e.blockedOn===t&&(e.blockedOn=null,ci||(ci=!0,a.unstable_scheduleCallback(a.unstable_NormalPriority,cb)))}var cw=null;function c_(e){cw!==e&&(cw=e,a.unstable_scheduleCallback(a.unstable_NormalPriority,function(){cw===e&&(cw=null);for(var t=0;t<e.length;t+=3){var n=e[t],r=e[t+1],a=e[t+2];if("function"!=typeof r)if(null===cr(r||n))continue;else break;var i=eF(n);null!==i&&(e.splice(t,3),t-=3,iU(i,{pending:!0,data:a,method:n.method,action:r},r,a))}}))}function ck(e){function t(t){return cv(t,e)}null!==co&&cv(co,e),null!==cs&&cv(cs,e),null!==cl&&cv(cl,e),cu.forEach(t),cc.forEach(t);for(var n=0;n<cd.length;n++){var r=cd[n];r.blockedOn===e&&(r.blockedOn=null)}for(;0<cd.length&&null===(n=cd[0]).blockedOn;)ch(n),null===n.blockedOn&&cd.shift();if(null!=(n=(e.ownerDocument||e).$$reactFormReplay))for(r=0;r<n.length;r+=3){var a=n[r],i=n[r+1],o=a[eR]||null;if("function"==typeof i)o||c_(n);else if(o){var s=null;if(i&&i.hasAttribute("formAction")){if(a=i,o=i[eR]||null)s=o.formAction;else if(null!==cr(a))continue}else s=o.action;"function"==typeof s?n[r+1]=s:(n.splice(r,3),r-=3),c_(n)}}}function cx(e){this._internalRoot=e}function cS(e){this._internalRoot=e}cS.prototype.render=cx.prototype.render=function(e){var t=this._internalRoot;if(null===t)throw Error(s(409));u3(t.current,s7(),e,t,null,null)},cS.prototype.unmount=cx.prototype.unmount=function(){var e=this._internalRoot;if(null!==e){this._internalRoot=null;var t=e.containerInfo;u3(e.current,2,null,e,null,null),li(),t[eM]=null}},cS.prototype.unstable_scheduleHydration=function(e){if(e){var t=eC();e={blockedOn:null,target:e,priority:t};for(var n=0;n<cd.length&&0!==t&&t<cd[n].priority;n++);cd.splice(n,0,e),0===n&&ch(e)}};var cA=i.version;if("19.1.1"!==cA)throw Error(s(527,cA,"19.1.1"));if(U.findDOMNode=function(e){var t=e._reactInternals;if(void 0===t){if("function"==typeof e.render)throw Error(s(188));throw Error(s(268,e=Object.keys(e).join(",")))}return null===(e=null!==(e=function(e){var t=e.alternate;if(!t){if(null===(t=u(e)))throw Error(s(188));return t!==e?null:e}for(var n=e,r=t;;){var a=n.return;if(null===a)break;var i=a.alternate;if(null===i){if(null!==(r=a.return)){n=r;continue}break}if(a.child===i.child){for(i=a.child;i;){if(i===n)return d(a),e;if(i===r)return d(a),t;i=i.sibling}throw Error(s(188))}if(n.return!==r.return)n=a,r=i;else{for(var o=!1,l=a.child;l;){if(l===n){o=!0,n=a,r=i;break}if(l===r){o=!0,r=a,n=i;break}l=l.sibling}if(!o){for(l=i.child;l;){if(l===n){o=!0,n=i,r=a;break}if(l===r){o=!0,r=i,n=a;break}l=l.sibling}if(!o)throw Error(s(189))}}if(n.alternate!==r)throw Error(s(190))}if(3!==n.tag)throw Error(s(188));return n.stateNode.current===n?e:t}(t))?function e(t){var n=t.tag;if(5===n||26===n||27===n||6===n)return t;for(t=t.child;null!==t;){if(null!==(n=e(t)))return n;t=t.sibling}return null}(e):null)?null:e.stateNode},"undefined"!=typeof __REACT_DEVTOOLS_GLOBAL_HOOK__){var cT=__REACT_DEVTOOLS_GLOBAL_HOOK__;if(!cT.isDisabled&&cT.supportsFiber)try{ec=cT.inject({bundleType:0,version:"19.1.1",rendererPackageName:"react-dom",currentDispatcherRef:N,reconcilerVersion:"19.1.1"}),ed=cT}catch(e){}}tU=function(e,t){if(!l(e))throw Error(s(299));var n=!1,r="",a=op,i=of,o=om,u=null;return null!=t&&(!0===t.unstable_strictMode&&(n=!0),void 0!==t.identifierPrefix&&(r=t.identifierPrefix),void 0!==t.onUncaughtError&&(a=t.onUncaughtError),void 0!==t.onCaughtError&&(i=t.onCaughtError),void 0!==t.onRecoverableError&&(o=t.onRecoverableError),void 0!==t.unstable_transitionCallbacks&&(u=t.unstable_transitionCallbacks)),t=u2(e,1,!1,null,null,n,r,a,i,o,u,null),e[eM]=t.current,l2(e),new cx(t)},tO=function(e,t,n){if(!l(e))throw Error(s(299));var r=!1,a="",i=op,o=of,u=om,c=null,d=null;return null!=n&&(!0===n.unstable_strictMode&&(r=!0),void 0!==n.identifierPrefix&&(a=n.identifierPrefix),void 0!==n.onUncaughtError&&(i=n.onUncaughtError),void 0!==n.onCaughtError&&(o=n.onCaughtError),void 0!==n.onRecoverableError&&(u=n.onRecoverableError),void 0!==n.unstable_transitionCallbacks&&(c=n.unstable_transitionCallbacks),void 0!==n.formState&&(d=n.formState)),(t=u2(e,1,!0,t,null!=n?n:null,r,a,i,o,u,c,d)).context=rt,n=t.current,(a=ah(r=eE(r=s7()))).callback=null,ag(n,a,r),n=r,t.current.lanes=n,eS(t,n),lj(t),e[eM]=t.current,l2(e),new cS(t)},t$="19.1.1"}),f("6qr1r",function(e,t){e.exports=p("h8XvE")}),f("h8XvE",function(t,n){function r(e,t){var n=e.length;for(e.push(t);0<n;){var r=n-1>>>1,a=e[r];if(0<o(a,t))e[r]=t,e[n]=a,n=r;else break}}function a(e){return 0===e.length?null:e[0]}function i(e){if(0===e.length)return null;var t=e[0],n=e.pop();if(n!==t){e[0]=n;for(var r=0,a=e.length,i=a>>>1;r<i;){var s=2*(r+1)-1,l=e[s],u=s+1,c=e[u];if(0>o(l,n))u<a&&0>o(c,l)?(e[r]=c,e[u]=n,r=u):(e[r]=l,e[s]=n,r=s);else if(u<a&&0>o(c,n))e[r]=c,e[u]=n,r=u;else break}}return t}function o(e,t){var n=e.sortIndex-t.sortIndex;return 0!==n?n:e.id-t.id}if(e(t.exports,"unstable_now",()=>s,e=>s=e),e(t.exports,"unstable_IdlePriority",()=>l,e=>l=e),e(t.exports,"unstable_ImmediatePriority",()=>u,e=>u=e),e(t.exports,"unstable_LowPriority",()=>c,e=>c=e),e(t.exports,"unstable_NormalPriority",()=>d,e=>d=e),e(t.exports,"unstable_Profiling",()=>p,e=>p=e),e(t.exports,"unstable_UserBlockingPriority",()=>f,e=>f=e),e(t.exports,"unstable_cancelCallback",()=>m,e=>m=e),e(t.exports,"unstable_forceFrameRate",()=>h,e=>h=e),e(t.exports,"unstable_getCurrentPriorityLevel",()=>g,e=>g=e),e(t.exports,"unstable_next",()=>y,e=>y=e),e(t.exports,"unstable_requestPaint",()=>b,e=>b=e),e(t.exports,"unstable_runWithPriority",()=>v,e=>v=e),e(t.exports,"unstable_scheduleCallback",()=>w,e=>w=e),e(t.exports,"unstable_shouldYield",()=>_,e=>_=e),e(t.exports,"unstable_wrapCallback",()=>k,e=>k=e),s=void 0,"object"==typeof performance&&"function"==typeof performance.now){var s,l,u,c,d,p,f,m,h,g,y,b,v,w,_,k,x,S=performance;s=function(){return S.now()}}else{var A=Date,T=A.now();s=function(){return A.now()-T}}var E=[],I=[],C=1,P=null,L=3,R=!1,M=!1,N=!1,U=!1,O="function"==typeof setTimeout?setTimeout:null,$="function"==typeof clearTimeout?clearTimeout:null,j="undefined"!=typeof setImmediate?setImmediate:null;function D(e){for(var t=a(I);null!==t;){if(null===t.callback)i(I);else if(t.startTime<=e)i(I),t.sortIndex=t.expirationTime,r(E,t);else break;t=a(I)}}function z(e){if(N=!1,D(e),!M)if(null!==a(E))M=!0,F||(F=!0,x());else{var t=a(I);null!==t&&K(z,t.startTime-e)}}var F=!1,B=-1,q=5,V=-1;function H(){return!!U||!(s()-V<q)}function Q(){if(U=!1,F){var e=s();V=e;var t=!0;try{e:{M=!1,N&&(N=!1,$(B),B=-1),R=!0;var n=L;try{t:{for(D(e),P=a(E);null!==P&&!(P.expirationTime>e&&H());){var r=P.callback;if("function"==typeof r){P.callback=null,L=P.priorityLevel;var o=r(P.expirationTime<=e);if(e=s(),"function"==typeof o){P.callback=o,D(e),t=!0;break t}P===a(E)&&i(E),D(e)}else i(E);P=a(E)}if(null!==P)t=!0;else{var l=a(I);null!==l&&K(z,l.startTime-e),t=!1}}break e}finally{P=null,L=n,R=!1}}}finally{t?x():F=!1}}}if("function"==typeof j)x=function(){j(Q)};else if("undefined"!=typeof MessageChannel){var W=new MessageChannel,G=W.port2;W.port1.onmessage=Q,x=function(){G.postMessage(null)}}else x=function(){O(Q,0)};function K(e,t){B=O(function(){e(s())},t)}l=5,u=1,c=4,d=3,p=null,f=2,m=function(e){e.callback=null},h=function(e){0>e||125<e?console.error("forceFrameRate takes a positive int between 0 and 125, forcing frame rates higher than 125 fps is not supported"):q=0<e?Math.floor(1e3/e):5},g=function(){return L},y=function(e){switch(L){case 1:case 2:case 3:var t=3;break;default:t=L}var n=L;L=t;try{return e()}finally{L=n}},b=function(){U=!0},v=function(e,t){switch(e){case 1:case 2:case 3:case 4:case 5:break;default:e=3}var n=L;L=e;try{return t()}finally{L=n}},w=function(e,t,n){var i=s();switch(n="object"==typeof n&&null!==n&&"number"==typeof(n=n.delay)&&0<n?i+n:i,e){case 1:var o=-1;break;case 2:o=250;break;case 5:o=0x3fffffff;break;case 4:o=1e4;break;default:o=5e3}return o=n+o,e={id:C++,callback:t,priorityLevel:e,startTime:n,expirationTime:o,sortIndex:-1},n>i?(e.sortIndex=n,r(I,e),null===a(E)&&e===a(I)&&(N?($(B),B=-1):N=!0,K(z,n-i))):(e.sortIndex=o,r(E,e),M||R||(M=!0,F||(F=!0,x()))),e},_=H,k=function(e){var t=L;return function(){var n=L;L=t;try{return e.apply(this,arguments)}finally{L=n}}}}),f("fYo6y",function(e,t){e.exports=p("lanIS")}),f("d2L2u",function(e,t){!function e(){if("undefined"!=typeof __REACT_DEVTOOLS_GLOBAL_HOOK__&&"function"==typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE)try{__REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE(e)}catch(e){console.error(e)}}(),e.exports=p("hw5nP")}),f("hw5nP",function(t,n){e(t.exports,"__DOM_INTERNALS_DO_NOT_USE_OR_WARN_USERS_THEY_CANNOT_UPGRADE",()=>r,e=>r=e),e(t.exports,"createPortal",()=>a,e=>a=e),e(t.exports,"flushSync",()=>i,e=>i=e),e(t.exports,"preconnect",()=>o,e=>o=e),e(t.exports,"prefetchDNS",()=>s,e=>s=e),e(t.exports,"preinit",()=>l,e=>l=e),e(t.exports,"preinitModule",()=>u,e=>u=e),e(t.exports,"preload",()=>c,e=>c=e),e(t.exports,"preloadModule",()=>d,e=>d=e),e(t.exports,"requestFormReset",()=>f,e=>f=e),e(t.exports,"unstable_batchedUpdates",()=>m,e=>m=e),e(t.exports,"useFormState",()=>h,e=>h=e),e(t.exports,"useFormStatus",()=>g,e=>g=e),e(t.exports,"version",()=>y,e=>y=e);var r,a,i,o,s,l,u,c,d,f,m,h,g,y,b=p("fYo6y");function v(e){var t="https://react.dev/errors/"+e;if(1<arguments.length){t+="?args[]="+encodeURIComponent(arguments[1]);for(var n=2;n<arguments.length;n++)t+="&args[]="+encodeURIComponent(arguments[n])}return"Minified React error #"+e+"; visit "+t+" for the full message or use the non-minified dev environment for full errors and additional helpful warnings."}function w(){}var _={d:{f:w,r:function(){throw Error(v(522))},D:w,C:w,L:w,m:w,X:w,S:w,M:w},p:0,findDOMNode:null},k=Symbol.for("react.portal"),x=b.__CLIENT_INTERNALS_DO_NOT_USE_OR_WARN_USERS_THEY_CANNOT_UPGRADE;function S(e,t){return"font"===e?"":"string"==typeof t?"use-credentials"===t?t:"":void 0}r=_,a=function(e,t){var n=2<arguments.length&&void 0!==arguments[2]?arguments[2]:null;if(!t||1!==t.nodeType&&9!==t.nodeType&&11!==t.nodeType)throw Error(v(299));return function(e,t,n){var r=3<arguments.length&&void 0!==arguments[3]?arguments[3]:null;return{$$typeof:k,key:null==r?null:""+r,children:e,containerInfo:t,implementation:n}}(e,t,null,n)},i=function(e){var t=x.T,n=_.p;try{if(x.T=null,_.p=2,e)return e()}finally{x.T=t,_.p=n,_.d.f()}},o=function(e,t){"string"==typeof e&&(t=t?"string"==typeof(t=t.crossOrigin)?"use-credentials"===t?t:"":void 0:null,_.d.C(e,t))},s=function(e){"string"==typeof e&&_.d.D(e)},l=function(e,t){if("string"==typeof e&&t&&"string"==typeof t.as){var n=t.as,r=S(n,t.crossOrigin),a="string"==typeof t.integrity?t.integrity:void 0,i="string"==typeof t.fetchPriority?t.fetchPriority:void 0;"style"===n?_.d.S(e,"string"==typeof t.precedence?t.precedence:void 0,{crossOrigin:r,integrity:a,fetchPriority:i}):"script"===n&&_.d.X(e,{crossOrigin:r,integrity:a,fetchPriority:i,nonce:"string"==typeof t.nonce?t.nonce:void 0})}},u=function(e,t){if("string"==typeof e)if("object"==typeof t&&null!==t){if(null==t.as||"script"===t.as){var n=S(t.as,t.crossOrigin);_.d.M(e,{crossOrigin:n,integrity:"string"==typeof t.integrity?t.integrity:void 0,nonce:"string"==typeof t.nonce?t.nonce:void 0})}}else null==t&&_.d.M(e)},c=function(e,t){if("string"==typeof e&&"object"==typeof t&&null!==t&&"string"==typeof t.as){var n=t.as,r=S(n,t.crossOrigin);_.d.L(e,n,{crossOrigin:r,integrity:"string"==typeof t.integrity?t.integrity:void 0,nonce:"string"==typeof t.nonce?t.nonce:void 0,type:"string"==typeof t.type?t.type:void 0,fetchPriority:"string"==typeof t.fetchPriority?t.fetchPriority:void 0,referrerPolicy:"string"==typeof t.referrerPolicy?t.referrerPolicy:void 0,imageSrcSet:"string"==typeof t.imageSrcSet?t.imageSrcSet:void 0,imageSizes:"string"==typeof t.imageSizes?t.imageSizes:void 0,media:"string"==typeof t.media?t.media:void 0})}},d=function(e,t){if("string"==typeof e)if(t){var n=S(t.as,t.crossOrigin);_.d.m(e,{as:"string"==typeof t.as&&"script"!==t.as?t.as:void 0,crossOrigin:n,integrity:"string"==typeof t.integrity?t.integrity:void 0})}else _.d.m(e)},f=function(e){_.d.r(e)},m=function(e,t){return e(t)},h=function(e,t,n){return x.H.useFormState(e,t,n)},g=function(){return x.H.useHostTransitionStatus()},y="19.1.1"});var m={};m=p("59OBb"),p("fYo6y");var h={};!function e(){if("undefined"!=typeof __REACT_DEVTOOLS_GLOBAL_HOOK__&&"function"==typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE)try{__REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE(e)}catch(e){console.error(e)}}(),h=p("bgXWC");var g=(p("fYo6y"),p("fYo6y"));const y=(0,g.forwardRef)(({id:e,name:t,rows:n=3},r)=>{let a=(0,g.useRef)();return(0,g.useImperativeHandle)(r,()=>e=>{if(void 0===e)return a.current?.value;a?.current&&(a.current.value=e)}),(0,m.jsxs)("div",{className:"mb-3",children:[(0,m.jsx)("label",{htmlFor:e,className:"form-label",children:t}),(0,m.jsx)("textarea",{ref:a,className:"form-control",id:e,rows:n})]})});var b={},v={};e(v,"request",()=>e5);const w="https://huggingface.co",_="https://router.huggingface.co",k=`${_}/v1`,x={"black-forest-labs":{},cerebras:{},cohere:{},"fal-ai":{},"featherless-ai":{},"fireworks-ai":{},groq:{},"hf-inference":{},hyperbolic:{},nebius:{},novita:{},nscale:{},openai:{},ovhcloud:{},replicate:{},sambanova:{},together:{}};class S extends Error{constructor(e){super(e),this.name="InferenceClientError"}}class A extends S{constructor(e){super(e),this.name="InputError"}}class T extends S{httpRequest;httpResponse;constructor(e,t,n){super(e),this.httpRequest={...t,...t.headers?{headers:{...t.headers,..."Authorization"in t.headers?{Authorization:"Bearer [redacted]"}:void 0}}:void 0},this.httpResponse=n}}class E extends T{constructor(e,t,n){super(e,t,n),this.name="ProviderApiError"}}class I extends T{constructor(e,t,n){super(e,t,n),this.name="HubApiError"}}class C extends S{constructor(e){super(e),this.name="ProviderOutputError"}}function P(e){return Array.isArray(e)?e:[e]}class L{provider;baseUrl;clientSideRoutingOnly;constructor(e,t,n=!1){this.provider=e,this.baseUrl=t,this.clientSideRoutingOnly=n}makeBaseUrl(e){return"provider-key"!==e.authMethod?`${_}/${this.provider}`:this.baseUrl}makeBody(e){return"data"in e.args&&e.args.data?e.args.data:JSON.stringify(this.preparePayload(e))}makeUrl(e){let t=this.makeBaseUrl(e),n=this.makeRoute(e).replace(/^\/+/,"");return`${t}/${n}`}prepareHeaders(e,t){let n={};return"none"!==e.authMethod&&(n.Authorization=`Bearer ${e.accessToken}`),t||(n["Content-Type"]="application/json"),n}}class R extends L{constructor(e,t,n=!1){super(e,t,n)}makeRoute(){return"v1/chat/completions"}preparePayload(e){return{...e.args,model:e.model}}async getResponse(e){if("object"==typeof e&&Array.isArray(e?.choices)&&"number"==typeof e?.created&&"string"==typeof e?.id&&"string"==typeof e?.model&&(void 0===e.system_fingerprint||null===e.system_fingerprint||"string"==typeof e.system_fingerprint)&&"object"==typeof e?.usage)return e;throw new C("Expected ChatCompletionOutput")}}class M extends L{constructor(e,t,n=!1){super(e,t,n)}preparePayload(e){return{...e.args,model:e.model}}makeRoute(){return"v1/completions"}async getResponse(e){let t=P(e);if(Array.isArray(t)&&t.length>0&&t.every(e=>"object"==typeof e&&!!e&&"generated_text"in e&&"string"==typeof e.generated_text))return t[0];throw new C("Expected Array<{generated_text: string}>")}}function N(e){if(globalThis.Buffer)return globalThis.Buffer.from(e).toString("base64");{let t=[];return e.forEach(e=>{t.push(String.fromCharCode(e))}),globalThis.btoa(t.join(""))}}function U(e,t){return e.includes(t)}function O(e,t){let n=Array.isArray(t)?t:[t],r=Object.keys(e).filter(e=>!U(n,e));return Object.assign({},...r.map(t=>{if(void 0!==e[t])return{[t]:e[t]}}))}a=function(e){for(var t,n=e.length,r=n%3,a=[],i=0,o=n-r;i<o;i+=16383)a.push(function(e,t,n){for(var r,a=[],i=t;i<n;i+=3)r=(e[i]<<16&0xff0000)+(e[i+1]<<8&65280)+(255&e[i+2]),a.push($[r>>18&63]+$[r>>12&63]+$[r>>6&63]+$[63&r]);return a.join("")}(e,i,i+16383>o?o:i+16383));return 1===r?a.push($[(t=e[n-1])>>2]+$[t<<4&63]+"=="):2===r&&a.push($[(t=(e[n-2]<<8)+e[n-1])>>10]+$[t>>4&63]+$[t<<2&63]+"="),a.join("")};for(var $=[],j=[],D="undefined"!=typeof Uint8Array?Uint8Array:Array,z="ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/",F=0,B=z.length;F<B;++F)$[F]=z[F],j[z.charCodeAt(F)]=F;j[45]=62,j[95]=63,i=function(e,t,n,r,a){var i,o,s=8*a-r-1,l=(1<<s)-1,u=l>>1,c=-7,d=n?a-1:0,p=n?-1:1,f=e[t+d];for(d+=p,i=f&(1<<-c)-1,f>>=-c,c+=s;c>0;i=256*i+e[t+d],d+=p,c-=8);for(o=i&(1<<-c)-1,i>>=-c,c+=r;c>0;o=256*o+e[t+d],d+=p,c-=8);if(0===i)i=1-u;else{if(i===l)return o?NaN:1/0*(f?-1:1);o+=Math.pow(2,r),i-=u}return(f?-1:1)*o*Math.pow(2,i-r)},o=function(e,t,n,r,a,i){var o,s,l,u=8*i-a-1,c=(1<<u)-1,d=c>>1,p=5960464477539062e-23*(23===a),f=r?0:i-1,m=r?1:-1,h=+(t<0||0===t&&1/t<0);for(isNaN(t=Math.abs(t))||t===1/0?(s=+!!isNaN(t),o=c):(o=Math.floor(Math.log(t)/Math.LN2),t*(l=Math.pow(2,-o))<1&&(o--,l*=2),o+d>=1?t+=p/l:t+=p*Math.pow(2,1-d),t*l>=2&&(o++,l/=2),o+d>=c?(s=0,o=c):o+d>=1?(s=(t*l-1)*Math.pow(2,a),o+=d):(s=t*Math.pow(2,d-1)*Math.pow(2,a),o=0));a>=8;e[n+f]=255&s,f+=m,s/=256,a-=8);for(o=o<<a|s,u+=a;u>0;e[n+f]=255&o,f+=m,o/=256,u-=8);e[n+f-m]|=128*h};const q="function"==typeof Symbol&&"function"==typeof Symbol.for?Symbol.for("nodejs.util.inspect.custom"):null;function V(e){if(e>0x7fffffff)throw RangeError('The value "'+e+'" is invalid for option "size"');let t=new Uint8Array(e);return Object.setPrototypeOf(t,H.prototype),t}function H(e,t,n){if("number"==typeof e){if("string"==typeof t)throw TypeError('The "string" argument must be of type string. Received type number');return G(e)}return Q(e,t,n)}function Q(e,t,n){if("string"==typeof e){var r=e,a=t;if(("string"!=typeof a||""===a)&&(a="utf8"),!H.isEncoding(a))throw TypeError("Unknown encoding: "+a);let n=0|J(r,a),i=V(n),o=i.write(r,a);return o!==n&&(i=i.slice(0,o)),i}if(ArrayBuffer.isView(e)){var i=e;if(e_(i,Uint8Array)){let e=new Uint8Array(i);return X(e.buffer,e.byteOffset,e.byteLength)}return K(i)}if(null==e)throw TypeError("The first argument must be one of type string, Buffer, ArrayBuffer, Array, or Array-like Object. Received type "+typeof e);if(e_(e,ArrayBuffer)||e&&e_(e.buffer,ArrayBuffer)||"undefined"!=typeof SharedArrayBuffer&&(e_(e,SharedArrayBuffer)||e&&e_(e.buffer,SharedArrayBuffer)))return X(e,t,n);if("number"==typeof e)throw TypeError('The "value" argument must not be of type number. Received type number');let o=e.valueOf&&e.valueOf();if(null!=o&&o!==e)return H.from(o,t,n);let s=function(e){if(H.isBuffer(e)){let t=0|Y(e.length),n=V(t);return 0===n.length||e.copy(n,0,0,t),n}return void 0!==e.length?"number"!=typeof e.length||function(e){return e!=e}(e.length)?V(0):K(e):"Buffer"===e.type&&Array.isArray(e.data)?K(e.data):void 0}(e);if(s)return s;if("undefined"!=typeof Symbol&&null!=Symbol.toPrimitive&&"function"==typeof e[Symbol.toPrimitive])return H.from(e[Symbol.toPrimitive]("string"),t,n);throw TypeError("The first argument must be one of type string, Buffer, ArrayBuffer, Array, or Array-like Object. Received type "+typeof e)}function W(e){if("number"!=typeof e)throw TypeError('"size" argument must be of type number');if(e<0)throw RangeError('The value "'+e+'" is invalid for option "size"')}function G(e){return W(e),V(e<0?0:0|Y(e))}function K(e){let t=e.length<0?0:0|Y(e.length),n=V(t);for(let r=0;r<t;r+=1)n[r]=255&e[r];return n}function X(e,t,n){let r;if(t<0||e.byteLength<t)throw RangeError('"offset" is outside of buffer bounds');if(e.byteLength<t+(n||0))throw RangeError('"length" is outside of buffer bounds');return Object.setPrototypeOf(r=void 0===t&&void 0===n?new Uint8Array(e):void 0===n?new Uint8Array(e,t):new Uint8Array(e,t,n),H.prototype),r}function Y(e){if(e>=0x7fffffff)throw RangeError("Attempt to allocate Buffer larger than maximum size: 0x7fffffff bytes");return 0|e}function J(e,t){if(H.isBuffer(e))return e.length;if(ArrayBuffer.isView(e)||e_(e,ArrayBuffer))return e.byteLength;if("string"!=typeof e)throw TypeError('The "string" argument must be one of type string, Buffer, or ArrayBuffer. Received type '+typeof e);let n=e.length,r=arguments.length>2&&!0===arguments[2];if(!r&&0===n)return 0;let a=!1;for(;;)switch(t){case"ascii":case"latin1":case"binary":return n;case"utf8":case"utf-8":return eb(e).length;case"ucs2":case"ucs-2":case"utf16le":case"utf-16le":return 2*n;case"hex":return n>>>1;case"base64":return ev(e).length;default:if(a)return r?-1:eb(e).length;t=(""+t).toLowerCase(),a=!0}}function Z(e,t,n){let r=!1;if((void 0===t||t<0)&&(t=0),t>this.length||((void 0===n||n>this.length)&&(n=this.length),n<=0||(n>>>=0)<=(t>>>=0)))return"";for(e||(e="utf8");;)switch(e){case"hex":return function(e,t,n){let r=e.length;(!t||t<0)&&(t=0),(!n||n<0||n>r)&&(n=r);let a="";for(let r=t;r<n;++r)a+=ek[e[r]];return a}(this,t,n);case"utf8":case"utf-8":return er(this,t,n);case"ascii":return function(e,t,n){let r="";n=Math.min(e.length,n);for(let a=t;a<n;++a)r+=String.fromCharCode(127&e[a]);return r}(this,t,n);case"latin1":case"binary":return function(e,t,n){let r="";n=Math.min(e.length,n);for(let a=t;a<n;++a)r+=String.fromCharCode(e[a]);return r}(this,t,n);case"base64":var i,o,s;return i=this,o=t,s=n,0===o&&s===i.length?a(i):a(i.slice(o,s));case"ucs2":case"ucs-2":case"utf16le":case"utf-16le":return function(e,t,n){let r=e.slice(t,n),a="";for(let e=0;e<r.length-1;e+=2)a+=String.fromCharCode(r[e]+256*r[e+1]);return a}(this,t,n);default:if(r)throw TypeError("Unknown encoding: "+e);e=(e+"").toLowerCase(),r=!0}}function ee(e,t,n){let r=e[t];e[t]=e[n],e[n]=r}function et(e,t,n,r,a){var i;if(0===e.length)return -1;if("string"==typeof n?(r=n,n=0):n>0x7fffffff?n=0x7fffffff:n<-0x80000000&&(n=-0x80000000),(i=n*=1)!=i&&(n=a?0:e.length-1),n<0&&(n=e.length+n),n>=e.length)if(a)return -1;else n=e.length-1;else if(n<0)if(!a)return -1;else n=0;if("string"==typeof t&&(t=H.from(t,r)),H.isBuffer(t))return 0===t.length?-1:en(e,t,n,r,a);if("number"==typeof t){if(t&=255,"function"==typeof Uint8Array.prototype.indexOf)if(a)return Uint8Array.prototype.indexOf.call(e,t,n);else return Uint8Array.prototype.lastIndexOf.call(e,t,n);return en(e,[t],n,r,a)}throw TypeError("val must be string, number or Buffer")}function en(e,t,n,r,a){let i,o=1,s=e.length,l=t.length;if(void 0!==r&&("ucs2"===(r=String(r).toLowerCase())||"ucs-2"===r||"utf16le"===r||"utf-16le"===r)){if(e.length<2||t.length<2)return -1;o=2,s/=2,l/=2,n/=2}function u(e,t){return 1===o?e[t]:e.readUInt16BE(t*o)}if(a){let r=-1;for(i=n;i<s;i++)if(u(e,i)===u(t,-1===r?0:i-r)){if(-1===r&&(r=i),i-r+1===l)return r*o}else -1!==r&&(i-=i-r),r=-1}else for(n+l>s&&(n=s-l),i=n;i>=0;i--){let n=!0;for(let r=0;r<l;r++)if(u(e,i+r)!==u(t,r)){n=!1;break}if(n)return i}return -1}function er(e,t,n){n=Math.min(e.length,n);let r=[],a=t;for(;a<n;){let t=e[a],i=null,o=t>239?4:t>223?3:t>191?2:1;if(a+o<=n){let n,r,s,l;switch(o){case 1:t<128&&(i=t);break;case 2:(192&(n=e[a+1]))==128&&(l=(31&t)<<6|63&n)>127&&(i=l);break;case 3:n=e[a+1],r=e[a+2],(192&n)==128&&(192&r)==128&&(l=(15&t)<<12|(63&n)<<6|63&r)>2047&&(l<55296||l>57343)&&(i=l);break;case 4:n=e[a+1],r=e[a+2],s=e[a+3],(192&n)==128&&(192&r)==128&&(192&s)==128&&(l=(15&t)<<18|(63&n)<<12|(63&r)<<6|63&s)>65535&&l<1114112&&(i=l)}}null===i?(i=65533,o=1):i>65535&&(i-=65536,r.push(i>>>10&1023|55296),i=56320|1023&i),r.push(i),a+=o}var i=r;let o=i.length;if(o<=4096)return String.fromCharCode.apply(String,i);let s="",l=0;for(;l<o;)s+=String.fromCharCode.apply(String,i.slice(l,l+=4096));return s}function ea(e,t,n){if(e%1!=0||e<0)throw RangeError("offset is not uint");if(e+t>n)throw RangeError("Trying to access beyond buffer length")}function ei(e,t,n,r,a,i){if(!H.isBuffer(e))throw TypeError('"buffer" argument must be a Buffer instance');if(t>a||t<i)throw RangeError('"value" argument is out of bounds');if(n+r>e.length)throw RangeError("Index out of range")}function eo(e,t,n,r,a){em(t,r,a,e,n,7);let i=Number(t&BigInt(0xffffffff));e[n++]=i,i>>=8,e[n++]=i,i>>=8,e[n++]=i,i>>=8,e[n++]=i;let o=Number(t>>BigInt(32)&BigInt(0xffffffff));return e[n++]=o,o>>=8,e[n++]=o,o>>=8,e[n++]=o,o>>=8,e[n++]=o,n}function es(e,t,n,r,a){em(t,r,a,e,n,7);let i=Number(t&BigInt(0xffffffff));e[n+7]=i,i>>=8,e[n+6]=i,i>>=8,e[n+5]=i,i>>=8,e[n+4]=i;let o=Number(t>>BigInt(32)&BigInt(0xffffffff));return e[n+3]=o,o>>=8,e[n+2]=o,o>>=8,e[n+1]=o,o>>=8,e[n]=o,n+8}function el(e,t,n,r,a,i){if(n+r>e.length||n<0)throw RangeError("Index out of range")}function eu(e,t,n,r,a){return t*=1,n>>>=0,a||el(e,t,n,4,34028234663852886e22,-34028234663852886e22),o(e,t,n,r,23,4),n+4}function ec(e,t,n,r,a){return t*=1,n>>>=0,a||el(e,t,n,8,17976931348623157e292,-17976931348623157e292),o(e,t,n,r,52,8),n+8}H.TYPED_ARRAY_SUPPORT=function(){try{let e=new Uint8Array(1),t={foo:function(){return 42}};return Object.setPrototypeOf(t,Uint8Array.prototype),Object.setPrototypeOf(e,t),42===e.foo()}catch(e){return!1}}(),H.TYPED_ARRAY_SUPPORT||"undefined"==typeof console||"function"!=typeof console.error||console.error("This browser lacks typed array (Uint8Array) support which is required by `buffer` v5.x. Use `buffer` v4.x if you require old browser support."),Object.defineProperty(H.prototype,"parent",{enumerable:!0,get:function(){if(H.isBuffer(this))return this.buffer}}),Object.defineProperty(H.prototype,"offset",{enumerable:!0,get:function(){if(H.isBuffer(this))return this.byteOffset}}),H.poolSize=8192,H.from=function(e,t,n){return Q(e,t,n)},Object.setPrototypeOf(H.prototype,Uint8Array.prototype),Object.setPrototypeOf(H,Uint8Array),H.alloc=function(e,t,n){return(W(e),e<=0)?V(e):void 0!==t?"string"==typeof n?V(e).fill(t,n):V(e).fill(t):V(e)},H.allocUnsafe=function(e){return G(e)},H.allocUnsafeSlow=function(e){return G(e)},H.isBuffer=function(e){return null!=e&&!0===e._isBuffer&&e!==H.prototype},H.compare=function(e,t){if(e_(e,Uint8Array)&&(e=H.from(e,e.offset,e.byteLength)),e_(t,Uint8Array)&&(t=H.from(t,t.offset,t.byteLength)),!H.isBuffer(e)||!H.isBuffer(t))throw TypeError('The "buf1", "buf2" arguments must be one of type Buffer or Uint8Array');if(e===t)return 0;let n=e.length,r=t.length;for(let a=0,i=Math.min(n,r);a<i;++a)if(e[a]!==t[a]){n=e[a],r=t[a];break}return n<r?-1:+(r<n)},H.isEncoding=function(e){switch(String(e).toLowerCase()){case"hex":case"utf8":case"utf-8":case"ascii":case"latin1":case"binary":case"base64":case"ucs2":case"ucs-2":case"utf16le":case"utf-16le":return!0;default:return!1}},H.concat=function(e,t){let n;if(!Array.isArray(e))throw TypeError('"list" argument must be an Array of Buffers');if(0===e.length)return H.alloc(0);if(void 0===t)for(n=0,t=0;n<e.length;++n)t+=e[n].length;let r=H.allocUnsafe(t),a=0;for(n=0;n<e.length;++n){let t=e[n];if(e_(t,Uint8Array))a+t.length>r.length?(H.isBuffer(t)||(t=H.from(t)),t.copy(r,a)):Uint8Array.prototype.set.call(r,t,a);else if(H.isBuffer(t))t.copy(r,a);else throw TypeError('"list" argument must be an Array of Buffers');a+=t.length}return r},H.byteLength=J,H.prototype._isBuffer=!0,H.prototype.swap16=function(){let e=this.length;if(e%2!=0)throw RangeError("Buffer size must be a multiple of 16-bits");for(let t=0;t<e;t+=2)ee(this,t,t+1);return this},H.prototype.swap32=function(){let e=this.length;if(e%4!=0)throw RangeError("Buffer size must be a multiple of 32-bits");for(let t=0;t<e;t+=4)ee(this,t,t+3),ee(this,t+1,t+2);return this},H.prototype.swap64=function(){let e=this.length;if(e%8!=0)throw RangeError("Buffer size must be a multiple of 64-bits");for(let t=0;t<e;t+=8)ee(this,t,t+7),ee(this,t+1,t+6),ee(this,t+2,t+5),ee(this,t+3,t+4);return this},H.prototype.toString=function(){let e=this.length;return 0===e?"":0==arguments.length?er(this,0,e):Z.apply(this,arguments)},H.prototype.toLocaleString=H.prototype.toString,H.prototype.equals=function(e){if(!H.isBuffer(e))throw TypeError("Argument must be a Buffer");return this===e||0===H.compare(this,e)},H.prototype.inspect=function(){let e="";return e=this.toString("hex",0,50).replace(/(.{2})/g,"$1 ").trim(),this.length>50&&(e+=" ... "),"<Buffer "+e+">"},q&&(H.prototype[q]=H.prototype.inspect),H.prototype.compare=function(e,t,n,r,a){if(e_(e,Uint8Array)&&(e=H.from(e,e.offset,e.byteLength)),!H.isBuffer(e))throw TypeError('The "target" argument must be one of type Buffer or Uint8Array. Received type '+typeof e);if(void 0===t&&(t=0),void 0===n&&(n=e?e.length:0),void 0===r&&(r=0),void 0===a&&(a=this.length),t<0||n>e.length||r<0||a>this.length)throw RangeError("out of range index");if(r>=a&&t>=n)return 0;if(r>=a)return -1;if(t>=n)return 1;if(t>>>=0,n>>>=0,r>>>=0,a>>>=0,this===e)return 0;let i=a-r,o=n-t,s=Math.min(i,o),l=this.slice(r,a),u=e.slice(t,n);for(let e=0;e<s;++e)if(l[e]!==u[e]){i=l[e],o=u[e];break}return i<o?-1:+(o<i)},H.prototype.includes=function(e,t,n){return -1!==this.indexOf(e,t,n)},H.prototype.indexOf=function(e,t,n){return et(this,e,t,n,!0)},H.prototype.lastIndexOf=function(e,t,n){return et(this,e,t,n,!1)},H.prototype.write=function(e,t,n,r){var a,i,o,s,l,u,c,d;if(void 0===t)r="utf8",n=this.length,t=0;else if(void 0===n&&"string"==typeof t)r=t,n=this.length,t=0;else if(isFinite(t))t>>>=0,isFinite(n)?(n>>>=0,void 0===r&&(r="utf8")):(r=n,n=void 0);else throw Error("Buffer.write(string, encoding, offset[, length]) is no longer supported");let p=this.length-t;if((void 0===n||n>p)&&(n=p),e.length>0&&(n<0||t<0)||t>this.length)throw RangeError("Attempt to write outside buffer bounds");r||(r="utf8");let f=!1;for(;;)switch(r){case"hex":return function(e,t,n,r){let a;n=Number(n)||0;let i=e.length-n;r?(r=Number(r))>i&&(r=i):r=i;let o=t.length;for(r>o/2&&(r=o/2),a=0;a<r;++a){var s;let r=parseInt(t.substr(2*a,2),16);if((s=r)!=s)break;e[n+a]=r}return a}(this,e,t,n);case"utf8":case"utf-8":return a=t,i=n,ew(eb(e,this.length-a),this,a,i);case"ascii":case"latin1":case"binary":return o=t,s=n,ew(function(e){let t=[];for(let n=0;n<e.length;++n)t.push(255&e.charCodeAt(n));return t}(e),this,o,s);case"base64":return l=t,u=n,ew(ev(e),this,l,u);case"ucs2":case"ucs-2":case"utf16le":case"utf-16le":return c=t,d=n,ew(function(e,t){let n,r,a=[];for(let i=0;i<e.length&&!((t-=2)<0);++i)r=(n=e.charCodeAt(i))>>8,a.push(n%256),a.push(r);return a}(e,this.length-c),this,c,d);default:if(f)throw TypeError("Unknown encoding: "+r);r=(""+r).toLowerCase(),f=!0}},H.prototype.toJSON=function(){return{type:"Buffer",data:Array.prototype.slice.call(this._arr||this,0)}},H.prototype.slice=function(e,t){let n=this.length;e=~~e,t=void 0===t?n:~~t,e<0?(e+=n)<0&&(e=0):e>n&&(e=n),t<0?(t+=n)<0&&(t=0):t>n&&(t=n),t<e&&(t=e);let r=this.subarray(e,t);return Object.setPrototypeOf(r,H.prototype),r},H.prototype.readUintLE=H.prototype.readUIntLE=function(e,t,n){e>>>=0,t>>>=0,n||ea(e,t,this.length);let r=this[e],a=1,i=0;for(;++i<t&&(a*=256);)r+=this[e+i]*a;return r},H.prototype.readUintBE=H.prototype.readUIntBE=function(e,t,n){e>>>=0,t>>>=0,n||ea(e,t,this.length);let r=this[e+--t],a=1;for(;t>0&&(a*=256);)r+=this[e+--t]*a;return r},H.prototype.readUint8=H.prototype.readUInt8=function(e,t){return e>>>=0,t||ea(e,1,this.length),this[e]},H.prototype.readUint16LE=H.prototype.readUInt16LE=function(e,t){return e>>>=0,t||ea(e,2,this.length),this[e]|this[e+1]<<8},H.prototype.readUint16BE=H.prototype.readUInt16BE=function(e,t){return e>>>=0,t||ea(e,2,this.length),this[e]<<8|this[e+1]},H.prototype.readUint32LE=H.prototype.readUInt32LE=function(e,t){return e>>>=0,t||ea(e,4,this.length),(this[e]|this[e+1]<<8|this[e+2]<<16)+0x1000000*this[e+3]},H.prototype.readUint32BE=H.prototype.readUInt32BE=function(e,t){return e>>>=0,t||ea(e,4,this.length),0x1000000*this[e]+(this[e+1]<<16|this[e+2]<<8|this[e+3])},H.prototype.readBigUInt64LE=ex(function(e){eh(e>>>=0,"offset");let t=this[e],n=this[e+7];(void 0===t||void 0===n)&&eg(e,this.length-8);let r=t+256*this[++e]+65536*this[++e]+0x1000000*this[++e],a=this[++e]+256*this[++e]+65536*this[++e]+0x1000000*n;return BigInt(r)+(BigInt(a)<<BigInt(32))}),H.prototype.readBigUInt64BE=ex(function(e){eh(e>>>=0,"offset");let t=this[e],n=this[e+7];(void 0===t||void 0===n)&&eg(e,this.length-8);let r=0x1000000*t+65536*this[++e]+256*this[++e]+this[++e],a=0x1000000*this[++e]+65536*this[++e]+256*this[++e]+n;return(BigInt(r)<<BigInt(32))+BigInt(a)}),H.prototype.readIntLE=function(e,t,n){e>>>=0,t>>>=0,n||ea(e,t,this.length);let r=this[e],a=1,i=0;for(;++i<t&&(a*=256);)r+=this[e+i]*a;return r>=(a*=128)&&(r-=Math.pow(2,8*t)),r},H.prototype.readIntBE=function(e,t,n){e>>>=0,t>>>=0,n||ea(e,t,this.length);let r=t,a=1,i=this[e+--r];for(;r>0&&(a*=256);)i+=this[e+--r]*a;return i>=(a*=128)&&(i-=Math.pow(2,8*t)),i},H.prototype.readInt8=function(e,t){return(e>>>=0,t||ea(e,1,this.length),128&this[e])?-((255-this[e]+1)*1):this[e]},H.prototype.readInt16LE=function(e,t){e>>>=0,t||ea(e,2,this.length);let n=this[e]|this[e+1]<<8;return 32768&n?0xffff0000|n:n},H.prototype.readInt16BE=function(e,t){e>>>=0,t||ea(e,2,this.length);let n=this[e+1]|this[e]<<8;return 32768&n?0xffff0000|n:n},H.prototype.readInt32LE=function(e,t){return e>>>=0,t||ea(e,4,this.length),this[e]|this[e+1]<<8|this[e+2]<<16|this[e+3]<<24},H.prototype.readInt32BE=function(e,t){return e>>>=0,t||ea(e,4,this.length),this[e]<<24|this[e+1]<<16|this[e+2]<<8|this[e+3]},H.prototype.readBigInt64LE=ex(function(e){eh(e>>>=0,"offset");let t=this[e],n=this[e+7];return(void 0===t||void 0===n)&&eg(e,this.length-8),(BigInt(this[e+4]+256*this[e+5]+65536*this[e+6]+(n<<24))<<BigInt(32))+BigInt(t+256*this[++e]+65536*this[++e]+0x1000000*this[++e])}),H.prototype.readBigInt64BE=ex(function(e){eh(e>>>=0,"offset");let t=this[e],n=this[e+7];return(void 0===t||void 0===n)&&eg(e,this.length-8),(BigInt((t<<24)+65536*this[++e]+256*this[++e]+this[++e])<<BigInt(32))+BigInt(0x1000000*this[++e]+65536*this[++e]+256*this[++e]+n)}),H.prototype.readFloatLE=function(e,t){return e>>>=0,t||ea(e,4,this.length),i(this,e,!0,23,4)},H.prototype.readFloatBE=function(e,t){return e>>>=0,t||ea(e,4,this.length),i(this,e,!1,23,4)},H.prototype.readDoubleLE=function(e,t){return e>>>=0,t||ea(e,8,this.length),i(this,e,!0,52,8)},H.prototype.readDoubleBE=function(e,t){return e>>>=0,t||ea(e,8,this.length),i(this,e,!1,52,8)},H.prototype.writeUintLE=H.prototype.writeUIntLE=function(e,t,n,r){if(e*=1,t>>>=0,n>>>=0,!r){let r=Math.pow(2,8*n)-1;ei(this,e,t,n,r,0)}let a=1,i=0;for(this[t]=255&e;++i<n&&(a*=256);)this[t+i]=e/a&255;return t+n},H.prototype.writeUintBE=H.prototype.writeUIntBE=function(e,t,n,r){if(e*=1,t>>>=0,n>>>=0,!r){let r=Math.pow(2,8*n)-1;ei(this,e,t,n,r,0)}let a=n-1,i=1;for(this[t+a]=255&e;--a>=0&&(i*=256);)this[t+a]=e/i&255;return t+n},H.prototype.writeUint8=H.prototype.writeUInt8=function(e,t,n){return e*=1,t>>>=0,n||ei(this,e,t,1,255,0),this[t]=255&e,t+1},H.prototype.writeUint16LE=H.prototype.writeUInt16LE=function(e,t,n){return e*=1,t>>>=0,n||ei(this,e,t,2,65535,0),this[t]=255&e,this[t+1]=e>>>8,t+2},H.prototype.writeUint16BE=H.prototype.writeUInt16BE=function(e,t,n){return e*=1,t>>>=0,n||ei(this,e,t,2,65535,0),this[t]=e>>>8,this[t+1]=255&e,t+2},H.prototype.writeUint32LE=H.prototype.writeUInt32LE=function(e,t,n){return e*=1,t>>>=0,n||ei(this,e,t,4,0xffffffff,0),this[t+3]=e>>>24,this[t+2]=e>>>16,this[t+1]=e>>>8,this[t]=255&e,t+4},H.prototype.writeUint32BE=H.prototype.writeUInt32BE=function(e,t,n){return e*=1,t>>>=0,n||ei(this,e,t,4,0xffffffff,0),this[t]=e>>>24,this[t+1]=e>>>16,this[t+2]=e>>>8,this[t+3]=255&e,t+4},H.prototype.writeBigUInt64LE=ex(function(e,t=0){return eo(this,e,t,BigInt(0),BigInt("0xffffffffffffffff"))}),H.prototype.writeBigUInt64BE=ex(function(e,t=0){return es(this,e,t,BigInt(0),BigInt("0xffffffffffffffff"))}),H.prototype.writeIntLE=function(e,t,n,r){if(e*=1,t>>>=0,!r){let r=Math.pow(2,8*n-1);ei(this,e,t,n,r-1,-r)}let a=0,i=1,o=0;for(this[t]=255&e;++a<n&&(i*=256);)e<0&&0===o&&0!==this[t+a-1]&&(o=1),this[t+a]=(e/i|0)-o&255;return t+n},H.prototype.writeIntBE=function(e,t,n,r){if(e*=1,t>>>=0,!r){let r=Math.pow(2,8*n-1);ei(this,e,t,n,r-1,-r)}let a=n-1,i=1,o=0;for(this[t+a]=255&e;--a>=0&&(i*=256);)e<0&&0===o&&0!==this[t+a+1]&&(o=1),this[t+a]=(e/i|0)-o&255;return t+n},H.prototype.writeInt8=function(e,t,n){return e*=1,t>>>=0,n||ei(this,e,t,1,127,-128),e<0&&(e=255+e+1),this[t]=255&e,t+1},H.prototype.writeInt16LE=function(e,t,n){return e*=1,t>>>=0,n||ei(this,e,t,2,32767,-32768),this[t]=255&e,this[t+1]=e>>>8,t+2},H.prototype.writeInt16BE=function(e,t,n){return e*=1,t>>>=0,n||ei(this,e,t,2,32767,-32768),this[t]=e>>>8,this[t+1]=255&e,t+2},H.prototype.writeInt32LE=function(e,t,n){return e*=1,t>>>=0,n||ei(this,e,t,4,0x7fffffff,-0x80000000),this[t]=255&e,this[t+1]=e>>>8,this[t+2]=e>>>16,this[t+3]=e>>>24,t+4},H.prototype.writeInt32BE=function(e,t,n){return e*=1,t>>>=0,n||ei(this,e,t,4,0x7fffffff,-0x80000000),e<0&&(e=0xffffffff+e+1),this[t]=e>>>24,this[t+1]=e>>>16,this[t+2]=e>>>8,this[t+3]=255&e,t+4},H.prototype.writeBigInt64LE=ex(function(e,t=0){return eo(this,e,t,-BigInt("0x8000000000000000"),BigInt("0x7fffffffffffffff"))}),H.prototype.writeBigInt64BE=ex(function(e,t=0){return es(this,e,t,-BigInt("0x8000000000000000"),BigInt("0x7fffffffffffffff"))}),H.prototype.writeFloatLE=function(e,t,n){return eu(this,e,t,!0,n)},H.prototype.writeFloatBE=function(e,t,n){return eu(this,e,t,!1,n)},H.prototype.writeDoubleLE=function(e,t,n){return ec(this,e,t,!0,n)},H.prototype.writeDoubleBE=function(e,t,n){return ec(this,e,t,!1,n)},H.prototype.copy=function(e,t,n,r){if(!H.isBuffer(e))throw TypeError("argument should be a Buffer");if(n||(n=0),r||0===r||(r=this.length),t>=e.length&&(t=e.length),t||(t=0),r>0&&r<n&&(r=n),r===n||0===e.length||0===this.length)return 0;if(t<0)throw RangeError("targetStart out of bounds");if(n<0||n>=this.length)throw RangeError("Index out of range");if(r<0)throw RangeError("sourceEnd out of bounds");r>this.length&&(r=this.length),e.length-t<r-n&&(r=e.length-t+n);let a=r-n;return this===e&&"function"==typeof Uint8Array.prototype.copyWithin?this.copyWithin(t,n,r):Uint8Array.prototype.set.call(e,this.subarray(n,r),t),a},H.prototype.fill=function(e,t,n,r){let a;if("string"==typeof e){if("string"==typeof t?(r=t,t=0,n=this.length):"string"==typeof n&&(r=n,n=this.length),void 0!==r&&"string"!=typeof r)throw TypeError("encoding must be a string");if("string"==typeof r&&!H.isEncoding(r))throw TypeError("Unknown encoding: "+r);if(1===e.length){let t=e.charCodeAt(0);("utf8"===r&&t<128||"latin1"===r)&&(e=t)}}else"number"==typeof e?e&=255:"boolean"==typeof e&&(e=Number(e));if(t<0||this.length<t||this.length<n)throw RangeError("Out of range index");if(n<=t)return this;if(t>>>=0,n=void 0===n?this.length:n>>>0,e||(e=0),"number"==typeof e)for(a=t;a<n;++a)this[a]=e;else{let i=H.isBuffer(e)?e:H.from(e,r),o=i.length;if(0===o)throw TypeError('The value "'+e+'" is invalid for argument "value"');for(a=0;a<n-t;++a)this[a+t]=i[a%o]}return this};const ed={};function ep(e,t,n){ed[e]=class extends n{constructor(){super(),Object.defineProperty(this,"message",{value:t.apply(this,arguments),writable:!0,configurable:!0}),this.name=`${this.name} [${e}]`,this.stack,delete this.name}get code(){return e}set code(e){Object.defineProperty(this,"code",{configurable:!0,enumerable:!0,value:e,writable:!0})}toString(){return`${this.name} [${e}]: ${this.message}`}}}function ef(e){let t="",n=e.length,r=+("-"===e[0]);for(;n>=r+4;n-=3)t=`_${e.slice(n-3,n)}${t}`;return`${e.slice(0,n)}${t}`}function em(e,t,n,r,a,i){if(e>n||e<t){let r,a="bigint"==typeof t?"n":"";throw r=i>3?0===t||t===BigInt(0)?`>= 0${a} and < 2${a} ** ${(i+1)*8}${a}`:`>= -(2${a} ** ${(i+1)*8-1}${a}) and < 2 ** ${(i+1)*8-1}${a}`:`>= ${t}${a} and <= ${n}${a}`,new ed.ERR_OUT_OF_RANGE("value",r,e)}eh(a,"offset"),(void 0===r[a]||void 0===r[a+i])&&eg(a,r.length-(i+1))}function eh(e,t){if("number"!=typeof e)throw new ed.ERR_INVALID_ARG_TYPE(t,"number",e)}function eg(e,t,n){if(Math.floor(e)!==e)throw eh(e,n),new ed.ERR_OUT_OF_RANGE(n||"offset","an integer",e);if(t<0)throw new ed.ERR_BUFFER_OUT_OF_BOUNDS;throw new ed.ERR_OUT_OF_RANGE(n||"offset",`>= ${+!!n} and <= ${t}`,e)}ep("ERR_BUFFER_OUT_OF_BOUNDS",function(e){return e?`${e} is outside of buffer bounds`:"Attempt to access memory outside buffer bounds"},RangeError),ep("ERR_INVALID_ARG_TYPE",function(e,t){return`The "${e}" argument must be of type number. Received type ${typeof t}`},TypeError),ep("ERR_OUT_OF_RANGE",function(e,t,n){let r=`The value of "${e}" is out of range.`,a=n;return Number.isInteger(n)&&Math.abs(n)>0x100000000?a=ef(String(n)):"bigint"==typeof n&&(a=String(n),(n>BigInt(2)**BigInt(32)||n<-(BigInt(2)**BigInt(32)))&&(a=ef(a)),a+="n"),r+=` It must be ${t}. Received ${a}`},RangeError);const ey=/[^+/0-9A-Za-z-_]/g;function eb(e,t){let n;t=t||1/0;let r=e.length,a=null,i=[];for(let o=0;o<r;++o){if((n=e.charCodeAt(o))>55295&&n<57344){if(!a){if(n>56319||o+1===r){(t-=3)>-1&&i.push(239,191,189);continue}a=n;continue}if(n<56320){(t-=3)>-1&&i.push(239,191,189),a=n;continue}n=(a-55296<<10|n-56320)+65536}else a&&(t-=3)>-1&&i.push(239,191,189);if(a=null,n<128){if((t-=1)<0)break;i.push(n)}else if(n<2048){if((t-=2)<0)break;i.push(n>>6|192,63&n|128)}else if(n<65536){if((t-=3)<0)break;i.push(n>>12|224,n>>6&63|128,63&n|128)}else if(n<1114112){if((t-=4)<0)break;i.push(n>>18|240,n>>12&63|128,n>>6&63|128,63&n|128)}else throw Error("Invalid code point")}return i}function ev(e){return function(e){var t,n,r=function(e){var t=e.length;if(t%4>0)throw Error("Invalid string. Length must be a multiple of 4");var n=e.indexOf("=");-1===n&&(n=t);var r=n===t?0:4-n%4;return[n,r]}(e),a=r[0],i=r[1],o=new D((a+i)*3/4-i),s=0,l=i>0?a-4:a;for(n=0;n<l;n+=4)t=j[e.charCodeAt(n)]<<18|j[e.charCodeAt(n+1)]<<12|j[e.charCodeAt(n+2)]<<6|j[e.charCodeAt(n+3)],o[s++]=t>>16&255,o[s++]=t>>8&255,o[s++]=255&t;return 2===i&&(t=j[e.charCodeAt(n)]<<2|j[e.charCodeAt(n+1)]>>4,o[s++]=255&t),1===i&&(t=j[e.charCodeAt(n)]<<10|j[e.charCodeAt(n+1)]<<4|j[e.charCodeAt(n+2)]>>2,o[s++]=t>>8&255,o[s++]=255&t),o}(function(e){if((e=(e=e.split("=")[0]).trim().replace(ey,"")).length<2)return"";for(;e.length%4!=0;)e+="=";return e}(e))}function ew(e,t,n,r){let a;for(a=0;a<r&&!(a+n>=t.length)&&!(a>=e.length);++a)t[a+n]=e[a];return a}function e_(e,t){return e instanceof t||null!=e&&null!=e.constructor&&null!=e.constructor.name&&e.constructor.name===t.name}const ek=function(){let e="0123456789abcdef",t=Array(256);for(let n=0;n<16;++n){let r=16*n;for(let a=0;a<16;++a)t[r+a]=e[n]+e[a]}return t}();function ex(e){return"undefined"==typeof BigInt?eS:e}function eS(){throw Error("BigInt not supported")}const eA=["feature-extraction","sentence-similarity"];class eT extends L{constructor(){super("hf-inference",`${_}/hf-inference`)}preparePayload(e){return e.args}makeUrl(e){return e.model.startsWith("http://")||e.model.startsWith("https://")?e.model:super.makeUrl(e)}makeRoute(e){return e.task&&["feature-extraction","sentence-similarity"].includes(e.task)?`models/${e.model}/pipeline/${e.task}`:`models/${e.model}`}async getResponse(e){return e}}class eE extends eT{async getResponse(e){if("object"==typeof e&&null!==e&&"labels"in e&&"scores"in e&&Array.isArray(e.labels)&&Array.isArray(e.scores)&&e.labels.length===e.scores.length&&e.labels.every(e=>"string"==typeof e)&&e.scores.every(e=>"number"==typeof e)){let t=e.scores;return e.labels.map((e,n)=>({label:e,score:t[n]}))}if(Array.isArray(e)&&e.every(eE.validateOutputElement))return e;throw new C("Received malformed response from HF-Inference zero-shot-classification API: expected Array<{label: string, score: number}>")}static validateOutputElement(e){return"object"==typeof e&&!!e&&"label"in e&&"score"in e&&"string"==typeof e.label&&"number"==typeof e.score}}class eI extends eT{static validate(e){return"object"==typeof e&&!!e&&"aggregator"in e&&"string"==typeof e.aggregator&&"answer"in e&&"string"==typeof e.answer&&"cells"in e&&Array.isArray(e.cells)&&e.cells.every(e=>"string"==typeof e)&&"coordinates"in e&&Array.isArray(e.coordinates)&&e.coordinates.every(e=>Array.isArray(e)&&e.every(e=>"number"==typeof e))}async getResponse(e){if(Array.isArray(e)&&Array.isArray(e)?e.every(e=>eI.validate(e)):eI.validate(e))return Array.isArray(e)?e[0]:e;throw new C("Received malformed response from HF-Inference table-question-answering API: expected {aggregator: string, answer: string, cells: string[], coordinates: number[][]}")}}let eC=console;const eP=new Map;async function eL(e,t,n){let r;if(eP.has(e))r=eP.get(e);else{var a;let i=`${w}/api/models/${e}?expand[]=inferenceProviderMapping`,o=await (n?.fetch??fetch)(i,{headers:t?.startsWith("hf_")?{Authorization:`Bearer ${t}`}:{}});if(!o.ok)if(o.headers.get("Content-Type")?.startsWith("application/json")){let t=await o.json();if("error"in t&&"string"==typeof t.error)throw new I(`Failed to fetch inference provider mapping for model ${e}: ${t.error}`,{url:i,method:"GET"},{requestId:o.headers.get("x-request-id")??"",status:o.status,body:t})}else throw new I(`Failed to fetch inference provider mapping for model ${e}`,{url:i,method:"GET"},{requestId:o.headers.get("x-request-id")??"",status:o.status,body:await o.text()});let s=null;try{s=await o.json()}catch{throw new I(`Failed to fetch inference provider mapping for model ${e}: malformed API response, invalid JSON`,{url:i,method:"GET"},{requestId:o.headers.get("x-request-id")??"",status:o.status,body:await o.text()})}if(!s?.inferenceProviderMapping)throw new I(`We have not been able to find inference provider information for model ${e}.`,{url:i,method:"GET"},{requestId:o.headers.get("x-request-id")??"",status:o.status,body:await o.text()});r=(a=s.inferenceProviderMapping)?Array.isArray(a)?a:Object.entries(a).map(([t,n])=>({provider:t,hfModelId:e,providerId:n.providerId,status:n.status,task:n.task,adapter:n.adapter,adapterWeightsPath:n.adapterWeightsPath})):[],eP.set(e,r)}return r}async function eR(e,t){if(x[e.provider][e.modelId])return x[e.provider][e.modelId];let n=(await eL(e.modelId,e.accessToken,t)).find(t=>t.provider===e.provider);if(n){let t="hf-inference"===e.provider&&U(eA,e.task)?eA:[e.task];if(!U(t,n.task))throw new A(`Model ${e.modelId} is not supported for task ${e.task} and provider ${e.provider}. Supported task: ${n.task}.`);return"staging"===n.status&&eC.warn(`Model ${e.modelId} is in staging mode for provider ${e.provider}. Meant for test purposes only.`),n}return null}async function eM(e,t,n){if(n){if(e)throw new A("Specifying both endpointUrl and provider is not supported.");return"hf-inference"}if(e||(eC.log("Defaulting to 'auto' which will select the first provider available for the model, sorted by the user's order in https://hf.co/settings/inference-providers."),e="auto"),"auto"===e){if(!t)throw new A("Specifying a model is required when provider is 'auto'");let n=await eL(t);e=n[0]?.provider,eC.log("Auto selected provider:",e)}if(!e)throw new A(`No Inference Provider available for model ${t}.`);return e}function eN(e){return new Promise(t=>{setTimeout(()=>t(),e)})}function eU(e){return/^http(s?):/.test(e)||e.startsWith("/")}const eO=["audio/mpeg","audio/mp4","audio/wav","audio/x-wav"];class e$ extends L{constructor(e){super("fal-ai",e||"https://fal.run")}preparePayload(e){return e.args}makeRoute(e){return`/${e.model}`}prepareHeaders(e,t){let n={Authorization:"provider-key"!==e.authMethod?`Bearer ${e.accessToken}`:`Key ${e.accessToken}`};return t||(n["Content-Type"]="application/json"),n}}class ej extends e${async getResponseFromQueueApi(e,t,n){let r;if(!t||!n)throw new A(`URL and headers are required for ${this.task} task`);if(!e.request_id)throw new C(`Received malformed response from Fal.ai ${this.task} API: no request ID found in the response`);let a=e.status,i=new URL(t),o=`${i.protocol}//${i.host}${"router.huggingface.co"===i.host?"/fal-ai":""}`,s=new URL(e.response_url).pathname,l=i.search,u=`${o}${s}/status${l}`,c=`${o}${s}${l}`;for(;"COMPLETED"!==a;){await eN(500);let e=await fetch(u,{headers:n});if(!e.ok)throw new E("Failed to fetch response status from fal-ai API",{url:u,method:"GET"},{requestId:e.headers.get("x-request-id")??"",status:e.status,body:await e.text()});try{a=(await e.json()).status}catch(e){throw new C("Failed to parse status response from fal-ai API: received malformed response")}}let d=await fetch(c,{headers:n});try{r=await d.json()}catch(e){throw new C("Failed to parse result response from fal-ai API: received malformed response")}return r}}function eD(e,t){return`${w}/${e}/resolve/main/${t}`}const ez="https://api.featherless.ai",eF="https://api.groq.com",eB="https://api.hyperbolic.xyz",eq="https://api.studio.nebius.ai",eV="https://api.novita.ai",eH="https://inference.api.nscale.com",eQ="https://oai.endpoints.kepler.ai.cloud.ovh.net";class eW extends L{constructor(e){super("replicate",e||"https://api.replicate.com")}makeRoute(e){return e.model.includes(":")?"v1/predictions":`v1/models/${e.model}/predictions`}preparePayload(e){return{input:{...O(e.args,["inputs","parameters"]),...e.args.parameters,prompt:e.args.inputs},version:e.model.includes(":")?e.model.split(":")[1]:void 0}}prepareHeaders(e,t){let n={Authorization:`Bearer ${e.accessToken}`,Prefer:"wait"};return t||(n["Content-Type"]="application/json"),n}makeUrl(e){let t=this.makeBaseUrl(e);return e.model.includes(":")?`${t}/v1/predictions`:`${t}/v1/models/${e.model}/predictions`}}const eG="https://api.together.xyz",eK={"black-forest-labs":{"text-to-image":new class extends L{constructor(){super("black-forest-labs","https://api.us1.bfl.ai")}preparePayload(e){return{...O(e.args,["inputs","parameters"]),...e.args.parameters,prompt:e.args.inputs}}prepareHeaders(e,t){let n={Authorization:"provider-key"!==e.authMethod?`Bearer ${e.accessToken}`:`X-Key ${e.accessToken}`};return t||(n["Content-Type"]="application/json"),n}makeRoute(e){if(!e)throw new A("Params are required");return`/v1/${e.model}`}async getResponse(e,t,n,r){let a=new URL(e.polling_url);for(let e=0;e<5;e++){await eN(1e3),eC.debug(`Polling Black Forest Labs API for the result... ${e+1}/5`),a.searchParams.set("attempt",e.toString(10));let t=await fetch(a,{headers:{"Content-Type":"application/json"}});if(!t.ok)throw new E("Failed to fetch result from black forest labs API",{url:a.toString(),method:"GET",headers:{"Content-Type":"application/json"}},{requestId:t.headers.get("x-request-id")??"",status:t.status,body:await t.text()});let n=await t.json();if("object"==typeof n&&n&&"status"in n&&"string"==typeof n.status&&"Ready"===n.status&&"result"in n&&"object"==typeof n.result&&n.result&&"sample"in n.result&&"string"==typeof n.result.sample){if("json"===r)return n.result;if("url"===r)return n.result.sample;let e=await fetch(n.result.sample);return await e.blob()}}throw new C("Timed out while waiting for the result from black forest labs API - aborting after 5 attempts")}}},cerebras:{conversational:new class extends R{constructor(){super("cerebras","https://api.cerebras.ai")}}},cohere:{conversational:new class extends R{constructor(){super("cohere","https://api.cohere.com")}makeRoute(){return"/compatibility/v1/chat/completions"}}},"fal-ai":{"text-to-image":new class extends e${preparePayload(e){let t={...O(e.args,["inputs","parameters"]),...e.args.parameters,sync_mode:!0,prompt:e.args.inputs};return e.mapping?.adapter==="lora"&&e.mapping.adapterWeightsPath&&(t.loras=[{path:eD(e.mapping.hfModelId,e.mapping.adapterWeightsPath),scale:1}],"fal-ai/lora"===e.mapping.providerId&&(t.model_name="stabilityai/stable-diffusion-xl-base-1.0")),t}async getResponse(e,t,n,r){if("object"==typeof e&&"images"in e&&Array.isArray(e.images)&&e.images.length>0&&"url"in e.images[0]&&"string"==typeof e.images[0].url){if("json"===r)return{...e};if("url"===r)return e.images[0].url;let t=await fetch(e.images[0].url);return await t.blob()}throw new C("Received malformed response from Fal.ai text-to-image API")}},"text-to-speech":new class extends e${preparePayload(e){return{...O(e.args,["inputs","parameters"]),...e.args.parameters,text:e.args.inputs}}async getResponse(e){if("string"!=typeof e?.audio?.url)throw new C(`Received malformed response from Fal.ai Text-to-Speech API: expected { audio: { url: string } } format, got instead: ${JSON.stringify(e)}`);let t=await fetch(e.audio.url);if(!t.ok)throw new E(`Failed to fetch audio from ${e.audio.url}: ${t.statusText}`,{url:e.audio.url,method:"GET",headers:{"Content-Type":"application/json"}},{requestId:t.headers.get("x-request-id")??"",status:t.status,body:await t.text()});try{return await t.blob()}catch(n){throw new E(`Failed to fetch audio from ${e.audio.url}: ${n instanceof Error?n.message:String(n)}`,{url:e.audio.url,method:"GET",headers:{"Content-Type":"application/json"}},{requestId:t.headers.get("x-request-id")??"",status:t.status,body:await t.text()})}}},"text-to-video":new class extends ej{task;constructor(){super("https://queue.fal.run"),this.task="text-to-video"}makeRoute(e){return"provider-key"!==e.authMethod?`/${e.model}?_subdomain=queue`:`/${e.model}`}preparePayload(e){return{...O(e.args,["inputs","parameters"]),...e.args.parameters,prompt:e.args.inputs}}async getResponse(e,t,n){let r=await this.getResponseFromQueueApi(e,t,n);if("object"==typeof r&&r&&"video"in r&&"object"==typeof r.video&&r.video&&"url"in r.video&&"string"==typeof r.video.url&&eU(r.video.url)){let e=await fetch(r.video.url);return await e.blob()}throw new C(`Received malformed response from Fal.ai text-to-video API: expected { video: { url: string } } result format, got instead: ${JSON.stringify(r)}`)}},"image-to-image":new class extends ej{task;constructor(){super("https://queue.fal.run"),this.task="image-to-image"}makeRoute(e){return"provider-key"!==e.authMethod?`/${e.model}?_subdomain=queue`:`/${e.model}`}preparePayload(e){let t=e.args;return e.mapping?.adapter==="lora"&&e.mapping.adapterWeightsPath&&(t.loras=[{path:eD(e.mapping.hfModelId,e.mapping.adapterWeightsPath),scale:1}]),t}async preparePayloadAsync(e){let t=e.inputs instanceof Blob?e.inputs.type:"image/png";return{...O(e,["inputs","parameters"]),image_url:`data:${t};base64,${N(new Uint8Array(e.inputs instanceof ArrayBuffer?e.inputs:await e.inputs.arrayBuffer()))}`,...e.parameters,...e}}async getResponse(e,t,n){let r=await this.getResponseFromQueueApi(e,t,n);if("object"==typeof r&&r&&"images"in r&&Array.isArray(r.images)&&r.images.length>0&&"object"==typeof r.images[0]&&r.images[0]&&"url"in r.images[0]&&"string"==typeof r.images[0].url&&eU(r.images[0].url)){let e=await fetch(r.images[0].url);return await e.blob()}throw new C(`Received malformed response from Fal.ai image-to-image API: expected { images: Array<{ url: string }> } result format, got instead: ${JSON.stringify(r)}`)}},"automatic-speech-recognition":new class extends e${prepareHeaders(e,t){let n=super.prepareHeaders(e,t);return n["Content-Type"]="application/json",n}async getResponse(e){if("string"!=typeof e?.text)throw new C(`Received malformed response from Fal.ai Automatic Speech Recognition API: expected { text: string } format, got instead: ${JSON.stringify(e)}`);return{text:e.text}}async preparePayloadAsync(e){let t="data"in e&&e.data instanceof Blob?e.data:"inputs"in e?e.inputs:void 0,n=t?.type;if(!n)throw new A("Unable to determine the input's content-type. Make sure your are passing a Blob when using provider fal-ai.");if(!eO.includes(n))throw new A(`Provider fal-ai does not support blob type ${n} - supported content types are: ${eO.join(", ")}`);let r=N(new Uint8Array(await t.arrayBuffer()));return{..."data"in e?O(e,"data"):O(e,"inputs"),audio_url:`data:${n};base64,${r}`}}},"image-segmentation":new class extends ej{task;constructor(){super("https://queue.fal.run"),this.task="image-segmentation"}makeRoute(e){return"provider-key"!==e.authMethod?`/${e.model}?_subdomain=queue`:`/${e.model}`}preparePayload(e){return{...O(e.args,["inputs","parameters"]),...e.args.parameters,sync_mode:!0}}async preparePayloadAsync(e){let t="data"in e&&e.data instanceof Blob?e.data:"inputs"in e?e.inputs:void 0,n=t instanceof Blob?t.type:"image/png",r=N(new Uint8Array(t instanceof ArrayBuffer?t:await t.arrayBuffer()));return{...O(e,["inputs","parameters","data"]),...e.parameters,...e,image_url:`data:${n};base64,${r}`,sync_mode:!0}}async getResponse(e,t,n){let r=await this.getResponseFromQueueApi(e,t,n);if("object"==typeof r&&null!==r&&"image"in r&&"object"==typeof r.image&&null!==r.image&&"url"in r.image&&"string"==typeof r.image.url){let e=await fetch(r.image.url);if(!e.ok)throw new E(`Failed to fetch segmentation mask from ${r.image.url}`,{url:r.image.url,method:"GET"},{requestId:e.headers.get("x-request-id")??"",status:e.status,body:await e.text()});let t=await e.blob();return[{label:"mask",score:1,mask:N(new Uint8Array(await t.arrayBuffer()))}]}throw new C(`Received malformed response from Fal.ai image-segmentation API: expected { image: { url: string } } format, got instead: ${JSON.stringify(e)}`)}},"image-to-video":new class extends ej{task;constructor(){super("https://queue.fal.run"),this.task="image-to-video"}makeRoute(e){return"provider-key"!==e.authMethod?`/${e.model}?_subdomain=queue`:`/${e.model}`}preparePayload(e){return{...O(e.args,["inputs","parameters"]),...e.args.parameters,image_url:e.args.image_url}}async preparePayloadAsync(e){let t=e.inputs instanceof Blob?e.inputs.type:"image/png";return{...O(e,["inputs","parameters"]),image_url:`data:${t};base64,${N(new Uint8Array(e.inputs instanceof ArrayBuffer?e.inputs:await e.inputs.arrayBuffer()))}`,...e.parameters,...e}}async getResponse(e,t,n){let r=await this.getResponseFromQueueApi(e,t,n);if("object"==typeof r&&null!==r&&"video"in r&&"object"==typeof r.video&&null!==r.video&&"url"in r.video&&"string"==typeof r.video.url&&"url"in r.video&&eU(r.video.url)){let e=await fetch(r.video.url);return await e.blob()}throw new C(`Received malformed response from Fal.ai image\u{2011}to\u{2011}video API: expected { video: { url: string } }, got: ${JSON.stringify(r)}`)}}},"featherless-ai":{conversational:new class extends R{constructor(){super("featherless-ai",ez)}},"text-generation":new class extends M{constructor(){super("featherless-ai",ez)}preparePayload(e){return{model:e.model,...O(e.args,["inputs","parameters"]),...e.args.parameters?{max_tokens:e.args.parameters.max_new_tokens,...O(e.args.parameters,"max_new_tokens")}:void 0,prompt:e.args.inputs}}async getResponse(e){if("object"==typeof e&&"choices"in e&&Array.isArray(e?.choices)&&"string"==typeof e?.model)return{generated_text:e.choices[0].text};throw new C("Received malformed response from Featherless AI text generation API")}}},"hf-inference":{"text-to-image":new class extends eT{async getResponse(e,t,n,r){if(!e)throw new C("Received malformed response from HF-Inference text-to-image API: response is undefined");if("object"==typeof e){if("json"===r)return{...e};if("data"in e&&Array.isArray(e.data)&&e.data[0].b64_json){let t=e.data[0].b64_json;if("url"===r)return`data:image/jpeg;base64,${t}`;let n=await fetch(`data:image/jpeg;base64,${t}`);return await n.blob()}if("output"in e&&Array.isArray(e.output)){if("url"===r)return e.output[0];let t=await fetch(e.output[0]);return await t.blob()}}if(e instanceof Blob){if("url"===r||"json"===r){let t=await e.arrayBuffer().then(e=>H.from(e).toString("base64"));return"url"===r?`data:image/jpeg;base64,${t}`:{output:`data:image/jpeg;base64,${t}`}}return e}throw new C("Received malformed response from HF-Inference text-to-image API: expected a Blob")}},conversational:new class extends eT{makeUrl(e){let t;return(t=(t=e.model.startsWith("http://")||e.model.startsWith("https://")?e.model.trim():`${this.makeBaseUrl(e)}/models/${e.model}`).replace(/\/+$/,"")).endsWith("/v1")?t+="/chat/completions":t.endsWith("/chat/completions")||(t+="/v1/chat/completions"),t}preparePayload(e){return{...e.args,model:e.model}}async getResponse(e){return e}},"text-generation":new class extends eT{async getResponse(e){let t=P(e);if(Array.isArray(t)&&t.every(e=>"generated_text"in e&&"string"==typeof e?.generated_text))return t?.[0];throw new C("Received malformed response from HF-Inference text generation API: expected Array<{generated_text: string}>")}},"text-classification":new class extends eT{async getResponse(e){let t=e?.[0];if(Array.isArray(t)&&t.every(e=>"string"==typeof e?.label&&"number"==typeof e.score))return t;throw new C("Received malformed response from HF-Inference text-classification API: expected Array<{label: string, score: number}>")}},"question-answering":new class extends eT{async getResponse(e){if(Array.isArray(e)?e.every(e=>"object"==typeof e&&!!e&&"string"==typeof e.answer&&"number"==typeof e.end&&"number"==typeof e.score&&"number"==typeof e.start):"object"==typeof e&&!!e&&"string"==typeof e.answer&&"number"==typeof e.end&&"number"==typeof e.score&&"number"==typeof e.start)return Array.isArray(e)?e[0]:e;throw new C("Received malformed response from HF-Inference question-answering API: expected Array<{answer: string, end: number, score: number, start: number}>")}},"audio-classification":new class extends eT{async getResponse(e){if(Array.isArray(e)&&e.every(e=>"object"==typeof e&&null!==e&&"string"==typeof e.label&&"number"==typeof e.score))return e;throw new C("Received malformed response from HF-Inference audio-classification API: expected Array<{label: string, score: number}> but received different format")}},"automatic-speech-recognition":new class extends eT{async getResponse(e){return e}async preparePayloadAsync(e){return"data"in e?e:{...O(e,"inputs"),data:e.inputs}}},"fill-mask":new class extends eT{async getResponse(e){if(Array.isArray(e)&&e.every(e=>"number"==typeof e.score&&"string"==typeof e.sequence&&"number"==typeof e.token&&"string"==typeof e.token_str))return e;throw new C("Received malformed response from HF-Inference fill-mask API: expected Array<{score: number, sequence: string, token: number, token_str: string}>")}},"feature-extraction":new class extends eT{async getResponse(e){let t=(e,n,r=0)=>!(r>n)&&(e.every(e=>Array.isArray(e))?e.every(e=>t(e,n,r+1)):e.every(e=>"number"==typeof e));if(Array.isArray(e)&&t(e,3,0))return e;throw new C("Received malformed response from HF-Inference feature-extraction API: expected Array<number[][][] | number[][] | number[] | number>")}},"image-classification":new class extends eT{async getResponse(e){if(Array.isArray(e)&&e.every(e=>"string"==typeof e.label&&"number"==typeof e.score))return e;throw new C("Received malformed response from HF-Inference image-classification API: expected Array<{label: string, score: number}>")}},"image-segmentation":new class extends eT{async getResponse(e){if(Array.isArray(e)&&e.every(e=>"string"==typeof e.label&&"string"==typeof e.mask&&(void 0===e.score||"number"==typeof e.score)))return e;throw new C("Received malformed response from HF-Inference image-segmentation API: expected Array<{label: string, mask: string, score: number}>")}async preparePayloadAsync(e){return{...e,inputs:N(new Uint8Array(e.inputs instanceof ArrayBuffer?e.inputs:await e.inputs.arrayBuffer()))}}},"document-question-answering":new class extends eT{async getResponse(e){if(Array.isArray(e)&&e.every(e=>"object"==typeof e&&!!e&&"string"==typeof e?.answer&&("number"==typeof e.end||void 0===e.end)&&("number"==typeof e.score||void 0===e.score)&&("number"==typeof e.start||void 0===e.start)))return e[0];throw new C("Received malformed response from HF-Inference document-question-answering API: expected Array<{answer: string, end: number, score: number, start: number}>")}},"image-to-text":new class extends eT{async getResponse(e){if("string"!=typeof e?.generated_text)throw new C("Received malformed response from HF-Inference image-to-text API: expected {generated_text: string}");return e}},"object-detection":new class extends eT{async getResponse(e){if(Array.isArray(e)&&e.every(e=>"string"==typeof e.label&&"number"==typeof e.score&&"number"==typeof e.box.xmin&&"number"==typeof e.box.ymin&&"number"==typeof e.box.xmax&&"number"==typeof e.box.ymax))return e;throw new C("Received malformed response from HF-Inference object-detection API: expected Array<{label: string, score: number, box: {xmin: number, ymin: number, xmax: number, ymax: number}}>")}},"audio-to-audio":new class extends eT{async getResponse(e){if(!Array.isArray(e))throw new C("Received malformed response from HF-Inference audio-to-audio API: expected Array");if(!e.every(e=>"object"==typeof e&&e&&"label"in e&&"string"==typeof e.label&&"content-type"in e&&"string"==typeof e["content-type"]&&"blob"in e&&"string"==typeof e.blob))throw new C("Received malformed response from HF-Inference audio-to-audio API: expected Array<{label: string, audio: Blob}>");return e}},"zero-shot-image-classification":new class extends eT{async getResponse(e){if(Array.isArray(e)&&e.every(e=>"string"==typeof e.label&&"number"==typeof e.score))return e;throw new C("Received malformed response from HF-Inference zero-shot-image-classification API: expected Array<{label: string, score: number}>")}},"zero-shot-classification":new eE,"image-to-image":new class extends eT{async preparePayloadAsync(e){return e.parameters?{...e,inputs:N(new Uint8Array(e.inputs instanceof ArrayBuffer?e.inputs:await e.inputs.arrayBuffer()))}:{...e,model:e.model,data:e.inputs}}async getResponse(e){if(e instanceof Blob)return e;throw new C("Received malformed response from HF-Inference image-to-image API: expected Blob")}},"sentence-similarity":new class extends eT{async getResponse(e){if(Array.isArray(e)&&e.every(e=>"number"==typeof e))return e;throw new C("Received malformed response from HF-Inference sentence-similarity API: expected Array<number>")}},"table-question-answering":new eI,"tabular-classification":new class extends eT{async getResponse(e){if(Array.isArray(e)&&e.every(e=>"number"==typeof e))return e;throw new C("Received malformed response from HF-Inference tabular-classification API: expected Array<number>")}},"text-to-speech":new class extends eT{async getResponse(e){return e}},"token-classification":new class extends eT{async getResponse(e){if(Array.isArray(e)&&e.every(e=>"number"==typeof e.end&&"string"==typeof e.entity_group&&"number"==typeof e.score&&"number"==typeof e.start&&"string"==typeof e.word))return e;throw new C("Received malformed response from HF-Inference token-classification API: expected Array<{end: number, entity_group: string, score: number, start: number, word: string}>")}},translation:new class extends eT{async getResponse(e){if(Array.isArray(e)&&e.every(e=>"string"==typeof e?.translation_text))return e?.length===1?e?.[0]:e;throw new C("Received malformed response from HF-Inference translation API: expected Array<{translation_text: string}>")}},summarization:new class extends eT{async getResponse(e){if(Array.isArray(e)&&e.every(e=>"string"==typeof e?.summary_text))return e?.[0];throw new C("Received malformed response from HF-Inference summarization API: expected Array<{summary_text: string}>")}},"visual-question-answering":new class extends eT{async getResponse(e){if(Array.isArray(e)&&e.every(e=>"object"==typeof e&&!!e&&"string"==typeof e?.answer&&"number"==typeof e.score))return e[0];throw new C("Received malformed response from HF-Inference visual-question-answering API: expected Array<{answer: string, score: number}>")}},"tabular-regression":new class extends eT{async getResponse(e){if(Array.isArray(e)&&e.every(e=>"number"==typeof e))return e;throw new C("Received malformed response from HF-Inference tabular-regression API: expected Array<number>")}},"text-to-audio":new class extends eT{async getResponse(e){return e}}},"fireworks-ai":{conversational:new class extends R{constructor(){super("fireworks-ai","https://api.fireworks.ai")}makeRoute(){return"/inference/v1/chat/completions"}}},groq:{conversational:new class extends R{constructor(){super("groq",eF)}makeRoute(){return"/openai/v1/chat/completions"}},"text-generation":new class extends M{constructor(){super("groq",eF)}makeRoute(){return"/openai/v1/chat/completions"}}},hyperbolic:{"text-to-image":new class extends L{constructor(){super("hyperbolic",eB)}makeRoute(e){return"/v1/images/generations"}preparePayload(e){return{...O(e.args,["inputs","parameters"]),...e.args.parameters,prompt:e.args.inputs,model_name:e.model}}async getResponse(e,t,n,r){if("object"==typeof e&&"images"in e&&Array.isArray(e.images)&&e.images[0]&&"string"==typeof e.images[0].image)return"json"===r?{...e}:"url"===r?`data:image/jpeg;base64,${e.images[0].image}`:fetch(`data:image/jpeg;base64,${e.images[0].image}`).then(e=>e.blob());throw new C("Received malformed response from Hyperbolic text-to-image API")}},conversational:new class extends R{constructor(){super("hyperbolic",eB)}},"text-generation":new class extends M{constructor(){super("hyperbolic",eB)}makeRoute(){return"v1/chat/completions"}preparePayload(e){return{messages:[{content:e.args.inputs,role:"user"}],...e.args.parameters?{max_tokens:e.args.parameters.max_new_tokens,...O(e.args.parameters,"max_new_tokens")}:void 0,...O(e.args,["inputs","parameters"]),model:e.model}}async getResponse(e){if("object"==typeof e&&"choices"in e&&Array.isArray(e?.choices)&&"string"==typeof e?.model)return{generated_text:e.choices[0].message.content};throw new C("Received malformed response from Hyperbolic text generation API")}}},nebius:{"text-to-image":new class extends L{constructor(){super("nebius",eq)}preparePayload(e){return{...O(e.args,["inputs","parameters"]),...e.args.parameters,response_format:"b64_json",prompt:e.args.inputs,model:e.model}}makeRoute(){return"v1/images/generations"}async getResponse(e,t,n,r){if("object"==typeof e&&"data"in e&&Array.isArray(e.data)&&e.data.length>0&&"b64_json"in e.data[0]&&"string"==typeof e.data[0].b64_json){if("json"===r)return{...e};let t=e.data[0].b64_json;return"url"===r?`data:image/jpeg;base64,${t}`:fetch(`data:image/jpeg;base64,${t}`).then(e=>e.blob())}throw new C("Received malformed response from Nebius text-to-image API")}},conversational:new class extends R{constructor(){super("nebius",eq)}preparePayload(e){let t=super.preparePayload(e),n=e.args.response_format;return n?.type==="json_schema"&&n.json_schema?.schema&&(t.guided_json=n.json_schema.schema),t}},"text-generation":new class extends M{constructor(){super("nebius",eq)}preparePayload(e){return{...e.args,model:e.model,prompt:e.args.inputs}}async getResponse(e){if("object"==typeof e&&"choices"in e&&Array.isArray(e?.choices)&&e.choices.length>0&&"string"==typeof e.choices[0]?.text)return{generated_text:e.choices[0].text};throw new C("Received malformed response from Nebius text generation API")}},"feature-extraction":new class extends L{constructor(){super("nebius",eq)}preparePayload(e){return{input:e.args.inputs,model:e.model}}makeRoute(){return"v1/embeddings"}async getResponse(e){return e.data.map(e=>e.embedding)}}},novita:{conversational:new class extends R{constructor(){super("novita",eV)}makeRoute(){return"/v3/openai/chat/completions"}},"text-generation":new class extends M{constructor(){super("novita",eV)}makeRoute(){return"/v3/openai/chat/completions"}},"text-to-video":new class extends L{constructor(){super("novita",eV)}makeRoute(e){return`/v3/async/${e.model}`}preparePayload(e){let{num_inference_steps:t,...n}=e.args.parameters??{};return{...O(e.args,["inputs","parameters"]),...n,steps:t,prompt:e.args.inputs}}async getResponse(e,t,n){let r;if(!t||!n)throw new A("URL and headers are required for text-to-video task");let a=e.task_id;if(!a)throw new C("Received malformed response from Novita text-to-video API: no task ID found in the response");let i=new URL(t),o=`${i.protocol}//${i.host}${"router.huggingface.co"===i.host?"/novita":""}`,s=`${o}/v3/async/task-result?task_id=${a}`,l="";for(;"TASK_STATUS_SUCCEED"!==l&&"TASK_STATUS_FAILED"!==l;){await eN(500);let e=await fetch(s,{headers:n});if(!e.ok)throw new E("Failed to fetch task result",{url:s,method:"GET",headers:n},{requestId:e.headers.get("x-request-id")??"",status:e.status,body:await e.text()});try{if((r=await e.json())&&"object"==typeof r&&"task"in r&&r.task&&"object"==typeof r.task&&"status"in r.task&&"string"==typeof r.task.status)l=r.task.status;else throw new C("Received malformed response from Novita text-to-video API: failed to get task status")}catch(e){throw new C("Received malformed response from Novita text-to-video API: failed to parse task result")}}if("TASK_STATUS_FAILED"===l)throw new C("Novita text-to-video task failed");if("object"==typeof r&&r&&"videos"in r&&"object"==typeof r.videos&&r.videos&&Array.isArray(r.videos)&&r.videos.length>0&&"video_url"in r.videos[0]&&"string"==typeof r.videos[0].video_url&&eU(r.videos[0].video_url)){let e=await fetch(r.videos[0].video_url);return await e.blob()}throw new C(`Received malformed response from Novita text-to-video API: expected { videos: [{ video_url: string }] } format, got instead: ${JSON.stringify(r)}`)}}},nscale:{"text-to-image":new class extends L{constructor(){super("nscale",eH)}preparePayload(e){return{...O(e.args,["inputs","parameters"]),...e.args.parameters,response_format:"b64_json",prompt:e.args.inputs,model:e.model}}makeRoute(){return"v1/images/generations"}async getResponse(e,t,n,r){if("object"==typeof e&&"data"in e&&Array.isArray(e.data)&&e.data.length>0&&"b64_json"in e.data[0]&&"string"==typeof e.data[0].b64_json){if("json"===r)return{...e};let t=e.data[0].b64_json;return"url"===r?`data:image/jpeg;base64,${t}`:fetch(`data:image/jpeg;base64,${t}`).then(e=>e.blob())}throw new C("Received malformed response from Nscale text-to-image API")}},conversational:new class extends R{constructor(){super("nscale",eH)}}},openai:{conversational:new class extends R{constructor(){super("openai","https://api.openai.com",!0)}}},ovhcloud:{conversational:new class extends R{constructor(){super("ovhcloud",eQ)}},"text-generation":new class extends M{constructor(){super("ovhcloud",eQ)}preparePayload(e){return{model:e.model,...O(e.args,["inputs","parameters"]),...e.args.parameters?{max_tokens:e.args.parameters.max_new_tokens,...O(e.args.parameters,"max_new_tokens")}:void 0,prompt:e.args.inputs}}async getResponse(e){if("object"==typeof e&&"choices"in e&&Array.isArray(e?.choices)&&"string"==typeof e?.model)return{generated_text:e.choices[0].text};throw new C("Received malformed response from OVHcloud text generation API")}}},replicate:{"text-to-image":new class extends eW{preparePayload(e){return{input:{...O(e.args,["inputs","parameters"]),...e.args.parameters,prompt:e.args.inputs,lora_weights:e.mapping?.adapter==="lora"&&e.mapping.adapterWeightsPath?`https://huggingface.co/${e.mapping.hfModelId}`:void 0},version:e.model.includes(":")?e.model.split(":")[1]:void 0}}async getResponse(e,t,n,r){if("object"==typeof e&&"output"in e&&Array.isArray(e.output)&&e.output.length>0&&"string"==typeof e.output[0]){if("json"===r)return{...e};if("url"===r)return e.output[0];let t=await fetch(e.output[0]);return await t.blob()}throw new C("Received malformed response from Replicate text-to-image API")}},"text-to-speech":new class extends eW{preparePayload(e){let t=super.preparePayload(e),n=t.input;return"object"==typeof n&&null!==n&&"prompt"in n&&(n.text=n.prompt,delete n.prompt),t}async getResponse(e){if(e instanceof Blob)return e;if(e&&"object"==typeof e&&"output"in e){if("string"==typeof e.output){let t=await fetch(e.output);return await t.blob()}else if(Array.isArray(e.output)){let t=await fetch(e.output[0]);return await t.blob()}}throw new C("Received malformed response from Replicate text-to-speech API")}},"text-to-video":new class extends eW{async getResponse(e){if("object"==typeof e&&e&&"output"in e&&"string"==typeof e.output&&eU(e.output)){let t=await fetch(e.output);return await t.blob()}throw new C("Received malformed response from Replicate text-to-video API")}},"image-to-image":new class extends eW{preparePayload(e){return{input:{...O(e.args,["inputs","parameters"]),...e.args.parameters,input_image:e.args.inputs,lora_weights:e.mapping?.adapter==="lora"&&e.mapping.adapterWeightsPath?`https://huggingface.co/${e.mapping.hfModelId}`:void 0},version:e.model.includes(":")?e.model.split(":")[1]:void 0}}async preparePayloadAsync(e){let{inputs:t,...n}=e,r=N(new Uint8Array(await t.arrayBuffer())),a=`data:${t.type||"image/jpeg"};base64,${r}`;return{...n,inputs:a}}async getResponse(e){if("object"==typeof e&&e&&"output"in e&&Array.isArray(e.output)&&e.output.length>0&&"string"==typeof e.output[0]){let t=await fetch(e.output[0]);return await t.blob()}if("object"==typeof e&&e&&"output"in e&&"string"==typeof e.output&&eU(e.output)){let t=await fetch(e.output);return await t.blob()}throw new C("Received malformed response from Replicate image-to-image API")}}},sambanova:{conversational:new class extends R{constructor(){super("sambanova","https://api.sambanova.ai")}preparePayload(e){let t=e.args.response_format;return t?.type==="json_schema"&&t.json_schema&&(t.json_schema.strict??!0)&&(t.json_schema.strict=!1),super.preparePayload(e)}},"feature-extraction":new class extends L{constructor(){super("sambanova","https://api.sambanova.ai")}makeRoute(){return"/v1/embeddings"}async getResponse(e){if("object"==typeof e&&"data"in e&&Array.isArray(e.data))return e.data.map(e=>e.embedding);throw new C("Received malformed response from Sambanova feature-extraction (embeddings) API")}preparePayload(e){return{model:e.model,input:e.args.inputs,...e.args}}}},together:{"text-to-image":new class extends L{constructor(){super("together",eG)}makeRoute(){return"v1/images/generations"}preparePayload(e){return{...O(e.args,["inputs","parameters"]),...e.args.parameters,prompt:e.args.inputs,response_format:"base64",model:e.model}}async getResponse(e,t,n,r){if("object"==typeof e&&"data"in e&&Array.isArray(e.data)&&e.data.length>0&&"b64_json"in e.data[0]&&"string"==typeof e.data[0].b64_json){if("json"===r)return{...e};let t=e.data[0].b64_json;return"url"===r?`data:image/jpeg;base64,${t}`:fetch(`data:image/jpeg;base64,${t}`).then(e=>e.blob())}throw new C("Received malformed response from Together text-to-image API")}},conversational:new class extends R{constructor(){super("together",eG)}preparePayload(e){let t=super.preparePayload(e),n=t.response_format;return n?.type==="json_schema"&&n?.json_schema?.schema&&(t.response_format={type:"json_schema",schema:n.json_schema.schema}),t}},"text-generation":new class extends M{constructor(){super("together",eG)}preparePayload(e){return{model:e.model,...e.args,prompt:e.args.inputs}}async getResponse(e){if("object"==typeof e&&"choices"in e&&Array.isArray(e?.choices)&&"string"==typeof e?.model)return{generated_text:e.choices[0].text};throw new C("Received malformed response from Together text generation API")}}}};function eX(e,t){if("hf-inference"===e&&!t||"auto"===e)return new eT;if(!t)throw new A("you need to provide a task name when using an external provider, e.g. 'text-to-image'");if(!(e in eK))throw new A(`Provider '${e}' not supported. Available providers: ${Object.keys(eK)}`);let n=eK[e];if(!n||!(t in n))throw new A(`Task '${t}' not supported for provider '${e}'. Available tasks: ${Object.keys(n??{})}`);return n[t]}let eY=null;async function eJ(e,t,n){let{model:r}=e,a=t.provider,{task:i}=n??{};if(e.endpointUrl&&"hf-inference"!==a)throw new A("Cannot use endpointUrl with a third-party provider.");if(r&&eU(r))throw new A("Model URLs are no longer supported. Use endpointUrl instead.");if(e.endpointUrl)return eZ(r??e.endpointUrl,t,e,void 0,n);if(!r&&!i)throw new A("No model provided, and no task has been specified.");let o=r??await e0(i);if(t.clientSideRoutingOnly&&!r)throw new A(`Provider ${a} requires a model ID to be passed directly.`);let s=t.clientSideRoutingOnly?{provider:a,providerId:function(e,t){if(!e.startsWith(`${t}/`))throw new A(`Models from ${t} must be prefixed by "${t}/". Got "${e}".`);return e.slice(t.length+1)}(r,a),hfModelId:r,status:"live",task:i}:await eR({modelId:o,task:i,provider:a,accessToken:e.accessToken},{fetch:n?.fetch});if(!s)throw new A(`We have not been able to find inference provider information for model ${o}.`);return eZ(s.providerId,t,e,s,n)}function eZ(e,t,n,r,a){let i,{accessToken:o,endpointUrl:s,provider:l,model:u,...c}=n,d=t.provider,{includeCredentials:p,task:f,signal:m,billTo:h}=a??{},g=(()=>{if(t.clientSideRoutingOnly&&o&&o.startsWith("hf_"))throw new A(`Provider ${d} is closed-source and does not support HF tokens.`);return o?o.startsWith("hf_")?"hf-token":"provider-key":"include"===p?"credentials-include":"none"})(),y=t.makeUrl({authMethod:g,model:s??e,task:f}),b=t.prepareHeaders({accessToken:o,authMethod:g},"data"in n&&!!n.data);h&&(b["X-HF-Bill-To"]=h);let v=["@huggingface/inference/4.6.1","undefined"!=typeof navigator?navigator.userAgent:void 0].filter(e=>void 0!==e).join(" ");b["User-Agent"]=v;let w=t.makeBody({args:c,model:e,task:f,mapping:r});return"string"==typeof p?i=p:!0===p&&(i="include"),{url:y,info:{headers:b,method:"POST",body:w,...i?{credentials:i}:void 0,signal:m}}}async function e0(e){eY||(eY=await e1());let t=eY[e];if((t?.models.length??0)<=0)throw new A(`No default model defined for task ${e}, please define the model explicitly.`);return t.models[0].id}async function e1(){let e=`${w}/api/tasks`,t=await fetch(e);if(!t.ok)throw new I("Failed to load tasks definitions from Hugging Face Hub.",{url:e,method:"GET"},{requestId:t.headers.get("x-request-id")??"",status:t.status,body:await t.text()});return await t.json()}function e2(){return{data:"",event:"",id:"",retry:void 0}}function e3(e){let t=null;if(e instanceof Blob||e instanceof ArrayBuffer)t="[Blob or ArrayBuffer]";else if("string"==typeof e)try{t=JSON.parse(e)}catch{t=e}return t.accessToken&&(t.accessToken="[REDACTED]"),t}async function e4(e,t,n){let{url:r,info:a}=await eJ(e,t,n),i=await (n?.fetch??fetch)(r,a),o={url:r,info:a};if(n?.retry_on_error!==!1&&503===i.status)return e4(e,t,n);if(!i.ok){let t=i.headers.get("Content-Type");if(["application/json","application/problem+json"].some(e=>t?.startsWith(e))){let t=await i.json();if([400,422,404,500].includes(i.status)&&n?.chatCompletion)throw new E(`Provider ${e.provider} does not seem to support chat completion for model ${e.model} . Error: ${JSON.stringify(t.error)}`,{url:r,method:a.method??"GET",headers:a.headers,body:e3(a.body)},{requestId:i.headers.get("x-request-id")??"",status:i.status,body:t});if("string"==typeof t.error||"string"==typeof t.detail||"string"==typeof t.message)throw new E(`Failed to perform inference: ${t.error??t.detail??t.message}`,{url:r,method:a.method??"GET",headers:a.headers,body:e3(a.body)},{requestId:i.headers.get("x-request-id")??"",status:i.status,body:t});throw new E("Failed to perform inference: an HTTP error occurred when requesting the provider.",{url:r,method:a.method??"GET",headers:a.headers,body:e3(a.body)},{requestId:i.headers.get("x-request-id")??"",status:i.status,body:t})}let o=t?.startsWith("text/plain;")?await i.text():void 0;throw new E(`Failed to perform inference: ${o??"an HTTP error occurred when requesting the provider"}`,{url:r,method:a.method??"GET",headers:a.headers,body:e3(a.body)},{requestId:i.headers.get("x-request-id")??"",status:i.status,body:o??""})}return i.headers.get("Content-Type")?.startsWith("application/json")?{data:await i.json(),requestContext:o}:{data:await i.blob(),requestContext:o}}async function*e6(e,t,n){var r;let a,i,o,s,{url:l,info:u}=await eJ({...e,stream:!0},t,n),c=await (n?.fetch??fetch)(l,u);if(n?.retry_on_error!==!1&&503===c.status)return yield*e6(e,t,n);if(!c.ok){if(c.headers.get("Content-Type")?.startsWith("application/json")){let t=await c.json();if([400,422,404,500].includes(c.status)&&n?.chatCompletion)throw new E(`Provider ${e.provider} does not seem to support chat completion for model ${e.model} . Error: ${JSON.stringify(t.error)}`,{url:l,method:u.method??"GET",headers:u.headers,body:e3(u.body)},{requestId:c.headers.get("x-request-id")??"",status:c.status,body:t});if("string"==typeof t.error)throw new E(`Failed to perform inference: ${t.error}`,{url:l,method:u.method??"GET",headers:u.headers,body:e3(u.body)},{requestId:c.headers.get("x-request-id")??"",status:c.status,body:t});if(t.error&&"message"in t.error&&"string"==typeof t.error.message)throw new E(`Failed to perform inference: ${t.error.message}`,{url:l,method:u.method??"GET",headers:u.headers,body:e3(u.body)},{requestId:c.headers.get("x-request-id")??"",status:c.status,body:t});if("string"==typeof t.message)throw new E(`Failed to perform inference: ${t.message}`,{url:l,method:u.method??"GET",headers:u.headers,body:e3(u.body)},{requestId:c.headers.get("x-request-id")??"",status:c.status,body:t})}throw new E("Failed to perform inference: an HTTP error occurred when requesting the provider.",{url:l,method:u.method??"GET",headers:u.headers,body:e3(u.body)},{requestId:c.headers.get("x-request-id")??"",status:c.status,body:""})}if(!c.headers.get("content-type")?.startsWith("text/event-stream"))throw new E("Failed to perform inference: server does not support event stream content type, it returned "+c.headers.get("content-type"),{url:l,method:u.method??"GET",headers:u.headers,body:e3(u.body)},{requestId:c.headers.get("x-request-id")??"",status:c.status,body:""});if(!c.body)return;let d=c.body.getReader(),p=[],f=(r=function(e,t,n){let r=e2(),a=new TextDecoder;return function(i,o){if(0===i.length)n?.(r),r=e2();else if(o>0){let n=a.decode(i.subarray(0,o)),s=o+(32===i[o+1]?2:1),l=a.decode(i.subarray(s));switch(n){case"data":r.data=r.data?r.data+"\n"+l:l;break;case"event":r.event=l;break;case"id":e(r.id=l);break;case"retry":{let e=parseInt(l,10);isNaN(e)||t(r.retry=e)}}}}}(()=>{},()=>{},e=>{p.push(e)}),s=!1,function(e){void 0===a?(a=e,i=0,o=-1):a=function(e,t){let n=new Uint8Array(e.length+t.length);return n.set(e),n.set(t,e.length),n}(a,e);let t=a.length,n=0;for(;i<t;){s&&(10===a[i]&&(n=++i),s=!1);let e=-1;for(;i<t&&-1===e;++i)switch(a[i]){case 58:-1===o&&(o=i-n);break;case 13:s=!0;case 10:e=i}if(-1===e)break;r(a.subarray(n,e),o),n=i,o=-1}n===t?a=void 0:0!==n&&(a=a.subarray(n),i-=n)});try{for(;;){let{done:e,value:t}=await d.read();if(e)return;for(let e of(f(t),p))if(e.data.length>0){if("[DONE]"===e.data)return;let t=JSON.parse(e.data);if("object"==typeof t&&null!==t&&"error"in t){let e="string"==typeof t.error?t.error:"object"==typeof t.error&&t.error&&"message"in t.error&&"string"==typeof t.error.message?t.error.message:JSON.stringify(t.error);throw new E(`Failed to perform inference: an occurred while streaming the response: ${e}`,{url:l,method:u.method??"GET",headers:u.headers,body:e3(u.body)},{requestId:c.headers.get("x-request-id")??"",status:c.status,body:t})}yield t}p=[]}}finally{d.releaseLock()}}async function e5(e,t){eC.warn("The request method is deprecated and will be removed in a future version of huggingface.js. Use specific task functions instead.");let n=eX(await eM(e.provider,e.model,e.endpointUrl),t?.task);return(await e4(e,n,t)).data}var e8={};async function*e9(e,t){eC.warn("The streamingRequest method is deprecated and will be removed in a future version of huggingface.js. Use specific task functions instead.");let n=eX(await eM(e.provider,e.model,e.endpointUrl),t?.task);yield*e6(e,n,t)}e(e8,"streamingRequest",()=>e9);var e7={};function te(e){return"data"in e?e:{...O(e,"inputs"),data:e.inputs}}async function tt(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"audio-classification"),r=te(e),{data:a}=await e4(r,n,{...t,task:"audio-classification"});return n.getResponse(a)}e(e7,"audioClassification",()=>tt);var tn={};async function tr(e,t){let n="inputs"in e?e.model:void 0,r=eX(await eM(e.provider,n),"audio-to-audio"),a=te(e),{data:i}=await e4(a,r,{...t,task:"audio-to-audio"});return r.getResponse(i)}e(tn,"audioToAudio",()=>tr);var ta={};async function ti(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"automatic-speech-recognition"),r=await n.preparePayloadAsync(e),{data:a}=await e4(r,n,{...t,task:"automatic-speech-recognition"});if("string"!=typeof a?.text)throw new C("Received malformed response from automatic-speech-recognition API");return n.getResponse(a)}e(ta,"automaticSpeechRecognition",()=>ti);var to={};async function ts(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"text-to-speech"),{data:r}=await e4(e,n,{...t,task:"text-to-speech"});return n.getResponse(r)}e(to,"textToSpeech",()=>ts);var tl={};function tu(e){return"data"in e?e:{...O(e,"inputs"),data:e.inputs}}async function tc(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"image-classification"),r=tu(e),{data:a}=await e4(r,n,{...t,task:"image-classification"});return n.getResponse(a)}e(tl,"imageClassification",()=>tc);var td={};async function tp(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"image-segmentation"),r=await n.preparePayloadAsync(e),{data:a}=await e4(r,n,{...t,task:"image-segmentation"}),{url:i,info:o}=await eJ(e,n,{...t,task:"image-segmentation"});return n.getResponse(a,i,o.headers)}e(td,"imageSegmentation",()=>tp);var tf={};async function tm(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"image-to-image"),r=await n.preparePayloadAsync(e),{data:a}=await e4(r,n,{...t,task:"image-to-image"}),{url:i,info:o}=await eJ(e,n,{...t,task:"image-to-image"});return n.getResponse(a,i,o.headers)}e(tf,"imageToImage",()=>tm);var th={};async function tg(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"image-to-text"),r=tu(e),{data:a}=await e4(r,n,{...t,task:"image-to-text"});return n.getResponse(a[0])}e(th,"imageToText",()=>tg);var ty={};async function tb(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"image-to-video"),r=await n.preparePayloadAsync(e),{data:a}=await e4(r,n,{...t,task:"image-to-video"}),{url:i,info:o}=await eJ(e,n,{...t,task:"image-to-video"});return n.getResponse(a,i,o.headers)}e(ty,"imageToVideo",()=>tb);var tv={};async function tw(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"object-detection"),r=tu(e),{data:a}=await e4(r,n,{...t,task:"object-detection"});return n.getResponse(a)}e(tv,"objectDetection",()=>tw);var t_={};async function tk(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"text-to-image"),{data:r}=await e4(e,n,{...t,task:"text-to-image"}),{url:a,info:i}=await eJ(e,n,{...t,task:"text-to-image"});return n.getResponse(r,a,i.headers,t?.outputType)}e(t_,"textToImage",()=>tk);var tx={};async function tS(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"text-to-video"),{data:r}=await e4(e,n,{...t,task:"text-to-video"}),{url:a,info:i}=await eJ(e,n,{...t,task:"text-to-video"});return n.getResponse(r,a,i.headers)}e(tx,"textToVideo",()=>tS);var tA={};async function tT(e){return e.inputs instanceof Blob?{...e,inputs:{image:N(new Uint8Array(await e.inputs.arrayBuffer()))}}:{...e,inputs:{image:N(new Uint8Array(e.inputs.image instanceof ArrayBuffer?e.inputs.image:await e.inputs.image.arrayBuffer()))}}}async function tE(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"zero-shot-image-classification"),r=await tT(e),{data:a}=await e4(r,n,{...t,task:"zero-shot-image-classification"});return n.getResponse(a)}e(tA,"zeroShotImageClassification",()=>tE);var tI={};async function tC(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"conversational"),{data:r}=await e4(e,n,{...t,task:"conversational"});return n.getResponse(r)}e(tI,"chatCompletion",()=>tC);var tP={};async function*tL(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"conversational");yield*e6(e,n,{...t,task:"conversational"})}e(tP,"chatCompletionStream",()=>tL);var tR={};async function tM(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"feature-extraction"),{data:r}=await e4(e,n,{...t,task:"feature-extraction"});return n.getResponse(r)}e(tR,"featureExtraction",()=>tM);var tN={};async function tU(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"fill-mask"),{data:r}=await e4(e,n,{...t,task:"fill-mask"});return n.getResponse(r)}e(tN,"fillMask",()=>tU);var tO={};async function t$(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"question-answering"),{data:r}=await e4(e,n,{...t,task:"question-answering"});return n.getResponse(r)}e(tO,"questionAnswering",()=>t$);var tj={};async function tD(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"sentence-similarity"),{data:r}=await e4(e,n,{...t,task:"sentence-similarity"});return n.getResponse(r)}e(tj,"sentenceSimilarity",()=>tD);var tz={};async function tF(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"summarization"),{data:r}=await e4(e,n,{...t,task:"summarization"});return n.getResponse(r)}e(tz,"summarization",()=>tF);var tB={};async function tq(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"table-question-answering"),{data:r}=await e4(e,n,{...t,task:"table-question-answering"});return n.getResponse(r)}e(tB,"tableQuestionAnswering",()=>tq);var tV={};async function tH(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"text-classification"),{data:r}=await e4(e,n,{...t,task:"text-classification"});return n.getResponse(r)}e(tV,"textClassification",()=>tH);var tQ={};async function tW(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"text-generation"),{data:r}=await e4(e,n,{...t,task:"text-generation"});return n.getResponse(r)}e(tQ,"textGeneration",()=>tW);var tG={};async function*tK(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"text-generation");yield*e6(e,n,{...t,task:"text-generation"})}e(tG,"textGenerationStream",()=>tK);var tX={};async function tY(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"token-classification"),{data:r}=await e4(e,n,{...t,task:"token-classification"});return n.getResponse(r)}e(tX,"tokenClassification",()=>tY);var tJ={};async function tZ(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"translation"),{data:r}=await e4(e,n,{...t,task:"translation"});return n.getResponse(r)}e(tJ,"translation",()=>tZ);var t0={};async function t1(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"zero-shot-classification"),{data:r}=await e4(e,n,{...t,task:"zero-shot-classification"});return n.getResponse(r)}e(t0,"zeroShotClassification",()=>t1);var t2={};async function t3(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"document-question-answering"),r={...e,inputs:{question:e.inputs.question,image:N(new Uint8Array(await e.inputs.image.arrayBuffer()))}},{data:a}=await e4(r,n,{...t,task:"document-question-answering"});return n.getResponse(a)}e(t2,"documentQuestionAnswering",()=>t3);var t4={};async function t6(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"visual-question-answering"),r={...e,inputs:{question:e.inputs.question,image:N(new Uint8Array(await e.inputs.image.arrayBuffer()))}},{data:a}=await e4(r,n,{...t,task:"visual-question-answering"});return n.getResponse(a)}e(t4,"visualQuestionAnswering",()=>t6);var t5={};async function t8(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"tabular-classification"),{data:r}=await e4(e,n,{...t,task:"tabular-classification"});return n.getResponse(r)}e(t5,"tabularClassification",()=>t8);var t9={};async function t7(e,t){let n=eX(await eM(e.provider,e.model,e.endpointUrl),"tabular-regression"),{data:r}=await e4(e,n,{...t,task:"tabular-regression"});return n.getResponse(r)}e(t9,"tabularRegression",()=>t7),t(b,v),t(b,e8),t(b,e7),t(b,tn),t(b,ta),t(b,to),t(b,tl),t(b,td),t(b,tf),t(b,th),t(b,ty),t(b,tv),t(b,t_),t(b,tx),t(b,tA),t(b,tI),t(b,tP),t(b,tR),t(b,tN),t(b,tO),t(b,tj),t(b,tz),t(b,tB),t(b,tV),t(b,tQ),t(b,tG),t(b,tX),t(b,tJ),t(b,t0),t(b,t2),t(b,t4),t(b,t5),t(b,t9);class ne{accessToken;defaultOptions;constructor(e="",t={}){for(let[n,r]of(this.accessToken=e,this.defaultOptions=t,Object.entries(b)))Object.defineProperty(this,n,{enumerable:!1,value:(n,a)=>r({endpointUrl:t.endpointUrl,accessToken:e,...n},{...O(t,["endpointUrl"]),...a})})}endpoint(e){return new ne(this.accessToken,{...this.defaultOptions,endpointUrl:e})}}var nt=Object.freeze({Text:"Text",NumericLiteral:"NumericLiteral",StringLiteral:"StringLiteral",Identifier:"Identifier",Equals:"Equals",OpenParen:"OpenParen",CloseParen:"CloseParen",OpenStatement:"OpenStatement",CloseStatement:"CloseStatement",OpenExpression:"OpenExpression",CloseExpression:"CloseExpression",OpenSquareBracket:"OpenSquareBracket",CloseSquareBracket:"CloseSquareBracket",OpenCurlyBracket:"OpenCurlyBracket",CloseCurlyBracket:"CloseCurlyBracket",Comma:"Comma",Dot:"Dot",Colon:"Colon",Pipe:"Pipe",CallOperator:"CallOperator",AdditiveBinaryOperator:"AdditiveBinaryOperator",MultiplicativeBinaryOperator:"MultiplicativeBinaryOperator",ComparisonBinaryOperator:"ComparisonBinaryOperator",UnaryOperator:"UnaryOperator",Comment:"Comment"}),nn=class{constructor(e,t){this.value=e,this.type=t}};function nr(e){return/\w/.test(e)}function na(e){return/[0-9]/.test(e)}var ni=[["{%",nt.OpenStatement],["%}",nt.CloseStatement],["{{",nt.OpenExpression],["}}",nt.CloseExpression],["(",nt.OpenParen],[")",nt.CloseParen],["{",nt.OpenCurlyBracket],["}",nt.CloseCurlyBracket],["[",nt.OpenSquareBracket],["]",nt.CloseSquareBracket],[",",nt.Comma],[".",nt.Dot],[":",nt.Colon],["|",nt.Pipe],["<=",nt.ComparisonBinaryOperator],[">=",nt.ComparisonBinaryOperator],["==",nt.ComparisonBinaryOperator],["!=",nt.ComparisonBinaryOperator],["<",nt.ComparisonBinaryOperator],[">",nt.ComparisonBinaryOperator],["+",nt.AdditiveBinaryOperator],["-",nt.AdditiveBinaryOperator],["~",nt.AdditiveBinaryOperator],["*",nt.MultiplicativeBinaryOperator],["/",nt.MultiplicativeBinaryOperator],["%",nt.MultiplicativeBinaryOperator],["=",nt.Equals]],no=new Map([["n","\n"],["t","	"],["r","\r"],["b","\b"],["f","\f"],["v","\v"],["'","'"],['"','"'],["\\","\\"]]),ns=class{type="Statement"},nl=class extends ns{constructor(e){super(),this.body=e}type="Program"},nu=class extends ns{constructor(e,t,n){super(),this.test=e,this.body=t,this.alternate=n}type="If"},nc=class extends ns{constructor(e,t,n,r){super(),this.loopvar=e,this.iterable=t,this.body=n,this.defaultBlock=r}type="For"},nd=class extends ns{type="Break"},np=class extends ns{type="Continue"},nf=class extends ns{constructor(e,t,n){super(),this.assignee=e,this.value=t,this.body=n}type="Set"},nm=class extends ns{constructor(e,t,n){super(),this.name=e,this.args=t,this.body=n}type="Macro"},nh=class extends ns{constructor(e){super(),this.value=e}type="Comment"},ng=class extends ns{type="Expression"},ny=class extends ng{constructor(e,t,n){super(),this.object=e,this.property=t,this.computed=n}type="MemberExpression"},nb=class extends ng{constructor(e,t){super(),this.callee=e,this.args=t}type="CallExpression"},nv=class extends ng{constructor(e){super(),this.value=e}type="Identifier"},nw=class extends ng{constructor(e){super(),this.value=e}type="Literal"},n_=class extends nw{type="IntegerLiteral"},nk=class extends nw{type="FloatLiteral"},nx=class extends nw{type="StringLiteral"},nS=class extends nw{type="ArrayLiteral"},nA=class extends nw{type="TupleLiteral"},nT=class extends nw{type="ObjectLiteral"},nE=class extends ng{constructor(e,t,n){super(),this.operator=e,this.left=t,this.right=n}type="BinaryExpression"},nI=class extends ng{constructor(e,t){super(),this.operand=e,this.filter=t}type="FilterExpression"},nC=class extends ns{constructor(e,t){super(),this.filter=e,this.body=t}type="FilterStatement"},nP=class extends ng{constructor(e,t){super(),this.lhs=e,this.test=t}type="SelectExpression"},nL=class extends ng{constructor(e,t,n){super(),this.operand=e,this.negate=t,this.test=n}type="TestExpression"},nR=class extends ng{constructor(e,t){super(),this.operator=e,this.argument=t}type="UnaryExpression"},nM=class extends ng{constructor(e,t,n){super(),this.start=e,this.stop=t,this.step=n}type="SliceExpression"},nN=class extends ng{constructor(e,t){super(),this.key=e,this.value=t}type="KeywordArgumentExpression"},nU=class extends ng{constructor(e){super(),this.argument=e}type="SpreadExpression"},nO=class extends ns{constructor(e,t,n){super(),this.call=e,this.callerArgs=t,this.body=n}type="CallStatement"},n$=class extends ng{constructor(e,t,n){super(),this.condition=e,this.trueExpr=t,this.falseExpr=n}type="Ternary"};function nj(e,t,n=1){void 0===t&&(t=e,e=0);let r=[];for(let a=e;a<t;a+=n)r.push(a);return r}function nD(e,t,n,r=1){let a=Math.sign(r);a>=0?(t=(t??=0)<0?Math.max(e.length+t,0):Math.min(t,e.length),n=(n??=e.length)<0?Math.max(e.length+n,0):Math.min(n,e.length)):(t=(t??=e.length-1)<0?Math.max(e.length+t,-1):Math.min(t,e.length-1),n=(n??=-1)<-1?Math.max(e.length+n,-1):Math.min(n,e.length-1));let i=[];for(let o=t;a*o<a*n;o+=r)i.push(e[o]);return i}function nz(e){return function(e,t){let n=new Intl.DateTimeFormat(void 0,{month:"long"}),r=new Intl.DateTimeFormat(void 0,{month:"short"}),a=e=>e<10?"0"+e:e.toString();return t.replace(/%[YmdbBHM%]/g,t=>{switch(t){case"%Y":return e.getFullYear().toString();case"%m":return a(e.getMonth()+1);case"%d":return a(e.getDate());case"%b":return r.format(e);case"%B":return n.format(e);case"%H":return a(e.getHours());case"%M":return a(e.getMinutes());case"%%":return"%";default:return t}})}(new Date,e)}var nF=class extends Error{},nB=class extends Error{},nq=class{type="RuntimeValue";value;builtins=new Map;constructor(e){this.value=e}__bool__(){return new nW(!!this.value)}toString(){return String(this.value)}},nV=class extends nq{type="IntegerValue"},nH=class extends nq{type="FloatValue";toString(){return this.value%1==0?this.value.toFixed(1):this.value.toString()}},nQ=class extends nq{type="StringValue";builtins=new Map([["upper",new nJ(()=>new nQ(this.value.toUpperCase()))],["lower",new nJ(()=>new nQ(this.value.toLowerCase()))],["strip",new nJ(()=>new nQ(this.value.trim()))],["title",new nJ(()=>new nQ(this.value.replace(/\b\w/g,e=>e.toUpperCase())))],["capitalize",new nJ(()=>new nQ(this.value.charAt(0).toUpperCase()+this.value.slice(1)))],["length",new nV(this.value.length)],["rstrip",new nJ(()=>new nQ(this.value.trimEnd()))],["lstrip",new nJ(()=>new nQ(this.value.trimStart()))],["startswith",new nJ(e=>{if(0===e.length)throw Error("startswith() requires at least one argument");let t=e[0];if(t instanceof nQ)return new nW(this.value.startsWith(t.value));if(t instanceof nX){for(let e of t.value){if(!(e instanceof nQ))throw Error("startswith() tuple elements must be strings");if(this.value.startsWith(e.value))return new nW(!0)}return new nW(!1)}throw Error("startswith() argument must be a string or tuple of strings")})],["endswith",new nJ(e=>{if(0===e.length)throw Error("endswith() requires at least one argument");let t=e[0];if(t instanceof nQ)return new nW(this.value.endsWith(t.value));if(t instanceof nX){for(let e of t.value){if(!(e instanceof nQ))throw Error("endswith() tuple elements must be strings");if(this.value.endsWith(e.value))return new nW(!0)}return new nW(!1)}throw Error("endswith() argument must be a string or tuple of strings")})],["split",new nJ(e=>{let t=e[0]??new nZ;if(!(t instanceof nQ||t instanceof nZ))throw Error("sep argument must be a string or null");let n=e[1]??new nV(-1);if(!(n instanceof nV))throw Error("maxsplit argument must be a number");let r=[];if(t instanceof nZ){let e=this.value.trimStart();for(let{0:t,index:a}of e.matchAll(/\S+/g)){if(-1!==n.value&&r.length>=n.value&&void 0!==a){r.push(t+e.slice(a+t.length));break}r.push(t)}}else{if(""===t.value)throw Error("empty separator");r=this.value.split(t.value),-1!==n.value&&r.length>n.value&&r.push(r.splice(n.value).join(t.value))}return new nX(r.map(e=>new nQ(e)))})],["replace",new nJ(e=>{let t;if(e.length<2)throw Error("replace() requires at least two arguments");let n=e[0],r=e[1];if(!(n instanceof nQ&&r instanceof nQ))throw Error("replace() arguments must be strings");if(!((t=e.length>2?"KeywordArgumentsValue"===e[2].type?e[2].value.get("count")??new nZ:e[2]:new nZ)instanceof nV||t instanceof nZ))throw Error("replace() count argument must be a number or null");return new nQ(function(e,t,n,r){if(0===r)return e;let a=null==r||r<0?1/0:r,i=0===t.length?RegExp("(?=)","gu"):RegExp(t.replace(/[.*+?^${}()|[\]\\]/g,"\\$&"),"gu");return e.replaceAll(i,e=>a>0?(--a,n):e)}(this.value,n.value,r.value,t.value))})]])},nW=class extends nq{type="BooleanValue"},nG=class extends nq{type="ObjectValue";__bool__(){return new nW(this.value.size>0)}builtins=new Map([["get",new nJ(([e,t])=>{if(!(e instanceof nQ))throw Error(`Object key must be a string: got ${e.type}`);return this.value.get(e.value)??t??new nZ})],["items",new nJ(()=>this.items())],["keys",new nJ(()=>this.keys())],["values",new nJ(()=>this.values())]]);items(){return new nX(Array.from(this.value.entries()).map(([e,t])=>new nX([new nQ(e),t])))}keys(){return new nX(Array.from(this.value.keys()).map(e=>new nQ(e)))}values(){return new nX(Array.from(this.value.values()))}},nK=class extends nG{type="KeywordArgumentsValue"},nX=class extends nq{type="ArrayValue";builtins=new Map([["length",new nV(this.value.length)]]);__bool__(){return new nW(this.value.length>0)}},nY=class extends nX{type="TupleValue"},nJ=class extends nq{type="FunctionValue"},nZ=class extends nq{type="NullValue"},n0=class extends nq{type="UndefinedValue"},n1=class{constructor(e){this.parent=e}variables=new Map([["namespace",new nJ(e=>{if(0===e.length)return new nG(new Map);if(1!==e.length||!(e[0]instanceof nG))throw Error("`namespace` expects either zero arguments or a single object argument");return e[0]})]]);tests=new Map([["boolean",e=>"BooleanValue"===e.type],["callable",e=>e instanceof nJ],["odd",e=>{if(!(e instanceof nV))throw Error(`cannot odd on ${e.type}`);return e.value%2!=0}],["even",e=>{if(!(e instanceof nV))throw Error(`cannot even on ${e.type}`);return e.value%2==0}],["false",e=>"BooleanValue"===e.type&&!e.value],["true",e=>"BooleanValue"===e.type&&e.value],["none",e=>"NullValue"===e.type],["string",e=>"StringValue"===e.type],["number",e=>e instanceof nV||e instanceof nH],["integer",e=>e instanceof nV],["iterable",e=>"ArrayValue"===e.type||"StringValue"===e.type],["mapping",e=>"ObjectValue"===e.type],["lower",e=>{let t=e.value;return"StringValue"===e.type&&t===t.toLowerCase()}],["upper",e=>{let t=e.value;return"StringValue"===e.type&&t===t.toUpperCase()}],["none",e=>"NullValue"===e.type],["defined",e=>"UndefinedValue"!==e.type],["undefined",e=>"UndefinedValue"===e.type],["equalto",(e,t)=>e.value===t.value],["eq",(e,t)=>e.value===t.value]]);set(e,t){return this.declareVariable(e,function e(t){switch(typeof t){case"number":return Number.isInteger(t)?new nV(t):new nH(t);case"string":return new nQ(t);case"boolean":return new nW(t);case"undefined":return new n0;case"object":if(null===t)return new nZ;if(Array.isArray(t))return new nX(t.map(e));return new nG(new Map(Object.entries(t).map(([t,n])=>[t,e(n)])));case"function":return new nJ((n,r)=>e(t(...n.map(e=>e.value))??null));default:throw Error(`Cannot convert to runtime value: ${t}`)}}(t))}declareVariable(e,t){if(this.variables.has(e))throw SyntaxError(`Variable already declared: ${e}`);return this.variables.set(e,t),t}setVariable(e,t){return this.variables.set(e,t),t}resolve(e){if(this.variables.has(e))return this;if(this.parent)return this.parent.resolve(e);throw Error(`Unknown variable: ${e}`)}lookupVariable(e){try{return this.resolve(e).variables.get(e)??new n0}catch{return new n0}}},n2=class{global;constructor(e){this.global=e??new n1}run(e){return this.evaluate(e,this.global)}evaluateBinaryExpression(e,t){let n=this.evaluate(e.left,t);switch(e.operator.value){case"and":return n.__bool__().value?this.evaluate(e.right,t):n;case"or":return n.__bool__().value?n:this.evaluate(e.right,t)}let r=this.evaluate(e.right,t);switch(e.operator.value){case"==":return new nW(n.value==r.value);case"!=":return new nW(n.value!=r.value)}if(n instanceof n0||r instanceof n0){if(r instanceof n0&&["in","not in"].includes(e.operator.value))return new nW("not in"===e.operator.value);throw Error(`Cannot perform operation ${e.operator.value} on undefined values`)}if(n instanceof nZ||r instanceof nZ)throw Error("Cannot perform operation on null values");if("~"===e.operator.value)return new nQ(n.value.toString()+r.value.toString());if((n instanceof nV||n instanceof nH)&&(r instanceof nV||r instanceof nH)){let t=n.value,a=r.value;switch(e.operator.value){case"+":case"-":case"*":{let i="+"===e.operator.value?t+a:"-"===e.operator.value?t-a:t*a;return n instanceof nH||r instanceof nH?new nH(i):new nV(i)}case"/":return new nH(t/a);case"%":{let e=t%a;return n instanceof nH||r instanceof nH?new nH(e):new nV(e)}case"<":return new nW(t<a);case">":return new nW(t>a);case">=":return new nW(t>=a);case"<=":return new nW(t<=a)}}else if(n instanceof nX&&r instanceof nX){if("+"===e.operator.value)return new nX(n.value.concat(r.value))}else if(r instanceof nX){let t=void 0!==r.value.find(e=>e.value===n.value);switch(e.operator.value){case"in":return new nW(t);case"not in":return new nW(!t)}}if((n instanceof nQ||r instanceof nQ)&&"+"===e.operator.value)return new nQ(n.value.toString()+r.value.toString());if(n instanceof nQ&&r instanceof nQ)switch(e.operator.value){case"in":return new nW(r.value.includes(n.value));case"not in":return new nW(!r.value.includes(n.value))}if(n instanceof nQ&&r instanceof nG)switch(e.operator.value){case"in":return new nW(r.value.has(n.value));case"not in":return new nW(!r.value.has(n.value))}throw SyntaxError(`Unknown operator "${e.operator.value}" between ${n.type} and ${r.type}`)}evaluateArguments(e,t){let n=[],r=new Map;for(let a of e)if("SpreadExpression"===a.type){let e=this.evaluate(a.argument,t);if(!(e instanceof nX))throw Error(`Cannot unpack non-iterable type: ${e.type}`);for(let t of e.value)n.push(t)}else if("KeywordArgumentExpression"===a.type)r.set(a.key.value,this.evaluate(a.value,t));else{if(r.size>0)throw Error("Positional arguments must come before keyword arguments");n.push(this.evaluate(a,t))}return[n,r]}applyFilter(e,t,n){if("Identifier"===t.type){if("tojson"===t.value)return new nQ(n3(e));if(e instanceof nX)switch(t.value){case"list":return e;case"first":return e.value[0];case"last":return e.value[e.value.length-1];case"length":return new nV(e.value.length);case"reverse":return new nX(e.value.reverse());case"sort":return new nX(e.value.sort((e,t)=>{if(e.type!==t.type)throw Error(`Cannot compare different types: ${e.type} and ${t.type}`);switch(e.type){case"IntegerValue":case"FloatValue":return e.value-t.value;case"StringValue":return e.value.localeCompare(t.value);default:throw Error(`Cannot compare type: ${e.type}`)}}));case"join":return new nQ(e.value.map(e=>e.value).join(""));case"string":return new nQ(n3(e));case"unique":{let t=new Set,n=[];for(let r of e.value)t.has(r.value)||(t.add(r.value),n.push(r));return new nX(n)}default:throw Error(`Unknown ArrayValue filter: ${t.value}`)}if(e instanceof nQ)switch(t.value){case"length":case"upper":case"lower":case"title":case"capitalize":{let r=e.builtins.get(t.value);if(r instanceof nJ)return r.value([],n);if(r instanceof nV)return r;throw Error(`Unknown StringValue filter: ${t.value}`)}case"trim":return new nQ(e.value.trim());case"indent":return new nQ(e.value.split("\n").map((e,t)=>0===t||0===e.length?e:"    "+e).join("\n"));case"join":case"string":return e;case"int":{let t=parseInt(e.value,10);return new nV(isNaN(t)?0:t)}case"float":{let t=parseFloat(e.value);return new nH(isNaN(t)?0:t)}default:throw Error(`Unknown StringValue filter: ${t.value}`)}if(e instanceof nV||e instanceof nH)switch(t.value){case"abs":return e instanceof nV?new nV(Math.abs(e.value)):new nH(Math.abs(e.value));case"int":return new nV(Math.floor(e.value));case"float":return new nH(e.value);default:throw Error(`Unknown NumericValue filter: ${t.value}`)}else if(e instanceof nG)switch(t.value){case"items":return new nX(Array.from(e.value.entries()).map(([e,t])=>new nX([new nQ(e),t])));case"length":return new nV(e.value.size);default:throw Error(`Unknown ObjectValue filter: ${t.value}`)}else if(e instanceof nW)switch(t.value){case"bool":return new nW(e.value);case"int":return new nV(+!!e.value);case"float":return new nH(+!!e.value);case"string":return new nQ(e.value?"true":"false");default:throw Error(`Unknown BooleanValue filter: ${t.value}`)}throw Error(`Cannot apply filter "${t.value}" to type: ${e.type}`)}if("CallExpression"===t.type){if("Identifier"!==t.callee.type)throw Error(`Unknown filter: ${t.callee.type}`);let r=t.callee.value;if("tojson"===r){let[,r]=this.evaluateArguments(t.args,n),a=r.get("indent")??new nZ;if(!(a instanceof nV||a instanceof nZ))throw Error("If set, indent must be a number");return new nQ(n3(e,a.value))}if("join"===r){let a;if(e instanceof nQ)a=Array.from(e.value);else if(e instanceof nX)a=e.value.map(e=>e.value);else throw Error(`Cannot apply filter "${r}" to type: ${e.type}`);let[i,o]=this.evaluateArguments(t.args,n),s=i.at(0)??o.get("separator")??new nQ("");if(!(s instanceof nQ))throw Error("separator must be a string");return new nQ(a.join(s.value))}if("int"===r||"float"===r){let[a,i]=this.evaluateArguments(t.args,n),o=a.at(0)??i.get("default")??("int"===r?new nV(0):new nH(0));if(e instanceof nQ){let t="int"===r?parseInt(e.value,10):parseFloat(e.value);return isNaN(t)?o:"int"===r?new nV(t):new nH(t)}if(e instanceof nV||e instanceof nH)return e;if(e instanceof nW)return"int"===r?new nV(+!!e.value):new nH(+!!e.value);else throw Error(`Cannot apply filter "${r}" to type: ${e.type}`)}else if("default"===r){let[r,a]=this.evaluateArguments(t.args,n),i=r[0]??new nQ(""),o=r[1]??a.get("boolean")??new nW(!1);if(!(o instanceof nW))throw Error("`default` filter flag must be a boolean");return e instanceof n0||o.value&&!e.__bool__().value?i:e}if(e instanceof nX){switch(r){case"selectattr":case"rejectattr":{let a,i="selectattr"===r;if(e.value.some(e=>!(e instanceof nG)))throw Error(`\`${r}\` can only be applied to array of objects`);if(t.args.some(e=>"StringLiteral"!==e.type))throw Error(`arguments of \`${r}\` must be strings`);let[o,s,l]=t.args.map(e=>this.evaluate(e,n));if(s){let e=n.tests.get(s.value);if(!e)throw Error(`Unknown test: ${s.value}`);a=e}else a=(...e)=>e[0].__bool__().value;return new nX(e.value.filter(e=>{let t=e.value.get(o.value),n=!!t&&a(t,l);return i?n:!n}))}case"map":{let[,r]=this.evaluateArguments(t.args,n);if(r.has("attribute")){let t=r.get("attribute");if(!(t instanceof nQ))throw Error("attribute must be a string");let n=r.get("default");return new nX(e.value.map(e=>{if(!(e instanceof nG))throw Error("items in map must be an object");return e.value.get(t.value)??n??new n0}))}throw Error("`map` expressions without `attribute` set are not currently supported.")}}throw Error(`Unknown ArrayValue filter: ${r}`)}if(e instanceof nQ){switch(r){case"indent":{let[r,a]=this.evaluateArguments(t.args,n),i=r.at(0)??a.get("width")??new nV(4);if(!(i instanceof nV))throw Error("width must be a number");let o=r.at(1)??a.get("first")??new nW(!1),s=r.at(2)??a.get("blank")??new nW(!1),l=e.value.split("\n"),u=" ".repeat(i.value);return new nQ(l.map((e,t)=>(o.value||0!==t)&&(s.value||0!==e.length)?u+e:e).join("\n"))}case"replace":{let r=e.builtins.get("replace");if(!(r instanceof nJ))throw Error("replace filter not available");let[a,i]=this.evaluateArguments(t.args,n);return r.value([...a,new nK(i)],n)}}throw Error(`Unknown StringValue filter: ${r}`)}throw Error(`Cannot apply filter "${r}" to type: ${e.type}`)}throw Error(`Unknown filter: ${t.type}`)}evaluateFilterExpression(e,t){let n=this.evaluate(e.operand,t);return this.applyFilter(n,e.filter,t)}evaluateTestExpression(e,t){let n=this.evaluate(e.operand,t),r=t.tests.get(e.test.value);if(!r)throw Error(`Unknown test: ${e.test.value}`);let a=r(n);return new nW(e.negate?!a:a)}evaluateSelectExpression(e,t){return this.evaluate(e.test,t).__bool__().value?this.evaluate(e.lhs,t):new n0}evaluateUnaryExpression(e,t){let n=this.evaluate(e.argument,t);if("not"===e.operator.value)return new nW(!n.value);throw SyntaxError(`Unknown operator: ${e.operator.value}`)}evaluateTernaryExpression(e,t){return this.evaluate(e.condition,t).__bool__().value?this.evaluate(e.trueExpr,t):this.evaluate(e.falseExpr,t)}evalProgram(e,t){return this.evaluateBlock(e.body,t)}evaluateBlock(e,t){let n="";for(let r of e){let e=this.evaluate(r,t);"NullValue"!==e.type&&"UndefinedValue"!==e.type&&(n+=e.toString())}return new nQ(n)}evaluateIdentifier(e,t){return t.lookupVariable(e.value)}evaluateCallExpression(e,t){let[n,r]=this.evaluateArguments(e.args,t);r.size>0&&n.push(new nK(r));let a=this.evaluate(e.callee,t);if("FunctionValue"!==a.type)throw Error(`Cannot call something that is not a function: got ${a.type}`);return a.value(n,t)}evaluateSliceExpression(e,t,n){if(!(e instanceof nX||e instanceof nQ))throw Error("Slice object must be an array or string");let r=this.evaluate(t.start,n),a=this.evaluate(t.stop,n),i=this.evaluate(t.step,n);if(!(r instanceof nV||r instanceof n0))throw Error("Slice start must be numeric or undefined");if(!(a instanceof nV||a instanceof n0))throw Error("Slice stop must be numeric or undefined");if(!(i instanceof nV||i instanceof n0))throw Error("Slice step must be numeric or undefined");return e instanceof nX?new nX(nD(e.value,r.value,a.value,i.value)):new nQ(nD(Array.from(e.value),r.value,a.value,i.value).join(""))}evaluateMemberExpression(e,t){let n,r,a=this.evaluate(e.object,t);if(e.computed)if("SliceExpression"===e.property.type)return this.evaluateSliceExpression(a,e.property,t);else n=this.evaluate(e.property,t);else n=new nQ(e.property.value);if(a instanceof nG){if(!(n instanceof nQ))throw Error(`Cannot access property with non-string: got ${n.type}`);r=a.value.get(n.value)??a.builtins.get(n.value)}else if(a instanceof nX||a instanceof nQ)if(n instanceof nV)r=a.value.at(n.value),a instanceof nQ&&(r=new nQ(a.value.at(n.value)));else if(n instanceof nQ)r=a.builtins.get(n.value);else throw Error(`Cannot access property with non-string/non-number: got ${n.type}`);else{if(!(n instanceof nQ))throw Error(`Cannot access property with non-string: got ${n.type}`);r=a.builtins.get(n.value)}return r instanceof nq?r:new n0}evaluateSet(e,t){let n=e.value?this.evaluate(e.value,t):this.evaluateBlock(e.body,t);if("Identifier"===e.assignee.type){let r=e.assignee.value;t.setVariable(r,n)}else if("TupleLiteral"===e.assignee.type){let r=e.assignee;if(!(n instanceof nX))throw Error(`Cannot unpack non-iterable type in set: ${n.type}`);let a=n.value;if(a.length!==r.value.length)throw Error(`Too ${r.value.length>a.length?"few":"many"} items to unpack in set`);for(let e=0;e<r.value.length;++e){let n=r.value[e];if("Identifier"!==n.type)throw Error(`Cannot unpack to non-identifier in set: ${n.type}`);t.setVariable(n.value,a[e])}}else if("MemberExpression"===e.assignee.type){let r=e.assignee,a=this.evaluate(r.object,t);if(!(a instanceof nG))throw Error("Cannot assign to member of non-object");if("Identifier"!==r.property.type)throw Error("Cannot assign to member with non-identifier property");a.value.set(r.property.value,n)}else throw Error(`Invalid LHS inside assignment expression: ${JSON.stringify(e.assignee)}`);return new nZ}evaluateIf(e,t){let n=this.evaluate(e.test,t);return this.evaluateBlock(n.__bool__().value?e.body:e.alternate,t)}evaluateFor(e,t){let n,r,a=new n1(t);if("SelectExpression"===e.iterable.type){let t=e.iterable;r=this.evaluate(t.lhs,a),n=t.test}else r=this.evaluate(e.iterable,a);if(!(r instanceof nX||r instanceof nG))throw Error(`Expected iterable or object type in for loop: got ${r.type}`);r instanceof nG&&(r=r.keys());let i=[],o=[];for(let t=0;t<r.value.length;++t){let s,l=new n1(a),u=r.value[t];if("Identifier"===e.loopvar.type)s=t=>t.setVariable(e.loopvar.value,u);else if("TupleLiteral"===e.loopvar.type){let t=e.loopvar;if("ArrayValue"!==u.type)throw Error(`Cannot unpack non-iterable type: ${u.type}`);if(t.value.length!==u.value.length)throw Error(`Too ${t.value.length>u.value.length?"few":"many"} items to unpack`);s=e=>{for(let n=0;n<t.value.length;++n){if("Identifier"!==t.value[n].type)throw Error(`Cannot unpack non-identifier type: ${t.value[n].type}`);e.setVariable(t.value[n].value,u.value[n])}}}else throw Error(`Invalid loop variable(s): ${e.loopvar.type}`);(!n||(s(l),this.evaluate(n,l).__bool__().value))&&(i.push(u),o.push(s))}let s="",l=!0;for(let t=0;t<i.length;++t){let n=new Map([["index",new nV(t+1)],["index0",new nV(t)],["revindex",new nV(i.length-t)],["revindex0",new nV(i.length-t-1)],["first",new nW(0===t)],["last",new nW(t===i.length-1)],["length",new nV(i.length)],["previtem",t>0?i[t-1]:new n0],["nextitem",t<i.length-1?i[t+1]:new n0]]);a.setVariable("loop",new nG(n)),o[t](a);try{let t=this.evaluateBlock(e.body,a);s+=t.value}catch(e){if(e instanceof nB)continue;if(e instanceof nF)break;throw e}l=!1}return l&&(s+=this.evaluateBlock(e.defaultBlock,a).value),new nQ(s)}evaluateMacro(e,t){return t.setVariable(e.name.value,new nJ((t,n)=>{let r,a=new n1(n);t=t.slice(),t.at(-1)?.type==="KeywordArgumentsValue"&&(r=t.pop());for(let n=0;n<e.args.length;++n){let i=e.args[n],o=t[n];if("Identifier"===i.type){if(!o)throw Error(`Missing positional argument: ${i.value}`);a.setVariable(i.value,o)}else if("KeywordArgumentExpression"===i.type){let e=o??r?.value.get(i.key.value)??this.evaluate(i.value,a);a.setVariable(i.key.value,e)}else throw Error(`Unknown argument type: ${i.type}`)}return this.evaluateBlock(e.body,a)})),new nZ}evaluateCallStatement(e,t){let n=new nJ((t,n)=>{let r=new n1(n);if(e.callerArgs)for(let n=0;n<e.callerArgs.length;++n){let a=e.callerArgs[n];if("Identifier"!==a.type)throw Error(`Caller parameter must be an identifier, got ${a.type}`);r.setVariable(a.value,t[n]??new n0)}return this.evaluateBlock(e.body,r)}),[r,a]=this.evaluateArguments(e.call.args,t);r.push(new nK(a));let i=this.evaluate(e.call.callee,t);if("FunctionValue"!==i.type)throw Error(`Cannot call something that is not a function: got ${i.type}`);let o=new n1(t);return o.setVariable("caller",n),i.value(r,o)}evaluateFilterStatement(e,t){let n=this.evaluateBlock(e.body,t);return this.applyFilter(n,e.filter,t)}evaluate(e,t){if(!e)return new n0;switch(e.type){case"Program":return this.evalProgram(e,t);case"Set":return this.evaluateSet(e,t);case"If":return this.evaluateIf(e,t);case"For":return this.evaluateFor(e,t);case"Macro":return this.evaluateMacro(e,t);case"CallStatement":return this.evaluateCallStatement(e,t);case"Break":throw new nF;case"Continue":throw new nB;case"IntegerLiteral":return new nV(e.value);case"FloatLiteral":return new nH(e.value);case"StringLiteral":return new nQ(e.value);case"ArrayLiteral":return new nX(e.value.map(e=>this.evaluate(e,t)));case"TupleLiteral":return new nY(e.value.map(e=>this.evaluate(e,t)));case"ObjectLiteral":{let n=new Map;for(let[r,a]of e.value){let e=this.evaluate(r,t);if(!(e instanceof nQ))throw Error(`Object keys must be strings: got ${e.type}`);n.set(e.value,this.evaluate(a,t))}return new nG(n)}case"Identifier":return this.evaluateIdentifier(e,t);case"CallExpression":return this.evaluateCallExpression(e,t);case"MemberExpression":return this.evaluateMemberExpression(e,t);case"UnaryExpression":return this.evaluateUnaryExpression(e,t);case"BinaryExpression":return this.evaluateBinaryExpression(e,t);case"FilterExpression":return this.evaluateFilterExpression(e,t);case"FilterStatement":return this.evaluateFilterStatement(e,t);case"TestExpression":return this.evaluateTestExpression(e,t);case"SelectExpression":return this.evaluateSelectExpression(e,t);case"Ternary":return this.evaluateTernaryExpression(e,t);case"Comment":return new nZ;default:throw SyntaxError(`Unknown node type: ${e.type}`)}}};function n3(e,t,n){let r=n??0;switch(e.type){case"NullValue":case"UndefinedValue":return"null";case"IntegerValue":case"FloatValue":case"StringValue":case"BooleanValue":return JSON.stringify(e.value);case"ArrayValue":case"ObjectValue":{let n=t?" ".repeat(t):"",a="\n"+n.repeat(r),i=a+n;if("ArrayValue"===e.type){let n=e.value.map(e=>n3(e,t,r+1));return t?`[${i}${n.join(`,${i}`)}${a}]`:`[${n.join(", ")}]`}{let n=Array.from(e.value.entries()).map(([e,n])=>{let a=`"${e}": ${n3(n,t,r+1)}`;return t?`${i}${a}`:a});return t?`{${n.join(",")}${a}}`:`{${n.join(", ")}}`}}default:throw Error(`Cannot convert to JSON: ${e.type}`)}}function n4(...e){return"{%- "+e.join(" ")+" -%}"}function n6(e,t=-1){switch(e.type){case"SpreadExpression":return`*${n6(e.argument)}`;case"Identifier":return e.value;case"IntegerLiteral":case"FloatLiteral":return`${e.value}`;case"StringLiteral":return JSON.stringify(e.value);case"BinaryExpression":{let n=function(e){switch(e.operator.type){case"MultiplicativeBinaryOperator":return 4;case"AdditiveBinaryOperator":return 3;case"ComparisonBinaryOperator":return 2;case"Identifier":if("and"===e.operator.value)return 1;if("in"===e.operator.value||"not in"===e.operator.value)return 2}return 0}(e),r=n6(e.left,n),a=n6(e.right,n+1),i=`${r} ${e.operator.value} ${a}`;return n<t?`(${i})`:i}case"UnaryExpression":return e.operator.value+("not"===e.operator.value?" ":"")+n6(e.argument,1/0);case"CallExpression":{let t=e.args.map(n6).join(", ");return`${n6(e.callee)}(${t})`}case"MemberExpression":{let t=n6(e.object);["Identifier","MemberExpression","CallExpression","StringLiteral","IntegerLiteral","FloatLiteral","ArrayLiteral","TupleLiteral","ObjectLiteral"].includes(e.object.type)||(t=`(${t})`);let n=n6(e.property);return e.computed||"Identifier"===e.property.type||(n=`(${n})`),e.computed?`${t}[${n}]`:`${t}.${n}`}case"FilterExpression":{let t=n6(e.operand,1/0);if("CallExpression"===e.filter.type)return`${t} | ${n6(e.filter)}`;return`${t} | ${e.filter.value}`}case"SelectExpression":return`${n6(e.lhs)} if ${n6(e.test)}`;case"TestExpression":return`${n6(e.operand)} is${e.negate?" not":""} ${e.test.value}`;case"ArrayLiteral":case"TupleLiteral":{let t=e.value.map(n6),n="ArrayLiteral"===e.type?"[]":"()";return`${n[0]}${t.join(", ")}${n[1]}`}case"ObjectLiteral":{let t=Array.from(e.value.entries()).map(([e,t])=>`${n6(e)}: ${n6(t)}`);return`{${t.join(", ")}}`}case"SliceExpression":{let t=e.start?n6(e.start):"",n=e.stop?n6(e.stop):"",r=e.step?`:${n6(e.step)}`:"";return`${t}:${n}${r}`}case"KeywordArgumentExpression":return`${e.key.value}=${n6(e.value)}`;case"Ternary":{let n=`${n6(e.trueExpr)} if ${n6(e.condition,0)} else ${n6(e.falseExpr)}`;return t>-1?`(${n})`:n}default:throw Error(`Unknown expression type: ${e.type}`)}}var n5=class{parsed;constructor(e){let t=function(e,t={}){let n=[],r=function(e,t={}){return e.endsWith("\n")&&(e=e.slice(0,-1)),t.lstrip_blocks&&(e=e.replace(/^[ \t]*({[#%-])/gm,"$1")),t.trim_blocks&&(e=e.replace(/([#%-]})\n/g,"$1")),e.replace(/-%}\s*/g,"%}").replace(/\s*{%-/g,"{%").replace(/-}}\s*/g,"}}").replace(/\s*{{-/g,"{{").replace(/-#}\s*/g,"#}").replace(/\s*{#-/g,"{#").replace(/{%\s*(end)?generation\s*%}/gs,"")}(e,t),a=0,i=0,o=e=>{let t="";for(;e(r[a]);){if("\\"===r[a]){if(++a>=r.length)throw SyntaxError("Unexpected end of input");let e=r[a++],n=no.get(e);if(void 0===n)throw SyntaxError(`Unexpected escaped character: ${e}`);t+=n;continue}if(t+=r[a++],a>=r.length)throw SyntaxError("Unexpected end of input")}return t};r:for(;a<r.length;){let e=n.at(-1)?.type;if(void 0===e||e===nt.CloseStatement||e===nt.CloseExpression||e===nt.Comment){let e="";for(;a<r.length&&("{"!==r[a]||"%"!==r[a+1]&&"{"!==r[a+1]&&"#"!==r[a+1]);)e+=r[a++];if(e.length>0){n.push(new nn(e,nt.Text));continue}}if("{"===r[a]&&"#"===r[a+1]){a+=2;let e="";for(;"#"!==r[a]||"}"!==r[a+1];){if(a+2>=r.length)throw SyntaxError("Missing end of comment tag");e+=r[a++]}n.push(new nn(e,nt.Comment)),a+=2;continue}o(e=>/\s/.test(e));let t=r[a];if("-"===t||"+"===t){let e=n.at(-1)?.type;if(e===nt.Text||void 0===e)throw SyntaxError(`Unexpected character: ${t}`);switch(e){case nt.Identifier:case nt.NumericLiteral:case nt.StringLiteral:case nt.CloseParen:case nt.CloseSquareBracket:break;default:{++a;let e=o(na);n.push(new nn(`${t}${e}`,e.length>0?nt.NumericLiteral:nt.UnaryOperator));continue}}}for(let[e,t]of ni)if(("}}"!==e||!(i>0))&&r.slice(a,a+e.length)===e){n.push(new nn(e,t)),t===nt.OpenExpression?i=0:t===nt.OpenCurlyBracket?++i:t===nt.CloseCurlyBracket&&--i,a+=e.length;continue r}if("'"===t||'"'===t){++a;let e=o(e=>e!==t);n.push(new nn(e,nt.StringLiteral)),++a;continue}if(na(t)){let e=o(na);if("."===r[a]&&na(r[a+1])){++a;let t=o(na);e=`${e}.${t}`}n.push(new nn(e,nt.NumericLiteral));continue}if(nr(t)){let e=o(nr);n.push(new nn(e,nt.Identifier));continue}throw SyntaxError(`Unexpected character: ${t}`)}return n}(e,{lstrip_blocks:!0,trim_blocks:!0});this.parsed=function(e){let t=new nl([]),n=0;function r(t,r){let a=e[n++];if(!a||a.type!==t)throw Error(`Parser Error: ${r}. ${a.type} !== ${t}.`);return a}function a(e){if(!s(e))throw SyntaxError(`Expected ${e}`);++n}function i(...t){return n+t.length<=e.length&&t.every((t,r)=>t===e[n+r].type)}function o(...t){return e[n]?.type===nt.OpenStatement&&e[n+1]?.type===nt.Identifier&&t.includes(e[n+1]?.value)}function s(...t){return n+t.length<=e.length&&t.every((t,r)=>"Identifier"===e[n+r].type&&t===e[n+r].value)}function l(e=!1){let t=e?v:u,r=[t()],a=i(nt.Comma);for(;a&&(++n,r.push(t()),i(nt.Comma)););return a?new nA(r):r[0]}function u(){return function e(){let t=c();if(s("if")){++n;let r=c();return s("else")?(++n,new n$(r,t,e())):new nP(t,r)}return t}()}function c(){let t=d();for(;s("or");){let r=e[n];++n,t=new nE(r,t,d())}return t}function d(){let t=p();for(;s("and");){let r=e[n];++n,t=new nE(r,t,p())}return t}function p(){let t;for(;s("not");){let r=e[n];++n,t=new nR(r,p())}return t??function(){let t=f();for(;;){let r;if(s("not","in"))r=new nn("not in",nt.Identifier),n+=2;else if(s("in"))r=e[n++];else if(i(nt.ComparisonBinaryOperator))r=e[n++];else break;t=new nE(r,t,f())}return t}()}function f(){let t=y();for(;i(nt.AdditiveBinaryOperator);){let r=e[n];++n,t=new nE(r,t,y())}return t}function m(e){let t=new nb(e,h());return t=g(t),i(nt.OpenParen)&&(t=m(t)),t}function h(){r(nt.OpenParen,"Expected opening parenthesis for arguments list");let t=function(){let t=[];for(;!i(nt.CloseParen);){let r;if(e[n].type===nt.MultiplicativeBinaryOperator&&"*"===e[n].value)++n,r=new nU(u());else if(r=u(),i(nt.Equals)){if(++n,!(r instanceof nv))throw SyntaxError("Expected identifier for keyword argument");r=new nN(r,u())}t.push(r),i(nt.Comma)&&++n}return t}();return r(nt.CloseParen,"Expected closing parenthesis for arguments list"),t}function g(t){for(;i(nt.Dot)||i(nt.OpenSquareBracket);){let a,o=e[n];++n;let s=o.type===nt.OpenSquareBracket;if(s)a=function(){let e=[],t=!1;for(;!i(nt.CloseSquareBracket);)i(nt.Colon)?(e.push(void 0),++n,t=!0):(e.push(u()),i(nt.Colon)&&(++n,t=!0));if(0===e.length)throw SyntaxError("Expected at least one argument for member/slice expression");if(t){if(e.length>3)throw SyntaxError("Expected 0-3 arguments for slice expression");return new nM(...e)}return e[0]}(),r(nt.CloseSquareBracket,"Expected closing square bracket");else if("Identifier"!==(a=v()).type)throw SyntaxError("Expected identifier following dot operator");t=new ny(t,a,s)}return t}function y(){let t=b();for(;i(nt.MultiplicativeBinaryOperator);)t=new nE(e[n++],t,b());return t}function b(){let e=function(){let e=function(){let e=g(v());return i(nt.OpenParen)?m(e):e}();for(;i(nt.Pipe);){++n;let t=v();if(!(t instanceof nv))throw SyntaxError("Expected identifier for the filter");i(nt.OpenParen)&&(t=m(t)),e=new nI(e,t)}return e}();for(;s("is");){++n;let t=s("not");t&&++n;let r=v();if(!(r instanceof nv))throw SyntaxError("Expected identifier for the test");e=new nL(e,t,r)}return e}function v(){let t=e[n++];switch(t.type){case nt.NumericLiteral:{let e=t.value;return e.includes(".")?new nk(Number(e)):new n_(Number(e))}case nt.StringLiteral:{let r=t.value;for(;i(nt.StringLiteral);)r+=e[n++].value;return new nx(r)}case nt.Identifier:return new nv(t.value);case nt.OpenParen:{let e=l();return r(nt.CloseParen,"Expected closing parenthesis, got ${tokens[current].type} instead."),e}case nt.OpenSquareBracket:{let e=[];for(;!i(nt.CloseSquareBracket);)e.push(u()),i(nt.Comma)&&++n;return++n,new nS(e)}case nt.OpenCurlyBracket:{let e=new Map;for(;!i(nt.CloseCurlyBracket);){let t=u();r(nt.Colon,"Expected colon between key and value in object literal");let a=u();e.set(t,a),i(nt.Comma)&&++n}return++n,new nT(e)}default:throw SyntaxError(`Unexpected token: ${t.type}`)}}for(;n<e.length;)t.body.push(function t(){switch(e[n].type){case nt.Comment:return new nh(e[n++].value);case nt.Text:return new nx(r(nt.Text,"Expected text token").value);case nt.OpenStatement:return function(){let c;if(r(nt.OpenStatement,"Expected opening statement token"),e[n].type!==nt.Identifier)throw SyntaxError(`Unknown statement, got ${e[n].type}`);let d=e[n].value;switch(d){case"set":++n,c=function(){let e=l(),s=null,u=[];if(i(nt.Equals))++n,s=l();else{for(r(nt.CloseStatement,"Expected %} token");!o("endset");)u.push(t());r(nt.OpenStatement,"Expected {% token"),a("endset")}return r(nt.CloseStatement,"Expected closing statement token"),new nf(e,s,u)}();break;case"if":++n,c=function e(){let a=u();r(nt.CloseStatement,"Expected closing statement token");let i=[],s=[];for(;!o("elif","else","endif");)i.push(t());if(o("elif")){++n,++n;let t=e();s.push(t)}else if(o("else"))for(++n,++n,r(nt.CloseStatement,"Expected closing statement token");!o("endif");)s.push(t());return new nu(a,i,s)}(),r(nt.OpenStatement,"Expected {% token"),a("endif"),r(nt.CloseStatement,"Expected %} token");break;case"macro":++n,c=function(){let e=v();if("Identifier"!==e.type)throw SyntaxError("Expected identifier following macro statement");let n=h();r(nt.CloseStatement,"Expected closing statement token");let a=[];for(;!o("endmacro");)a.push(t());return new nm(e,n,a)}(),r(nt.OpenStatement,"Expected {% token"),a("endmacro"),r(nt.CloseStatement,"Expected %} token");break;case"for":++n,c=function(){let e=l(!0);if(!(e instanceof nv||e instanceof nA))throw SyntaxError(`Expected identifier/tuple for the loop variable, got ${e.type} instead`);if(!s("in"))throw SyntaxError("Expected `in` keyword following loop variable");++n;let a=u();r(nt.CloseStatement,"Expected closing statement token");let i=[];for(;!o("endfor","else");)i.push(t());let c=[];if(o("else"))for(++n,++n,r(nt.CloseStatement,"Expected closing statement token");!o("endfor");)c.push(t());return new nc(e,a,i,c)}(),r(nt.OpenStatement,"Expected {% token"),a("endfor"),r(nt.CloseStatement,"Expected %} token");break;case"call":{++n;let e=null;i(nt.OpenParen)&&(e=h());let s=v();if("Identifier"!==s.type)throw SyntaxError("Expected identifier following call statement");let l=h();r(nt.CloseStatement,"Expected closing statement token");let u=[];for(;!o("endcall");)u.push(t());r(nt.OpenStatement,"Expected '{%'"),a("endcall"),r(nt.CloseStatement,"Expected closing statement token"),c=new nO(new nb(s,l),e,u);break}case"break":++n,r(nt.CloseStatement,"Expected closing statement token"),c=new nd;break;case"continue":++n,r(nt.CloseStatement,"Expected closing statement token"),c=new np;break;case"filter":{++n;let e=v();e instanceof nv&&i(nt.OpenParen)&&(e=m(e)),r(nt.CloseStatement,"Expected closing statement token");let s=[];for(;!o("endfilter");)s.push(t());r(nt.OpenStatement,"Expected '{%'"),a("endfilter"),r(nt.CloseStatement,"Expected '%}'"),c=new nC(e,s);break}default:throw SyntaxError(`Unknown statement type: ${d}`)}return c}();case nt.OpenExpression:r(nt.OpenExpression,"Expected opening expression token");let c=u();return r(nt.CloseExpression,"Expected closing expression token"),c;default:throw SyntaxError(`Unexpected token type: ${e[n].type}`)}}());return t}(t)}render(e){let t=new n1;if(t.set("false",!1),t.set("true",!0),t.set("none",null),t.set("raise_exception",e=>{throw Error(e)}),t.set("range",nj),t.set("strftime_now",nz),t.set("True",!0),t.set("False",!1),t.set("None",null),e)for(let[n,r]of Object.entries(e))t.set(n,r);return new n2(t).run(this.parsed).value}format(e){return function(e,t="	"){let n="number"==typeof t?" ".repeat(t):t;return(function e(t,n,r){return t.map(t=>(function(t,n,r){let a=r.repeat(n);switch(t.type){case"Program":return e(t.body,n,r);case"If":return function(t,n,r){let a=r.repeat(n),i=[],o=t;for(;o;)if(i.push({test:o.test,body:o.body}),1===o.alternate.length&&"If"===o.alternate[0].type)o=o.alternate[0];else break;let s=a+n4("if",n6(i[0].test))+"\n"+e(i[0].body,n+1,r);for(let t=1;t<i.length;++t)s+="\n"+a+n4("elif",n6(i[t].test))+"\n"+e(i[t].body,n+1,r);return o&&o.alternate.length>0&&(s+="\n"+a+n4("else")+"\n"+e(o.alternate,n+1,r)),s+="\n"+a+n4("endif")}(t,n,r);case"For":var i=t,o=n,s=r;let l=s.repeat(o),u="";if("SelectExpression"===i.iterable.type){let e=i.iterable;u=`${n6(e.lhs)} if ${n6(e.test)}`}else u=n6(i.iterable);let c=l+n4("for",n6(i.loopvar),"in",u)+"\n"+e(i.body,o+1,s);return i.defaultBlock.length>0&&(c+="\n"+l+n4("else")+"\n"+e(i.defaultBlock,o+1,s)),c+="\n"+l+n4("endfor");case"Set":var d=t,p=n,f=r;let m=f.repeat(p),h=n6(d.assignee),g=d.value?n6(d.value):"",y=m+n4("set",`${h}${d.value?" = "+g:""}`);return 0===d.body.length?y:y+"\n"+e(d.body,p+1,f)+"\n"+m+n4("endset");case"Macro":var b=t,v=n,w=r;let _=w.repeat(v),k=b.args.map(n6).join(", ");return _+n4("macro",`${b.name.value}(${k})`)+"\n"+e(b.body,v+1,w)+"\n"+_+n4("endmacro");case"Break":return a+n4("break");case"Continue":return a+n4("continue");case"CallStatement":var x=t,S=n,A=r;let T=A.repeat(S),E=x.callerArgs&&x.callerArgs.length>0?`(${x.callerArgs.map(n6).join(", ")})`:"",I=T+n4(`call${E}`,n6(x.call))+"\n";return I+=e(x.body,S+1,A)+"\n",I+=T+n4("endcall");case"FilterStatement":var C=t,P=n,L=r;let R=L.repeat(P),M=R+n4("filter","Identifier"===C.filter.type?C.filter.value:n6(C.filter))+"\n";return M+=e(C.body,P+1,L)+"\n",M+=R+n4("endfilter");case"Comment":return a+"{# "+t.value+" #}";default:return a+"{{- "+n6(t)+" -}}"}})(t,n,r)).join("\n")})(e.body,0,n).replace(/\n$/,"")}(this.parsed,e?.indent||"	")}};const n8=["audio-classification","automatic-speech-recognition","depth-estimation","document-question-answering","feature-extraction","fill-mask","image-classification","image-feature-extraction","image-segmentation","image-to-image","image-to-text","image-text-to-text","mask-generation","object-detection","question-answering","summarization","table-question-answering","text-classification","text-generation","text-to-audio","text-to-speech","token-classification","translation","video-classification","visual-question-answering","zero-shot-classification","zero-shot-image-classification","zero-shot-object-detection"],n9={"text-classification":{name:"Text Classification",subtasks:[{type:"acceptability-classification",name:"Acceptability Classification"},{type:"entity-linking-classification",name:"Entity Linking Classification"},{type:"fact-checking",name:"Fact Checking"},{type:"intent-classification",name:"Intent Classification"},{type:"language-identification",name:"Language Identification"},{type:"multi-class-classification",name:"Multi Class Classification"},{type:"multi-label-classification",name:"Multi Label Classification"},{type:"multi-input-text-classification",name:"Multi-input Text Classification"},{type:"natural-language-inference",name:"Natural Language Inference"},{type:"semantic-similarity-classification",name:"Semantic Similarity Classification"},{type:"sentiment-classification",name:"Sentiment Classification"},{type:"topic-classification",name:"Topic Classification"},{type:"semantic-similarity-scoring",name:"Semantic Similarity Scoring"},{type:"sentiment-scoring",name:"Sentiment Scoring"},{type:"sentiment-analysis",name:"Sentiment Analysis"},{type:"hate-speech-detection",name:"Hate Speech Detection"},{type:"text-scoring",name:"Text Scoring"}],modality:"nlp"},"token-classification":{name:"Token Classification",subtasks:[{type:"named-entity-recognition",name:"Named Entity Recognition"},{type:"part-of-speech",name:"Part of Speech"},{type:"parsing",name:"Parsing"},{type:"lemmatization",name:"Lemmatization"},{type:"word-sense-disambiguation",name:"Word Sense Disambiguation"},{type:"coreference-resolution",name:"Coreference-resolution"}],modality:"nlp"},"table-question-answering":{name:"Table Question Answering",modality:"nlp"},"question-answering":{name:"Question Answering",subtasks:[{type:"extractive-qa",name:"Extractive QA"},{type:"open-domain-qa",name:"Open Domain QA"},{type:"closed-domain-qa",name:"Closed Domain QA"}],modality:"nlp"},"zero-shot-classification":{name:"Zero-Shot Classification",modality:"nlp"},translation:{name:"Translation",modality:"nlp"},summarization:{name:"Summarization",subtasks:[{type:"news-articles-summarization",name:"News Articles Summarization"},{type:"news-articles-headline-generation",name:"News Articles Headline Generation"}],modality:"nlp"},"feature-extraction":{name:"Feature Extraction",modality:"nlp"},"text-generation":{name:"Text Generation",subtasks:[{type:"dialogue-modeling",name:"Dialogue Modeling"},{type:"dialogue-generation",name:"Dialogue Generation"},{type:"conversational",name:"Conversational"},{type:"language-modeling",name:"Language Modeling"},{type:"text-simplification",name:"Text simplification"},{type:"explanation-generation",name:"Explanation Generation"},{type:"abstractive-qa",name:"Abstractive QA"},{type:"open-domain-abstractive-qa",name:"Open Domain Abstractive QA"},{type:"closed-domain-qa",name:"Closed Domain QA"},{type:"open-book-qa",name:"Open Book QA"},{type:"closed-book-qa",name:"Closed Book QA"},{type:"text2text-generation",name:"Text2Text Generation"}],modality:"nlp"},"fill-mask":{name:"Fill-Mask",subtasks:[{type:"slot-filling",name:"Slot Filling"},{type:"masked-language-modeling",name:"Masked Language Modeling"}],modality:"nlp"},"sentence-similarity":{name:"Sentence Similarity",modality:"nlp"},"text-to-speech":{name:"Text-to-Speech",modality:"audio"},"text-to-audio":{name:"Text-to-Audio",modality:"audio"},"automatic-speech-recognition":{name:"Automatic Speech Recognition",modality:"audio"},"audio-to-audio":{name:"Audio-to-Audio",modality:"audio"},"audio-classification":{name:"Audio Classification",subtasks:[{type:"keyword-spotting",name:"Keyword Spotting"},{type:"speaker-identification",name:"Speaker Identification"},{type:"audio-intent-classification",name:"Audio Intent Classification"},{type:"audio-emotion-recognition",name:"Audio Emotion Recognition"},{type:"audio-language-identification",name:"Audio Language Identification"}],modality:"audio"},"audio-text-to-text":{name:"Audio-Text-to-Text",modality:"multimodal",hideInDatasets:!0},"voice-activity-detection":{name:"Voice Activity Detection",modality:"audio"},"depth-estimation":{name:"Depth Estimation",modality:"cv"},"image-classification":{name:"Image Classification",subtasks:[{type:"multi-label-image-classification",name:"Multi Label Image Classification"},{type:"multi-class-image-classification",name:"Multi Class Image Classification"}],modality:"cv"},"object-detection":{name:"Object Detection",subtasks:[{type:"face-detection",name:"Face Detection"},{type:"vehicle-detection",name:"Vehicle Detection"}],modality:"cv"},"image-segmentation":{name:"Image Segmentation",subtasks:[{type:"instance-segmentation",name:"Instance Segmentation"},{type:"semantic-segmentation",name:"Semantic Segmentation"},{type:"panoptic-segmentation",name:"Panoptic Segmentation"}],modality:"cv"},"text-to-image":{name:"Text-to-Image",modality:"cv"},"image-to-text":{name:"Image-to-Text",subtasks:[{type:"image-captioning",name:"Image Captioning"}],modality:"cv"},"image-to-image":{name:"Image-to-Image",subtasks:[{type:"image-inpainting",name:"Image Inpainting"},{type:"image-colorization",name:"Image Colorization"},{type:"super-resolution",name:"Super Resolution"}],modality:"cv"},"image-to-video":{name:"Image-to-Video",modality:"cv"},"unconditional-image-generation":{name:"Unconditional Image Generation",modality:"cv"},"video-classification":{name:"Video Classification",modality:"cv"},"reinforcement-learning":{name:"Reinforcement Learning",modality:"rl"},robotics:{name:"Robotics",modality:"rl",subtasks:[{type:"grasping",name:"Grasping"},{type:"task-planning",name:"Task Planning"}]},"tabular-classification":{name:"Tabular Classification",modality:"tabular",subtasks:[{type:"tabular-multi-class-classification",name:"Tabular Multi Class Classification"},{type:"tabular-multi-label-classification",name:"Tabular Multi Label Classification"}]},"tabular-regression":{name:"Tabular Regression",modality:"tabular",subtasks:[{type:"tabular-single-column-regression",name:"Tabular Single Column Regression"}]},"tabular-to-text":{name:"Tabular to Text",modality:"tabular",subtasks:[{type:"rdf-to-text",name:"RDF to text"}],hideInModels:!0},"table-to-text":{name:"Table to Text",modality:"nlp",hideInModels:!0},"multiple-choice":{name:"Multiple Choice",subtasks:[{type:"multiple-choice-qa",name:"Multiple Choice QA"},{type:"multiple-choice-coreference-resolution",name:"Multiple Choice Coreference Resolution"}],modality:"nlp",hideInModels:!0},"text-ranking":{name:"Text Ranking",modality:"nlp"},"text-retrieval":{name:"Text Retrieval",subtasks:[{type:"document-retrieval",name:"Document Retrieval"},{type:"utterance-retrieval",name:"Utterance Retrieval"},{type:"entity-linking-retrieval",name:"Entity Linking Retrieval"},{type:"fact-checking-retrieval",name:"Fact Checking Retrieval"}],modality:"nlp",hideInModels:!0},"time-series-forecasting":{name:"Time Series Forecasting",modality:"tabular",subtasks:[{type:"univariate-time-series-forecasting",name:"Univariate Time Series Forecasting"},{type:"multivariate-time-series-forecasting",name:"Multivariate Time Series Forecasting"}]},"text-to-video":{name:"Text-to-Video",modality:"cv"},"image-text-to-text":{name:"Image-Text-to-Text",modality:"multimodal"},"visual-question-answering":{name:"Visual Question Answering",subtasks:[{type:"visual-question-answering",name:"Visual Question Answering"}],modality:"multimodal"},"document-question-answering":{name:"Document Question Answering",subtasks:[{type:"document-question-answering",name:"Document Question Answering"}],modality:"multimodal",hideInDatasets:!0},"zero-shot-image-classification":{name:"Zero-Shot Image Classification",modality:"cv"},"graph-ml":{name:"Graph Machine Learning",modality:"other"},"mask-generation":{name:"Mask Generation",modality:"cv"},"zero-shot-object-detection":{name:"Zero-Shot Object Detection",modality:"cv"},"text-to-3d":{name:"Text-to-3D",modality:"cv"},"image-to-3d":{name:"Image-to-3D",modality:"cv"},"image-feature-extraction":{name:"Image Feature Extraction",modality:"cv"},"video-text-to-text":{name:"Video-Text-to-Text",modality:"multimodal",hideInDatasets:!1},"keypoint-detection":{name:"Keypoint Detection",subtasks:[{type:"pose-estimation",name:"Pose Estimation"}],modality:"cv",hideInDatasets:!0},"visual-document-retrieval":{name:"Visual Document Retrieval",modality:"multimodal"},"any-to-any":{name:"Any-to-Any",modality:"multimodal"},"video-to-video":{name:"Video-to-Video",modality:"cv",hideInDatasets:!0},other:{name:"Other",modality:"other",hideInModels:!0,hideInDatasets:!0}};Object.keys(n9),Object.values(n9).flatMap(e=>"subtasks"in e?e.subtasks:[]).map(e=>e.type);const n7={datasets:[{description:"A benchmark of 10 different audio tasks.",id:"s3prl/superb"},{description:"A dataset of YouTube clips and their sound categories.",id:"agkphysics/AudioSet"}],demo:{inputs:[{filename:"audio.wav",type:"audio"}],outputs:[{data:[{label:"Up",score:.2},{label:"Down",score:.8}],type:"chart"}]},metrics:[{description:"",id:"accuracy"},{description:"",id:"recall"},{description:"",id:"precision"},{description:"",id:"f1"}],models:[{description:"An easy-to-use model for command recognition.",id:"speechbrain/google_speech_command_xvector"},{description:"An emotion recognition model.",id:"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition"},{description:"A language identification model.",id:"facebook/mms-lid-126"}],spaces:[{description:"An application that can classify music into different genre.",id:"kurianbenoy/audioclassification"}],summary:"Audio classification is the task of assigning a label or class to a given audio. It can be used for recognizing which command a user is giving or the emotion of a statement, as well as identifying a speaker.",widgetModels:["MIT/ast-finetuned-audioset-10-10-0.4593"],youtubeId:"KWwzcmG98Ds"},re={datasets:[{description:"Wikipedia dataset containing cleaned articles of all languages. Can be used to train `feature-extraction` models.",id:"wikipedia"}],demo:{inputs:[{label:"Input",content:"India, officially the Republic of India, is a country in South Asia.",type:"text"}],outputs:[{table:[["Dimension 1","Dimension 2","Dimension 3"],["2.583383083343506","2.757075071334839","0.9023529887199402"],["8.29393482208252","1.1071064472198486","2.03399395942688"],["-0.7754912972450256","-1.647324562072754","-0.6113331913948059"],["0.07087723910808563","1.5942802429199219","1.4610432386398315"]],type:"tabular"}]},metrics:[],models:[{description:"A powerful feature extraction model for natural language processing tasks.",id:"thenlper/gte-large"},{description:"A strong feature extraction model for retrieval.",id:"Alibaba-NLP/gte-Qwen1.5-7B-instruct"}],spaces:[{description:"A leaderboard to rank text feature extraction models based on a benchmark.",id:"mteb/leaderboard"},{description:"A leaderboard to rank best feature extraction models based on human feedback.",id:"mteb/arena"}],summary:"Feature extraction is the task of extracting features learnt in a model.",widgetModels:["facebook/bart-base"]},rt={datasets:[{description:"A common dataset that is used to train models for many languages.",id:"wikipedia"},{description:"A large English dataset with text crawled from the web.",id:"c4"}],demo:{inputs:[{label:"Input",content:"The <mask> barked at me",type:"text"}],outputs:[{type:"chart",data:[{label:"wolf",score:.487},{label:"dog",score:.061},{label:"cat",score:.058},{label:"fox",score:.047},{label:"squirrel",score:.025}]}]},metrics:[{description:"Cross Entropy is a metric that calculates the difference between two probability distributions. Each probability distribution is the distribution of predicted words",id:"cross_entropy"},{description:"Perplexity is the exponential of the cross-entropy loss. It evaluates the probabilities assigned to the next word by the model. Lower perplexity indicates better performance",id:"perplexity"}],models:[{description:"State-of-the-art masked language model.",id:"answerdotai/ModernBERT-large"},{description:"A multilingual model trained on 100 languages.",id:"FacebookAI/xlm-roberta-base"}],spaces:[],summary:"Masked language modeling is the task of masking some of the words in a sentence and predicting which words should replace those masks. These models are useful when we want to get a statistical understanding of the language in which the model is trained in.",widgetModels:["distilroberta-base"],youtubeId:"mqElG5QJWUg"},rn={datasets:[{description:"Benchmark dataset used for image classification with images that belong to 100 classes.",id:"cifar100"},{description:"Dataset consisting of images of garments.",id:"fashion_mnist"}],demo:{inputs:[{filename:"image-classification-input.jpeg",type:"img"}],outputs:[{type:"chart",data:[{label:"Egyptian cat",score:.514},{label:"Tabby cat",score:.193},{label:"Tiger cat",score:.068}]}]},metrics:[{description:"",id:"accuracy"},{description:"",id:"recall"},{description:"",id:"precision"},{description:"",id:"f1"}],models:[{description:"A strong image classification model.",id:"google/vit-base-patch16-224"},{description:"A robust image classification model.",id:"facebook/deit-base-distilled-patch16-224"},{description:"A strong image classification model.",id:"facebook/convnext-large-224"}],spaces:[{description:"A leaderboard to evaluate different image classification models.",id:"timm/leaderboard"}],summary:"Image classification is the task of assigning a label or class to an entire image. Images are expected to have only one class for each image. Image classification models take an image as input and return a prediction about which class the image belongs to.",widgetModels:["google/vit-base-patch16-224"],youtubeId:"tjAIM7BOYhw"},rr={datasets:[{description:"ImageNet-1K is a image classification dataset in which images are used to train image-feature-extraction models.",id:"imagenet-1k"}],demo:{inputs:[{filename:"mask-generation-input.png",type:"img"}],outputs:[{table:[["Dimension 1","Dimension 2","Dimension 3"],["0.21236686408519745","1.0919708013534546","0.8512550592422485"],["0.809657871723175","-0.18544459342956543","-0.7851548194885254"],["1.3103108406066895","-0.2479034662246704","-0.9107287526130676"],["1.8536205291748047","-0.36419737339019775","0.09717650711536407"]],type:"tabular"}]},metrics:[],models:[{description:"A powerful image feature extraction model.",id:"timm/vit_large_patch14_dinov2.lvd142m"},{description:"A strong image feature extraction model.",id:"nvidia/MambaVision-T-1K"},{description:"A robust image feature extraction model.",id:"facebook/dino-vitb16"},{description:"Cutting-edge image feature extraction model.",id:"apple/aimv2-large-patch14-336-distilled"},{description:"Strong image feature extraction model that can be used on images and documents.",id:"OpenGVLab/InternViT-6B-448px-V1-2"}],spaces:[{description:"A leaderboard to evaluate different image-feature-extraction models on classification performances",id:"timm/leaderboard"}],summary:"Image feature extraction is the task of extracting features learnt in a computer vision model.",widgetModels:[]};var ra={datasets:[],demo:{inputs:[],outputs:[]},isPlaceholder:!0,metrics:[],models:[],spaces:[],summary:"",widgetModels:[],youtubeId:void 0,canonicalId:void 0};const ri={datasets:[{description:"Bing queries with relevant passages from various web sources.",id:"microsoft/ms_marco"}],demo:{inputs:[{label:"Source sentence",content:"Machine learning is so easy.",type:"text"},{label:"Sentences to compare to",content:"Deep learning is so straightforward.",type:"text"},{label:"",content:"This is so difficult, like rocket science.",type:"text"},{label:"",content:"I can't believe how much I struggled with this.",type:"text"}],outputs:[{type:"chart",data:[{label:"Deep learning is so straightforward.",score:.623},{label:"This is so difficult, like rocket science.",score:.413},{label:"I can't believe how much I struggled with this.",score:.256}]}]},metrics:[{description:"Reciprocal Rank is a measure used to rank the relevancy of documents given a set of documents. Reciprocal Rank is the reciprocal of the rank of the document retrieved, meaning, if the rank is 3, the Reciprocal Rank is 0.33. If the rank is 1, the Reciprocal Rank is 1",id:"Mean Reciprocal Rank"},{description:"The similarity of the embeddings is evaluated mainly on cosine similarity. It is calculated as the cosine of the angle between two vectors. It is particularly useful when your texts are not the same length",id:"Cosine Similarity"}],models:[{description:"This model works well for sentences and paragraphs and can be used for clustering/grouping and semantic searches.",id:"sentence-transformers/all-mpnet-base-v2"},{description:"A multilingual robust sentence similarity model.",id:"BAAI/bge-m3"},{description:"A robust sentence similarity model.",id:"HIT-TMG/KaLM-embedding-multilingual-mini-instruct-v1.5"}],spaces:[{description:"An application that leverages sentence similarity to answer questions from YouTube videos.",id:"Gradio-Blocks/Ask_Questions_To_YouTube_Videos"},{description:"An application that retrieves relevant PubMed abstracts for a given online article which can be used as further references.",id:"Gradio-Blocks/pubmed-abstract-retriever"},{description:"An application that leverages sentence similarity to summarize text.",id:"nickmuchi/article-text-summarizer"},{description:"A guide that explains how Sentence Transformers can be used for semantic search.",id:"sentence-transformers/Sentence_Transformers_for_semantic_search"}],summary:"Sentence Similarity is the task of determining how similar two texts are. Sentence similarity models convert input texts into vectors (embeddings) that capture semantic information and calculate how close (similar) they are between them. This task is particularly useful for information retrieval and clustering/grouping.",widgetModels:["BAAI/bge-small-en-v1.5"],youtubeId:"VCZq5AkbNEU"},ro={datasets:[{description:"The WikiTableQuestions dataset is a large-scale dataset for the task of question answering on semi-structured tables.",id:"wikitablequestions"},{description:"WikiSQL is a dataset of 80654 hand-annotated examples of questions and SQL queries distributed across 24241 tables from Wikipedia.",id:"wikisql"}],demo:{inputs:[{table:[["Rank","Name","No.of reigns","Combined days"],["1","lou Thesz","3","3749"],["2","Ric Flair","8","3103"],["3","Harley Race","7","1799"]],type:"tabular"},{label:"Question",content:"What is the number of reigns for Harley Race?",type:"text"}],outputs:[{label:"Result",content:"7",type:"text"}]},metrics:[{description:"Checks whether the predicted answer(s) is the same as the ground-truth answer(s).",id:"Denotation Accuracy"}],models:[{description:"A table question answering model that is capable of neural SQL execution, i.e., employ TAPEX to execute a SQL query on a given table.",id:"microsoft/tapex-base"},{description:"A robust table question answering model.",id:"google/tapas-base-finetuned-wtq"}],spaces:[{description:"An application that answers questions based on table CSV files.",id:"katanaml/table-query"}],summary:"Table Question Answering (Table QA) is the answering a question about an information on a given table.",widgetModels:["google/tapas-base-finetuned-wtq"]},rs={datasets:[{description:"A comprehensive curation of datasets covering all benchmarks.",id:"inria-soda/tabular-benchmark"}],demo:{inputs:[{table:[["Glucose","Blood Pressure ","Skin Thickness","Insulin","BMI"],["148","72","35","0","33.6"],["150","50","30","0","35.1"],["141","60","29","1","39.2"]],type:"tabular"}],outputs:[{table:[["Diabetes"],["1"],["1"],["0"]],type:"tabular"}]},metrics:[{description:"",id:"accuracy"},{description:"",id:"recall"},{description:"",id:"precision"},{description:"",id:"f1"}],models:[{description:"Breast cancer prediction model based on decision trees.",id:"scikit-learn/cancer-prediction-trees"}],spaces:[{description:"An application that can predict defective products on a production line.",id:"scikit-learn/tabular-playground"},{description:"An application that compares various tabular classification techniques on different datasets.",id:"scikit-learn/classification"}],summary:"Tabular classification is the task of classifying a target category (a group) based on set of attributes.",widgetModels:["scikit-learn/tabular-playground"],youtubeId:""},rl={datasets:[{description:"A comprehensive curation of datasets covering all benchmarks.",id:"inria-soda/tabular-benchmark"}],demo:{inputs:[{table:[["Car Name","Horsepower","Weight"],["ford torino","140","3,449"],["amc hornet","97","2,774"],["toyota corolla","65","1,773"]],type:"tabular"}],outputs:[{table:[["MPG (miles per gallon)"],["17"],["18"],["31"]],type:"tabular"}]},metrics:[{description:"",id:"mse"},{description:"Coefficient of determination (or R-squared) is a measure of how well the model fits the data. Higher R-squared is considered a better fit.",id:"r-squared"}],models:[{description:"Fish weight prediction based on length measurements and species.",id:"scikit-learn/Fish-Weight"}],spaces:[{description:"An application that can predict weight of a fish based on set of attributes.",id:"scikit-learn/fish-weight-prediction"}],summary:"Tabular regression is the task of predicting a numerical value given a set of attributes.",widgetModels:["scikit-learn/Fish-Weight"],youtubeId:""},ru={datasets:[{description:"A widely used dataset useful to benchmark named entity recognition models.",id:"eriktks/conll2003"},{description:"A multilingual dataset of Wikipedia articles annotated for named entity recognition in over 150 different languages.",id:"unimelb-nlp/wikiann"}],demo:{inputs:[{label:"Input",content:"My name is Omar and I live in Zrich.",type:"text"}],outputs:[{text:"My name is Omar and I live in Zrich.",tokens:[{type:"PERSON",start:11,end:15},{type:"GPE",start:30,end:36}],type:"text-with-tokens"}]},metrics:[{description:"",id:"accuracy"},{description:"",id:"recall"},{description:"",id:"precision"},{description:"",id:"f1"}],models:[{description:"A robust performance model to identify people, locations, organizations and names of miscellaneous entities.",id:"dslim/bert-base-NER"},{description:"A strong model to identify people, locations, organizations and names in multiple languages.",id:"FacebookAI/xlm-roberta-large-finetuned-conll03-english"},{description:"A token classification model specialized on medical entity recognition.",id:"blaze999/Medical-NER"},{description:"Flair models are typically the state of the art in named entity recognition tasks.",id:"flair/ner-english"}],spaces:[{description:"An application that can recognizes entities, extracts noun chunks and recognizes various linguistic features of each token.",id:"spacy/gradio_pipeline_visualizer"}],summary:"Token classification is a natural language understanding task in which a label is assigned to some tokens in a text. Some popular token classification subtasks are Named Entity Recognition (NER) and Part-of-Speech (PoS) tagging. NER models could be trained to identify specific entities in a text, such as dates, individuals and places; and PoS tagging would identify, for example, which words in a text are verbs, nouns, and punctuation marks.",widgetModels:["FacebookAI/xlm-roberta-large-finetuned-conll03-english"],youtubeId:"wVHdVlPScxA"},rc={datasets:[{description:"A widely used dataset used to benchmark multiple variants of text classification.",id:"nyu-mll/glue"},{description:"A text classification dataset used to benchmark natural language inference models",id:"stanfordnlp/snli"}],demo:{inputs:[{label:"Input",content:"I love Hugging Face!",type:"text"}],outputs:[{type:"chart",data:[{label:"POSITIVE",score:.9},{label:"NEUTRAL",score:.1},{label:"NEGATIVE",score:0}]}]},metrics:[{description:"",id:"accuracy"},{description:"",id:"recall"},{description:"",id:"precision"},{description:"The F1 metric is the harmonic mean of the precision and recall. It can be calculated as: F1 = 2 * (precision * recall) / (precision + recall)",id:"f1"}],models:[{description:"A robust model trained for sentiment analysis.",id:"distilbert/distilbert-base-uncased-finetuned-sst-2-english"},{description:"A sentiment analysis model specialized in financial sentiment.",id:"ProsusAI/finbert"},{description:"A sentiment analysis model specialized in analyzing tweets.",id:"cardiffnlp/twitter-roberta-base-sentiment-latest"},{description:"A model that can classify languages.",id:"papluca/xlm-roberta-base-language-detection"},{description:"A model that can classify text generation attacks.",id:"meta-llama/Prompt-Guard-86M"}],spaces:[{description:"An application that can classify financial sentiment.",id:"IoannisTr/Tech_Stocks_Trading_Assistant"},{description:"A dashboard that contains various text classification tasks.",id:"miesnerjacob/Multi-task-NLP"},{description:"An application that analyzes user reviews in healthcare.",id:"spacy/healthsea-demo"}],summary:"Text Classification is the task of assigning a label or class to a given text. Some use cases are sentiment analysis, natural language inference, and assessing grammatical correctness.",widgetModels:["distilbert/distilbert-base-uncased-finetuned-sst-2-english"],youtubeId:"leNG9fN9FQU"},rd={datasets:[{description:"Bing queries with relevant passages from various web sources.",id:"microsoft/ms_marco"}],demo:{inputs:[{label:"Source sentence",content:"Machine learning is so easy.",type:"text"},{label:"Sentences to compare to",content:"Deep learning is so straightforward.",type:"text"},{label:"",content:"This is so difficult, like rocket science.",type:"text"},{label:"",content:"I can't believe how much I struggled with this.",type:"text"}],outputs:[{type:"chart",data:[{label:"Deep learning is so straightforward.",score:2.2006407},{label:"This is so difficult, like rocket science.",score:-6.2634873},{label:"I can't believe how much I struggled with this.",score:-10.251488}]}]},metrics:[{description:"Discounted Cumulative Gain (DCG) measures the gain, or usefulness, of search results discounted by their position. The normalization is done by dividing the DCG by the ideal DCG, which is the DCG of the perfect ranking.",id:"Normalized Discounted Cumulative Gain"},{description:"Reciprocal Rank is a measure used to rank the relevancy of documents given a set of documents. Reciprocal Rank is the reciprocal of the rank of the document retrieved, meaning, if the rank is 3, the Reciprocal Rank is 0.33. If the rank is 1, the Reciprocal Rank is 1",id:"Mean Reciprocal Rank"},{description:"Mean Average Precision (mAP) is the overall average of the Average Precision (AP) values, where AP is the Area Under the PR Curve (AUC-PR)",id:"Mean Average Precision"}],models:[{description:"An extremely efficient text ranking model trained on a web search dataset.",id:"cross-encoder/ms-marco-MiniLM-L6-v2"},{description:"A strong multilingual text reranker model.",id:"Alibaba-NLP/gte-multilingual-reranker-base"},{description:"An efficient text ranking model that punches above its weight.",id:"Alibaba-NLP/gte-reranker-modernbert-base"}],spaces:[],summary:"Text Ranking is the task of ranking a set of texts based on their relevance to a query. Text ranking models are trained on large datasets of queries and relevant documents to learn how to rank documents based on their relevance to the query. This task is particularly useful for search engines and information retrieval systems.",widgetModels:["cross-encoder/ms-marco-MiniLM-L6-v2"],youtubeId:""},rp={datasets:[{description:"Benchmark dataset used for video classification with videos that belong to 400 classes.",id:"kinetics400"}],demo:{inputs:[{filename:"video-classification-input.gif",type:"img"}],outputs:[{type:"chart",data:[{label:"Playing Guitar",score:.514},{label:"Playing Tennis",score:.193},{label:"Cooking",score:.068}]}]},metrics:[{description:"",id:"accuracy"},{description:"",id:"recall"},{description:"",id:"precision"},{description:"",id:"f1"}],models:[{description:"Strong Video Classification model trained on the Kinetics 400 dataset.",id:"google/vivit-b-16x2-kinetics400"},{description:"Strong Video Classification model trained on the Kinetics 400 dataset.",id:"microsoft/xclip-base-patch32"}],spaces:[{description:"An application that classifies video at different timestamps.",id:"nateraw/lavila"},{description:"An application that classifies video.",id:"fcakyon/video-classification"}],summary:"Video classification is the task of assigning a label or class to an entire video. Videos are expected to have only one class for each video. Video classification models take a video as input and return a prediction about which class the video belongs to.",widgetModels:[],youtubeId:""},rf={datasets:[{description:"A large dataset used to train visual document retrieval models.",id:"vidore/colpali_train_set"}],demo:{inputs:[{filename:"input.png",type:"img"},{label:"Question",content:"Is the model in this paper the fastest for inference?",type:"text"}],outputs:[{type:"chart",data:[{label:"Page 10",score:.7},{label:"Page 11",score:.06},{label:"Page 9",score:.003}]}]},isPlaceholder:!1,metrics:[{description:"NDCG@k scores ranked recommendation lists for top-k results. 0 is the worst, 1 is the best.",id:"Normalized Discounted Cumulative Gain at K"}],models:[{description:"Very accurate visual document retrieval model for multilingual queries and documents.",id:"vidore/colqwen2-v1.0"},{description:"Very fast and efficient visual document retrieval model that works on five languages.",id:"marco/mcdse-2b-v1"}],spaces:[{description:"A leaderboard of visual document retrieval models.",id:"vidore/vidore-leaderboard"}],summary:"Visual document retrieval is the task of searching for relevant image-based documents, such as PDFs. These models take a text query and multiple documents as input and return the top-most relevant documents and relevancy scores as output.",widgetModels:[""],youtubeId:""},rm={datasets:[{description:"A widely used dataset containing questions (with answers) about images.",id:"Graphcore/vqa"},{description:"A dataset to benchmark visual reasoning based on text in images.",id:"facebook/textvqa"}],demo:{inputs:[{filename:"elephant.jpeg",type:"img"},{label:"Question",content:"What is in this image?",type:"text"}],outputs:[{type:"chart",data:[{label:"elephant",score:.97},{label:"elephants",score:.06},{label:"animal",score:.003}]}]},isPlaceholder:!1,metrics:[{description:"",id:"accuracy"},{description:"Measures how much a predicted answer differs from the ground truth based on the difference in their semantic meaning.",id:"wu-palmer similarity"}],models:[{description:"A visual question answering model trained to convert charts and plots to text.",id:"google/deplot"},{description:"A visual question answering model trained for mathematical reasoning and chart derendering from images.",id:"google/matcha-base"},{description:"A strong visual question answering that answers questions from book covers.",id:"google/pix2struct-ocrvqa-large"}],spaces:[{description:"An application that compares visual question answering models across different tasks.",id:"merve/pix2struct"},{description:"An application that can answer questions based on images.",id:"nielsr/vilt-vqa"},{description:"An application that can caption images and answer questions about a given image. ",id:"Salesforce/BLIP"},{description:"An application that can caption images and answer questions about a given image. ",id:"vumichien/Img2Prompt"}],summary:"Visual Question Answering is the task of answering open-ended questions based on an image. They output natural language responses to natural language questions.",widgetModels:["dandelin/vilt-b32-finetuned-vqa"],youtubeId:""},rh={datasets:[{description:"A widely used dataset used to benchmark multiple variants of text classification.",id:"nyu-mll/glue"},{description:"The Multi-Genre Natural Language Inference (MultiNLI) corpus is a crowd-sourced collection of 433k sentence pairs annotated with textual entailment information.",id:"nyu-mll/multi_nli"},{description:"FEVER is a publicly available dataset for fact extraction and verification against textual sources.",id:"fever/fever"}],demo:{inputs:[{label:"Text Input",content:"Dune is the best movie ever.",type:"text"},{label:"Candidate Labels",content:"CINEMA, ART, MUSIC",type:"text"}],outputs:[{type:"chart",data:[{label:"CINEMA",score:.9},{label:"ART",score:.1},{label:"MUSIC",score:0}]}]},metrics:[],models:[{description:"Powerful zero-shot text classification model.",id:"facebook/bart-large-mnli"},{description:"Cutting-edge zero-shot multilingual text classification model.",id:"MoritzLaurer/ModernBERT-large-zeroshot-v2.0"},{description:"Zero-shot text classification model that can be used for topic and sentiment classification.",id:"knowledgator/gliclass-modern-base-v2.0-init"}],spaces:[],summary:"Zero-shot text classification is a task in natural language processing where a model is trained on a set of labeled examples but is then able to classify new examples from previously unseen classes.",widgetModels:["facebook/bart-large-mnli"]},rg={datasets:[{description:"",id:""}],demo:{inputs:[{filename:"image-classification-input.jpeg",type:"img"},{label:"Classes",content:"cat, dog, bird",type:"text"}],outputs:[{type:"chart",data:[{label:"Cat",score:.664},{label:"Dog",score:.329},{label:"Bird",score:.008}]}]},metrics:[{description:"Computes the number of times the correct label appears in top K labels predicted",id:"top-K accuracy"}],models:[{description:"Multilingual image classification model for 80 languages.",id:"visheratin/mexma-siglip"},{description:"Strong zero-shot image classification model.",id:"google/siglip2-base-patch16-224"},{description:"Robust zero-shot image classification model.",id:"intfloat/mmE5-mllama-11b-instruct"},{description:"Powerful zero-shot image classification model supporting 94 languages.",id:"jinaai/jina-clip-v2"},{description:"Strong image classification model for biomedical domain.",id:"microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224"}],spaces:[{description:"An application that leverages zero-shot image classification to find best captions to generate an image. ",id:"pharma/CLIP-Interrogator"},{description:"An application to compare different zero-shot image classification models. ",id:"merve/compare_clip_siglip"}],summary:"Zero-shot image classification is the task of classifying previously unseen classes during training of a model.",widgetModels:["google/siglip-so400m-patch14-224"],youtubeId:""},ry={"audio-classification":["speechbrain","transformers","transformers.js"],"audio-to-audio":["asteroid","fairseq","speechbrain"],"automatic-speech-recognition":["espnet","nemo","speechbrain","transformers","transformers.js"],"audio-text-to-text":[],"depth-estimation":["transformers","transformers.js"],"document-question-answering":["transformers","transformers.js"],"feature-extraction":["sentence-transformers","transformers","transformers.js"],"fill-mask":["transformers","transformers.js"],"graph-ml":["transformers"],"image-classification":["keras","timm","transformers","transformers.js"],"image-feature-extraction":["timm","transformers"],"image-segmentation":["transformers","transformers.js"],"image-text-to-text":["transformers"],"image-to-image":["diffusers","transformers","transformers.js"],"image-to-text":["transformers","transformers.js"],"image-to-video":["diffusers"],"keypoint-detection":["transformers"],"video-classification":["transformers"],"mask-generation":["transformers"],"multiple-choice":["transformers"],"object-detection":["transformers","transformers.js","ultralytics"],other:[],"question-answering":["adapter-transformers","allennlp","transformers","transformers.js"],robotics:[],"reinforcement-learning":["transformers","stable-baselines3","ml-agents","sample-factory"],"sentence-similarity":["sentence-transformers","spacy","transformers.js"],summarization:["transformers","transformers.js"],"table-question-answering":["transformers"],"table-to-text":["transformers"],"tabular-classification":["sklearn"],"tabular-regression":["sklearn"],"tabular-to-text":["transformers"],"text-classification":["adapter-transformers","setfit","spacy","transformers","transformers.js"],"text-generation":["transformers","transformers.js"],"text-ranking":["sentence-transformers","transformers"],"text-retrieval":[],"text-to-image":["diffusers"],"text-to-speech":["espnet","tensorflowtts","transformers","transformers.js"],"text-to-audio":["transformers","transformers.js"],"text-to-video":["diffusers"],"time-series-forecasting":[],"token-classification":["adapter-transformers","flair","spacy","span-marker","stanza","transformers","transformers.js"],translation:["transformers","transformers.js"],"unconditional-image-generation":["diffusers"],"video-text-to-text":["transformers"],"visual-question-answering":["transformers","transformers.js"],"voice-activity-detection":[],"zero-shot-classification":["transformers","transformers.js"],"zero-shot-image-classification":["transformers","transformers.js"],"zero-shot-object-detection":["transformers","transformers.js"],"text-to-3d":["diffusers"],"image-to-3d":["diffusers"],"any-to-any":["transformers"],"visual-document-retrieval":["transformers"],"video-to-video":["diffusers"]};function rb(e,t=ra){return{...t,id:e,label:n9[e].name,libraries:ry[e]}}rb("any-to-any",{datasets:[{description:"A dataset with multiple modality input and output pairs.",id:"PKU-Alignment/align-anything"}],demo:{inputs:[{filename:"any-to-any-input.jpg",type:"img"},{label:"Text Prompt",content:"What is the significance of this place?",type:"text"}],outputs:[{label:"Generated Text",content:"The place in the picture is Osaka Castle, located in Osaka, Japan. Osaka Castle is a historic castle that was originally built in the 16th century by Toyotomi Hideyoshi, a powerful warlord of the time. It is one of the most famous landmarks in Osaka and is known for its distinctive white walls and black roof tiles. The castle has been rebuilt several times over the centuries and is now a popular tourist attraction, offering visitors a glimpse into Japan's rich history and culture.",type:"text"},{filename:"any-to-any-output.wav",type:"audio"}]},metrics:[],models:[{description:"Strong model that can take in video, audio, image, text and output text and natural speech.",id:"Qwen/Qwen2.5-Omni-7B"},{description:"Robust model that can take in image and text and generate image and text.",id:"deepseek-ai/Janus-Pro-7B"},{description:"Any-to-any model with speech, video, audio, image and text understanding capabilities.",id:"openbmb/MiniCPM-o-2_6"},{description:"A model that can understand image and text and generate image and text.",id:"EPFL-VILAB/4M-21_XL"}],spaces:[{description:"An application to chat with an any-to-any (image & text) model.",id:"deepseek-ai/Janus-Pro-7B"}],summary:"Any-to-any models can understand two or more modalities and output two or more modalities.",widgetModels:[],youtubeId:""}),rb("audio-classification",n7),rb("audio-to-audio",{datasets:[{description:"512-element X-vector embeddings of speakers from CMU ARCTIC dataset.",id:"Matthijs/cmu-arctic-xvectors"}],demo:{inputs:[{filename:"input.wav",type:"audio"}],outputs:[{filename:"label-0.wav",type:"audio"},{filename:"label-1.wav",type:"audio"}]},metrics:[{description:"The Signal-to-Noise ratio is the relationship between the target signal level and the background noise level. It is calculated as the logarithm of the target signal divided by the background noise, in decibels.",id:"snri"},{description:"The Signal-to-Distortion ratio is the relationship between the target signal and the sum of noise, interference, and artifact errors",id:"sdri"}],models:[{description:"A speech enhancement model.",id:"ResembleAI/resemble-enhance"},{description:"A model that can change the voice in a speech recording.",id:"microsoft/speecht5_vc"}],spaces:[{description:"An application for speech separation.",id:"younver/speechbrain-speech-separation"},{description:"An application for audio style transfer.",id:"nakas/audio-diffusion_style_transfer"}],summary:"Audio-to-Audio is a family of tasks in which the input is an audio and the output is one or multiple generated audios. Some example tasks are speech enhancement and source separation.",widgetModels:["speechbrain/sepformer-wham"],youtubeId:"iohj7nCCYoM"}),rb("audio-text-to-text",ra),rb("automatic-speech-recognition",{datasets:[{description:"31,175 hours of multilingual audio-text dataset in 108 languages.",id:"mozilla-foundation/common_voice_17_0"},{description:"Multilingual and diverse audio dataset with 101k hours of audio.",id:"amphion/Emilia-Dataset"},{description:"A dataset with 44.6k hours of English speaker data and 6k hours of other language speakers.",id:"parler-tts/mls_eng"},{description:"A multilingual audio dataset with 370K hours of audio.",id:"espnet/yodas"}],demo:{inputs:[{filename:"input.flac",type:"audio"}],outputs:[{label:"Transcript",content:"Going along slushy country roads and speaking to damp audiences in...",type:"text"}]},metrics:[{description:"",id:"wer"},{description:"",id:"cer"}],models:[{description:"A powerful ASR model by OpenAI.",id:"openai/whisper-large-v3"},{description:"A good generic speech model by MetaAI for fine-tuning.",id:"facebook/w2v-bert-2.0"},{description:"An end-to-end model that performs ASR and Speech Translation by MetaAI.",id:"facebook/seamless-m4t-v2-large"},{description:"A powerful multilingual ASR and Speech Translation model by Nvidia.",id:"nvidia/canary-1b"},{description:"Powerful speaker diarization model.",id:"pyannote/speaker-diarization-3.1"}],spaces:[{description:"A powerful general-purpose speech recognition application.",id:"hf-audio/whisper-large-v3"},{description:"Latest ASR model from Useful Sensors.",id:"mrfakename/Moonshinex"},{description:"A high quality speech and text translation model by Meta.",id:"facebook/seamless_m4t"},{description:"A powerful multilingual ASR and Speech Translation model by Nvidia",id:"nvidia/canary-1b"}],summary:"Automatic Speech Recognition (ASR), also known as Speech to Text (STT), is the task of transcribing a given audio to text. It has many applications, such as voice user interfaces.",widgetModels:["openai/whisper-large-v3"],youtubeId:"TksaY_FDgnk"}),rb("depth-estimation",{datasets:[{description:"NYU Depth V2 Dataset: Video dataset containing both RGB and depth sensor data.",id:"sayakpaul/nyu_depth_v2"},{description:"Monocular depth estimation benchmark based without noise and errors.",id:"depth-anything/DA-2K"}],demo:{inputs:[{filename:"depth-estimation-input.jpg",type:"img"}],outputs:[{filename:"depth-estimation-output.png",type:"img"}]},metrics:[],models:[{description:"Cutting-edge depth estimation model.",id:"depth-anything/Depth-Anything-V2-Large"},{description:"A strong monocular depth estimation model.",id:"jingheya/lotus-depth-g-v1-0"},{description:"A depth estimation model that predicts depth in videos.",id:"tencent/DepthCrafter"},{description:"A robust depth estimation model.",id:"apple/DepthPro-hf"}],spaces:[{description:"An application that predicts the depth of an image and then reconstruct the 3D model as voxels.",id:"radames/dpt-depth-estimation-3d-voxels"},{description:"An application for bleeding-edge depth estimation.",id:"akhaliq/depth-pro"},{description:"An application on cutting-edge depth estimation in videos.",id:"tencent/DepthCrafter"},{description:"A human-centric depth estimation application.",id:"facebook/sapiens-depth"}],summary:"Depth estimation is the task of predicting depth of the objects present in an image.",widgetModels:[""],youtubeId:""}),rb("document-question-answering",{datasets:[{description:"Largest document understanding dataset.",id:"HuggingFaceM4/Docmatix"},{description:"Dataset from the 2020 DocVQA challenge. The documents are taken from the UCSF Industry Documents Library.",id:"eliolio/docvqa"}],demo:{inputs:[{label:"Question",content:"What is the idea behind the consumer relations efficiency team?",type:"text"},{filename:"document-question-answering-input.png",type:"img"}],outputs:[{label:"Answer",content:"Balance cost efficiency with quality customer service",type:"text"}]},metrics:[{description:"The evaluation metric for the DocVQA challenge is the Average Normalized Levenshtein Similarity (ANLS). This metric is flexible to character regognition errors and compares the predicted answer with the ground truth answer.",id:"anls"},{description:"Exact Match is a metric based on the strict character match of the predicted answer and the right answer. For answers predicted correctly, the Exact Match will be 1. Even if only one character is different, Exact Match will be 0",id:"exact-match"}],models:[{description:"A robust document question answering model.",id:"impira/layoutlm-document-qa"},{description:"A document question answering model specialized in invoices.",id:"impira/layoutlm-invoices"},{description:"A special model for OCR-free document question answering.",id:"microsoft/udop-large"},{description:"A powerful model for document question answering.",id:"google/pix2struct-docvqa-large"}],spaces:[{description:"A robust document question answering application.",id:"impira/docquery"},{description:"An application that can answer questions from invoices.",id:"impira/invoices"},{description:"An application to compare different document question answering models.",id:"merve/compare_docvqa_models"}],summary:"Document Question Answering (also known as Document Visual Question Answering) is the task of answering questions on document images. Document question answering models take a (document, question) pair as input and return an answer in natural language. Models usually rely on multi-modal features, combining text, position of words (bounding-boxes) and image.",widgetModels:["impira/layoutlm-invoices"],youtubeId:""}),rb("visual-document-retrieval",rf),rb("feature-extraction",re),rb("fill-mask",rt),rb("image-classification",rn),rb("image-feature-extraction",rr),rb("image-segmentation",{datasets:[{description:"Scene segmentation dataset.",id:"scene_parse_150"}],demo:{inputs:[{filename:"image-segmentation-input.jpeg",type:"img"}],outputs:[{filename:"image-segmentation-output.png",type:"img"}]},metrics:[{description:"Average Precision (AP) is the Area Under the PR Curve (AUC-PR). It is calculated for each semantic class separately",id:"Average Precision"},{description:"Mean Average Precision (mAP) is the overall average of the AP values",id:"Mean Average Precision"},{description:"Intersection over Union (IoU) is the overlap of segmentation masks. Mean IoU is the average of the IoU of all semantic classes",id:"Mean Intersection over Union"},{description:"AP is the Average Precision at the IoU threshold of a  value, for example, AP50 and AP75",id:"AP"}],models:[{description:"Solid semantic segmentation model trained on ADE20k.",id:"openmmlab/upernet-convnext-small"},{description:"Background removal model.",id:"briaai/RMBG-1.4"},{description:"A multipurpose image segmentation model for high resolution images.",id:"ZhengPeng7/BiRefNet"},{description:"Powerful human-centric image segmentation model.",id:"facebook/sapiens-seg-1b"},{description:"Panoptic segmentation model trained on the COCO (common objects) dataset.",id:"facebook/mask2former-swin-large-coco-panoptic"}],spaces:[{description:"A semantic segmentation application that can predict unseen instances out of the box.",id:"facebook/ov-seg"},{description:"One of the strongest segmentation applications.",id:"jbrinkma/segment-anything"},{description:"A human-centric segmentation model.",id:"facebook/sapiens-pose"},{description:"An instance segmentation application to predict neuronal cell types from microscopy images.",id:"rashmi/sartorius-cell-instance-segmentation"},{description:"An application that segments videos.",id:"ArtGAN/Segment-Anything-Video"},{description:"An panoptic segmentation application built for outdoor environments.",id:"segments/panoptic-segment-anything"}],summary:"Image Segmentation divides an image into segments where each pixel in the image is mapped to an object. This task has multiple variants such as instance segmentation, panoptic segmentation and semantic segmentation.",widgetModels:["nvidia/segformer-b0-finetuned-ade-512-512"],youtubeId:"dKE8SIt9C-w"}),rb("image-to-image",{datasets:[{description:"Synthetic dataset, for image relighting",id:"VIDIT"},{description:"Multiple images of celebrities, used for facial expression translation",id:"huggan/CelebA-faces"},{description:"12M image-caption pairs.",id:"Spawning/PD12M"}],demo:{inputs:[{filename:"image-to-image-input.jpeg",type:"img"}],outputs:[{filename:"image-to-image-output.png",type:"img"}]},isPlaceholder:!1,metrics:[{description:"Peak Signal to Noise Ratio (PSNR) is an approximation of the human perception, considering the ratio of the absolute intensity with respect to the variations. Measured in dB, a high value indicates a high fidelity.",id:"PSNR"},{description:"Structural Similarity Index (SSIM) is a perceptual metric which compares the luminance, contrast and structure of two images. The values of SSIM range between -1 and 1, and higher values indicate closer resemblance to the original image.",id:"SSIM"},{description:"Inception Score (IS) is an analysis of the labels predicted by an image classification model when presented with a sample of the generated images.",id:"IS"}],models:[{description:"An image-to-image model to improve image resolution.",id:"fal/AuraSR-v2"},{description:"A model that increases the resolution of an image.",id:"keras-io/super-resolution"},{description:"A model for applying edits to images through image controls.",id:"Yuanshi/OminiControl"},{description:"A model that generates images based on segments in the input image and the text prompt.",id:"mfidabel/controlnet-segment-anything"},{description:"Strong model for inpainting and outpainting.",id:"black-forest-labs/FLUX.1-Fill-dev"},{description:"Strong model for image editing using depth maps.",id:"black-forest-labs/FLUX.1-Depth-dev-lora"}],spaces:[{description:"Image enhancer application for low light.",id:"keras-io/low-light-image-enhancement"},{description:"Style transfer application.",id:"keras-io/neural-style-transfer"},{description:"An application that generates images based on segment control.",id:"mfidabel/controlnet-segment-anything"},{description:"Image generation application that takes image control and text prompt.",id:"hysts/ControlNet"},{description:"Colorize any image using this app.",id:"ioclab/brightness-controlnet"},{description:"Edit images with instructions.",id:"timbrooks/instruct-pix2pix"}],summary:"Image-to-image is the task of transforming an input image through a variety of possible manipulations and enhancements, such as super-resolution, image inpainting, colorization, and more.",widgetModels:["stabilityai/stable-diffusion-2-inpainting"],youtubeId:""}),rb("image-text-to-text",{datasets:[{description:"Instructions composed of image and text.",id:"liuhaotian/LLaVA-Instruct-150K"},{description:"Collection of image-text pairs on scientific topics.",id:"DAMO-NLP-SG/multimodal_textbook"},{description:"A collection of datasets made for model fine-tuning.",id:"HuggingFaceM4/the_cauldron"},{description:"Screenshots of websites with their HTML/CSS codes.",id:"HuggingFaceM4/WebSight"}],demo:{inputs:[{filename:"image-text-to-text-input.png",type:"img"},{label:"Text Prompt",content:"Describe the position of the bee in detail.",type:"text"}],outputs:[{label:"Answer",content:"The bee is sitting on a pink flower, surrounded by other flowers. The bee is positioned in the center of the flower, with its head and front legs sticking out.",type:"text"}]},metrics:[],models:[{description:"Small and efficient yet powerful vision language model.",id:"HuggingFaceTB/SmolVLM-Instruct"},{description:"A screenshot understanding model used to control computers.",id:"microsoft/OmniParser-v2.0"},{description:"Cutting-edge vision language model.",id:"allenai/Molmo-7B-D-0924"},{description:"Small yet powerful model.",id:"vikhyatk/moondream2"},{description:"Strong image-text-to-text model.",id:"Qwen/Qwen2.5-VL-7B-Instruct"},{description:"Image-text-to-text model with agentic capabilities.",id:"microsoft/Magma-8B"},{description:"Strong image-text-to-text model focused on documents.",id:"allenai/olmOCR-7B-0225-preview"},{description:"Small yet strong image-text-to-text model.",id:"ibm-granite/granite-vision-3.2-2b"}],spaces:[{description:"Leaderboard to evaluate vision language models.",id:"opencompass/open_vlm_leaderboard"},{description:"Vision language models arena, where models are ranked by votes of users.",id:"WildVision/vision-arena"},{description:"Powerful vision-language model assistant.",id:"akhaliq/Molmo-7B-D-0924"},{description:"Powerful vision language assistant that can understand multiple images.",id:"HuggingFaceTB/SmolVLM2"},{description:"An application for chatting with an image-text-to-text model.",id:"GanymedeNil/Qwen2-VL-7B"},{description:"An application that parses screenshots into actions.",id:"showlab/ShowUI"},{description:"An application that detects gaze.",id:"moondream/gaze-demo"}],summary:"Image-text-to-text models take in an image and text prompt and output text. These models are also called vision-language models, or VLMs. The difference from image-to-text models is that these models take an additional text input, not restricting the model to certain use cases like image captioning, and may also be trained to accept a conversation as input.",widgetModels:["Qwen/Qwen2-VL-7B-Instruct"],youtubeId:"IoGaGfU1CIg"}),rb("image-to-text",{datasets:[{description:"Dataset from 12M image-text of Reddit",id:"red_caps"},{description:"Dataset from 3.3M images of Google",id:"datasets/conceptual_captions"}],demo:{inputs:[{filename:"savanna.jpg",type:"img"}],outputs:[{label:"Detailed description",content:"a herd of giraffes and zebras grazing in a field",type:"text"}]},metrics:[],models:[{description:"A robust image captioning model.",id:"Salesforce/blip2-opt-2.7b"},{description:"A powerful and accurate image-to-text model that can also localize concepts in images.",id:"microsoft/kosmos-2-patch14-224"},{description:"A strong optical character recognition model.",id:"facebook/nougat-base"},{description:"A powerful model that lets you have a conversation with the image.",id:"llava-hf/llava-1.5-7b-hf"}],spaces:[{description:"An application that compares various image captioning models.",id:"nielsr/comparing-captioning-models"},{description:"A robust image captioning application.",id:"flax-community/image-captioning"},{description:"An application that transcribes handwritings into text.",id:"nielsr/TrOCR-handwritten"},{description:"An application that can caption images and answer questions about a given image.",id:"Salesforce/BLIP"},{description:"An application that can caption images and answer questions with a conversational agent.",id:"Salesforce/BLIP2"},{description:"An image captioning application that demonstrates the effect of noise on captions.",id:"johko/capdec-image-captioning"}],summary:"Image to text models output a text from a given image. Image captioning or optical character recognition can be considered as the most common applications of image to text.",widgetModels:["Salesforce/blip-image-captioning-large"],youtubeId:""}),rb("image-to-video",{datasets:[{description:"A benchmark dataset for reference image controlled video generation.",id:"ali-vilab/VACE-Benchmark"},{description:"A dataset of video generation style preferences.",id:"Rapidata/sora-video-generation-style-likert-scoring"},{description:"A dataset with videos and captions throughout the videos.",id:"BestWishYsh/ChronoMagic"}],demo:{inputs:[{filename:"image-to-video-input.jpg",type:"img"},{label:"Optional Text Prompt",content:"This penguin is dancing",type:"text"}],outputs:[{filename:"image-to-video-output.gif",type:"img"}]},metrics:[{description:"Frchet Video Distance (FVD) measures the perceptual similarity between the distributions of generated videos and a set of real videos, assessing overall visual quality and temporal coherence of the video generated from an input image.",id:"fvd"},{description:"CLIP Score measures the semantic similarity between a textual prompt (if provided alongside the input image) and the generated video frames. It evaluates how well the video's generated content and motion align with the textual description, conditioned on the initial image.",id:"clip_score"},{description:"First Frame Fidelity, often measured using LPIPS (Learned Perceptual Image Patch Similarity), PSNR, or SSIM, quantifies how closely the first frame of the generated video matches the input conditioning image.",id:"lpips"},{description:"Identity Preservation Score measures the consistency of identity (e.g., a person's face or a specific object's characteristics) between the input image and throughout the generated video frames, often calculated using features from specialized models like face recognition (e.g., ArcFace) or re-identification models.",id:"identity_preservation"},{description:"Motion Score evaluates the quality, realism, and temporal consistency of motion in the video generated from a static image. This can be based on optical flow analysis (e.g., smoothness, magnitude), consistency of object trajectories, or specific motion plausibility assessments.",id:"motion_score"}],models:[{description:"LTX-Video, a 13B parameter model for high quality video generation",id:"Lightricks/LTX-Video-0.9.7-dev"},{description:"A 14B parameter model for reference image controlled video generation",id:"Wan-AI/Wan2.1-VACE-14B"},{description:"An image-to-video generation model using FramePack F1 methodology with Hunyuan-DiT architecture",id:"lllyasviel/FramePack_F1_I2V_HY_20250503"},{description:"A distilled version of the LTX-Video-0.9.7-dev model for faster inference",id:"Lightricks/LTX-Video-0.9.7-distilled"},{description:"An image-to-video generation model by Skywork AI, 14B parameters, producing 720p videos.",id:"Skywork/SkyReels-V2-I2V-14B-720P"},{description:"Image-to-video variant of Tencent's HunyuanVideo.",id:"tencent/HunyuanVideo-I2V"},{description:"A 14B parameter model for 720p image-to-video generation by Wan-AI.",id:"Wan-AI/Wan2.1-I2V-14B-720P"},{description:"A Diffusers version of the Wan2.1-I2V-14B-720P model for 720p image-to-video generation.",id:"Wan-AI/Wan2.1-I2V-14B-720P-Diffusers"}],spaces:[{description:"An application to generate videos fast.",id:"Lightricks/ltx-video-distilled"},{description:"Generate videos with the FramePack-F1",id:"linoyts/FramePack-F1"},{description:"Generate videos with the FramePack",id:"lisonallen/framepack-i2v"},{description:"Wan2.1 with CausVid LoRA",id:"multimodalart/wan2-1-fast"},{description:"A demo for Stable Video Diffusion",id:"multimodalart/stable-video-diffusion"}],summary:"Image-to-video models take a still image as input and generate a video. These models can be guided by text prompts to influence the content and style of the output video.",widgetModels:[],youtubeId:void 0}),rb("keypoint-detection",{datasets:[{description:"A dataset of hand keypoints of over 500k examples.",id:"Vincent-luo/hagrid-mediapipe-hands"}],demo:{inputs:[{filename:"keypoint-detection-input.png",type:"img"}],outputs:[{filename:"keypoint-detection-output.png",type:"img"}]},metrics:[],models:[{description:"A robust keypoint detection model.",id:"magic-leap-community/superpoint"},{description:"A robust keypoint matching model.",id:"magic-leap-community/superglue_outdoor"},{description:"Strong keypoint detection model used to detect human pose.",id:"facebook/sapiens-pose-1b"},{description:"Powerful keypoint detection model used to detect human pose.",id:"usyd-community/vitpose-plus-base"}],spaces:[{description:"An application that detects hand keypoints in real-time.",id:"datasciencedojo/Hand-Keypoint-Detection-Realtime"},{description:"An application to try a universal keypoint detection model.",id:"merve/SuperPoint"}],summary:"Keypoint detection is the task of identifying meaningful distinctive points or features in an image.",widgetModels:[],youtubeId:""}),rb("mask-generation",{datasets:[{description:"Widely used benchmark dataset for multiple Vision tasks.",id:"merve/coco2017"},{description:"Medical Imaging dataset of the Human Brain for segmentation and mask generating tasks",id:"rocky93/BraTS_segmentation"}],demo:{inputs:[{filename:"mask-generation-input.png",type:"img"}],outputs:[{filename:"mask-generation-output.png",type:"img"}]},metrics:[{description:"IoU is used to measure the overlap between predicted mask and the ground truth mask.",id:"Intersection over Union (IoU)"}],models:[{description:"Small yet powerful mask generation model.",id:"Zigeng/SlimSAM-uniform-50"},{description:"Very strong mask generation model.",id:"facebook/sam2-hiera-large"}],spaces:[{description:"An application that combines a mask generation model with a zero-shot object detection model for text-guided image segmentation.",id:"merve/OWLSAM2"},{description:"An application that compares the performance of a large and a small mask generation model.",id:"merve/slimsam"},{description:"An application based on an improved mask generation model.",id:"SkalskiP/segment-anything-model-2"},{description:"An application to remove objects from videos using mask generation models.",id:"SkalskiP/SAM_and_ProPainter"}],summary:"Mask generation is the task of generating masks that identify a specific object or region of interest in a given image. Masks are often used in segmentation tasks, where they provide a precise way to isolate the object of interest for further processing or analysis.",widgetModels:[],youtubeId:""}),rb("object-detection",{datasets:[{description:"Widely used benchmark dataset for multiple vision tasks.",id:"merve/coco2017"},{description:"Multi-task computer vision benchmark.",id:"merve/pascal-voc"}],demo:{inputs:[{filename:"object-detection-input.jpg",type:"img"}],outputs:[{filename:"object-detection-output.jpg",type:"img"}]},metrics:[{description:"The Average Precision (AP) metric is the Area Under the PR Curve (AUC-PR). It is calculated for each class separately",id:"Average Precision"},{description:"The Mean Average Precision (mAP) metric is the overall average of the AP values",id:"Mean Average Precision"},{description:"The AP metric is the Average Precision at the IoU threshold of a  value, for example, AP50 and AP75",id:"AP"}],models:[{description:"Solid object detection model pre-trained on the COCO 2017 dataset.",id:"facebook/detr-resnet-50"},{description:"Accurate object detection model.",id:"IDEA-Research/dab-detr-resnet-50"},{description:"Fast and accurate object detection model.",id:"PekingU/rtdetr_v2_r50vd"},{description:"Object detection model for low-lying objects.",id:"StephanST/WALDO30"}],spaces:[{description:"Leaderboard to compare various object detection models across several metrics.",id:"hf-vision/object_detection_leaderboard"},{description:"An application that contains various object detection models to try from.",id:"Gradio-Blocks/Object-Detection-With-DETR-and-YOLOS"},{description:"A cutting-edge object detection application.",id:"sunsmarterjieleaf/yolov12"},{description:"An object tracking, segmentation and inpainting application.",id:"VIPLab/Track-Anything"},{description:"Very fast object tracking application based on object detection.",id:"merve/RT-DETR-tracking-coco"}],summary:"Object Detection models allow users to identify objects of certain defined classes. Object detection models receive an image as input and output the images with bounding boxes and labels on detected objects.",widgetModels:["facebook/detr-resnet-50"],youtubeId:"WdAeKSOpxhw"}),rb("video-classification",rp),rb("question-answering",{datasets:[{description:"A famous question answering dataset based on English articles from Wikipedia.",id:"squad_v2"},{description:"A dataset of aggregated anonymized actual queries issued to the Google search engine.",id:"natural_questions"}],demo:{inputs:[{label:"Question",content:"Which name is also used to describe the Amazon rainforest in English?",type:"text"},{label:"Context",content:"The Amazon rainforest, also known in English as Amazonia or the Amazon Jungle",type:"text"}],outputs:[{label:"Answer",content:"Amazonia",type:"text"}]},metrics:[{description:"Exact Match is a metric based on the strict character match of the predicted answer and the right answer. For answers predicted correctly, the Exact Match will be 1. Even if only one character is different, Exact Match will be 0",id:"exact-match"},{description:" The F1-Score metric is useful if we value both false positives and false negatives equally. The F1-Score is calculated on each word in the predicted sequence against the correct answer",id:"f1"}],models:[{description:"A robust baseline model for most question answering domains.",id:"deepset/roberta-base-squad2"},{description:"Small yet robust model that can answer questions.",id:"distilbert/distilbert-base-cased-distilled-squad"},{description:"A special model that can answer questions from tables.",id:"google/tapas-base-finetuned-wtq"}],spaces:[{description:"An application that can answer a long question from Wikipedia.",id:"deepset/wikipedia-assistant"}],summary:"Question Answering models can retrieve the answer to a question from a given text, which is useful for searching for an answer in a document. Some question answering models can generate answers without context!",widgetModels:["deepset/roberta-base-squad2"],youtubeId:"ajPx5LwJD-I"}),rb("reinforcement-learning",{datasets:[{description:"A curation of widely used datasets for Data Driven Deep Reinforcement Learning (D4RL)",id:"edbeeching/decision_transformer_gym_replay"}],demo:{inputs:[{label:"State",content:"Red traffic light, pedestrians are about to pass.",type:"text"}],outputs:[{label:"Action",content:"Stop the car.",type:"text"},{label:"Next State",content:"Yellow light, pedestrians have crossed.",type:"text"}]},metrics:[{description:"Accumulated reward across all time steps discounted by a factor that ranges between 0 and 1 and determines how much the agent optimizes for future relative to immediate rewards. Measures how good is the policy ultimately found by a given algorithm considering uncertainty over the future.",id:"Discounted Total Reward"},{description:"Average return obtained after running the policy for a certain number of evaluation episodes. As opposed to total reward, mean reward considers how much reward a given algorithm receives while learning.",id:"Mean Reward"},{description:"Measures how good a given algorithm is after a predefined time. Some algorithms may be guaranteed to converge to optimal behavior across many time steps. However, an agent that reaches an acceptable level of optimality after a given time horizon may be preferable to one that ultimately reaches optimality but takes a long time.",id:"Level of Performance After Some Time"}],models:[{description:"A Reinforcement Learning model trained on expert data from the Gym Hopper environment",id:"edbeeching/decision-transformer-gym-hopper-expert"},{description:"A PPO agent playing seals/CartPole-v0 using the stable-baselines3 library and the RL Zoo.",id:"HumanCompatibleAI/ppo-seals-CartPole-v0"}],spaces:[{description:"An application for a cute puppy agent learning to catch a stick.",id:"ThomasSimonini/Huggy"},{description:"An application to play Snowball Fight with a reinforcement learning agent.",id:"ThomasSimonini/SnowballFight"}],summary:"Reinforcement learning is the computational approach of learning from action by interacting with an environment through trial and error and receiving rewards (negative or positive) as feedback",widgetModels:[],youtubeId:"q0BiUn5LiBc"}),rb("sentence-similarity",ri),rb("summarization",{canonicalId:"text-generation",datasets:[{description:"News articles in five different languages along with their summaries. Widely used for benchmarking multilingual summarization models.",id:"mlsum"},{description:"English conversations and their summaries. Useful for benchmarking conversational agents.",id:"samsum"}],demo:{inputs:[{label:"Input",content:"The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side. It was the first structure to reach a height of 300 metres. Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.",type:"text"}],outputs:[{label:"Output",content:"The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building. It was the first structure to reach a height of 300 metres.",type:"text"}]},metrics:[{description:"The generated sequence is compared against its summary, and the overlap of tokens are counted. ROUGE-N refers to overlap of N subsequent tokens, ROUGE-1 refers to overlap of single tokens and ROUGE-2 is the overlap of two subsequent tokens.",id:"rouge"}],models:[{description:"A strong summarization model trained on English news articles. Excels at generating factual summaries.",id:"facebook/bart-large-cnn"},{description:"A summarization model trained on medical articles.",id:"Falconsai/medical_summarization"}],spaces:[{description:"An application that can summarize long paragraphs.",id:"pszemraj/summarize-long-text"},{description:"A much needed summarization application for terms and conditions.",id:"ml6team/distilbart-tos-summarizer-tosdr"},{description:"An application that summarizes long documents.",id:"pszemraj/document-summarization"},{description:"An application that can detect errors in abstractive summarization.",id:"ml6team/post-processing-summarization"}],summary:"Summarization is the task of producing a shorter version of a document while preserving its important information. Some models can extract text from the original input, while other models can generate entirely new text.",widgetModels:["facebook/bart-large-cnn"],youtubeId:"yHnr5Dk2zCI"}),rb("table-question-answering",ro),rb("tabular-classification",rs),rb("tabular-regression",rl),rb("text-classification",rc),rb("text-generation",{datasets:[{description:"Multilingual dataset used to evaluate text generation models.",id:"CohereForAI/Global-MMLU"},{description:"High quality multilingual data used to train text-generation models.",id:"HuggingFaceFW/fineweb-2"},{description:"Truly open-source, curated and cleaned dialogue dataset.",id:"HuggingFaceH4/ultrachat_200k"},{description:"A reasoning dataset.",id:"open-r1/OpenThoughts-114k-math"},{description:"A multilingual instruction dataset with preference ratings on responses.",id:"allenai/tulu-3-sft-mixture"},{description:"A large synthetic dataset for alignment of text generation models.",id:"HuggingFaceTB/smoltalk"},{description:"A dataset made for training text generation models solving math questions.",id:"HuggingFaceTB/finemath"}],demo:{inputs:[{label:"Input",content:"Once upon a time,",type:"text"}],outputs:[{label:"Output",content:"Once upon a time, we knew that our ancestors were on the verge of extinction. The great explorers and poets of the Old World, from Alexander the Great to Chaucer, are dead and gone. A good many of our ancient explorers and poets have",type:"text"}]},metrics:[{description:"Cross Entropy is a metric that calculates the difference between two probability distributions. Each probability distribution is the distribution of predicted words",id:"Cross Entropy"},{description:"The Perplexity metric is the exponential of the cross-entropy loss. It evaluates the probabilities assigned to the next word by the model. Lower perplexity indicates better performance",id:"Perplexity"}],models:[{description:"A text-generation model trained to follow instructions.",id:"google/gemma-2-2b-it"},{description:"Smaller variant of one of the most powerful models.",id:"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"},{description:"Very powerful text generation model trained to follow instructions.",id:"meta-llama/Meta-Llama-3.1-8B-Instruct"},{description:"Powerful text generation model by Microsoft.",id:"microsoft/phi-4"},{description:"A very powerful model with reasoning capabilities.",id:"simplescaling/s1.1-32B"},{description:"Strong conversational model that supports very long instructions.",id:"Qwen/Qwen2.5-7B-Instruct-1M"},{description:"Text generation model used to write code.",id:"Qwen/Qwen2.5-Coder-32B-Instruct"},{description:"Powerful reasoning based open large language model.",id:"deepseek-ai/DeepSeek-R1"}],spaces:[{description:"A leaderboard to compare different open-source text generation models based on various benchmarks.",id:"open-llm-leaderboard/open_llm_leaderboard"},{description:"A leaderboard for comparing chain-of-thought performance of models.",id:"logikon/open_cot_leaderboard"},{description:"An text generation based application based on a very powerful LLaMA2 model.",id:"ysharma/Explore_llamav2_with_TGI"},{description:"An text generation based application to converse with Zephyr model.",id:"HuggingFaceH4/zephyr-chat"},{description:"A leaderboard that ranks text generation models based on blind votes from people.",id:"lmsys/chatbot-arena-leaderboard"},{description:"An chatbot to converse with a very powerful text generation model.",id:"mlabonne/phixtral-chat"}],summary:"Generating text is the task of generating new text given another text. These models can, for example, fill in incomplete text or paraphrase.",widgetModels:["mistralai/Mistral-Nemo-Instruct-2407"],youtubeId:"e9gNEAlsOvU"}),rb("text-ranking",rd),rb("text-to-image",{datasets:[{description:"RedCaps is a large-scale dataset of 12M image-text pairs collected from Reddit.",id:"red_caps"},{description:"Conceptual Captions is a dataset consisting of ~3.3M images annotated with captions.",id:"conceptual_captions"},{description:"12M image-caption pairs.",id:"Spawning/PD12M"}],demo:{inputs:[{label:"Input",content:"A city above clouds, pastel colors, Victorian style",type:"text"}],outputs:[{filename:"image.jpeg",type:"img"}]},metrics:[{description:"The Inception Score (IS) measure assesses diversity and meaningfulness. It uses a generated image sample to predict its label. A higher score signifies more diverse and meaningful images.",id:"IS"},{description:"The Frchet Inception Distance (FID) calculates the distance between distributions between synthetic and real samples. A lower FID score indicates better similarity between the distributions of real and generated images.",id:"FID"},{description:"R-precision assesses how the generated image aligns with the provided text description. It uses the generated images as queries to retrieve relevant text descriptions. The top 'r' relevant descriptions are selected and used to calculate R-precision as r/R, where 'R' is the number of ground truth descriptions associated with the generated images. A higher R-precision value indicates a better model.",id:"R-Precision"}],models:[{description:"One of the most powerful image generation models that can generate realistic outputs.",id:"black-forest-labs/FLUX.1-dev"},{description:"A powerful yet fast image generation model.",id:"latent-consistency/lcm-lora-sdxl"},{description:"Text-to-image model for photorealistic generation.",id:"Kwai-Kolors/Kolors"},{description:"A powerful text-to-image model.",id:"stabilityai/stable-diffusion-3-medium-diffusers"}],spaces:[{description:"A powerful text-to-image application.",id:"stabilityai/stable-diffusion-3-medium"},{description:"A text-to-image application to generate comics.",id:"jbilcke-hf/ai-comic-factory"},{description:"An application to match multiple custom image generation models.",id:"multimodalart/flux-lora-lab"},{description:"A powerful yet very fast image generation application.",id:"latent-consistency/lcm-lora-for-sdxl"},{description:"A gallery to explore various text-to-image models.",id:"multimodalart/LoraTheExplorer"},{description:"An application for `text-to-image`, `image-to-image` and image inpainting.",id:"ArtGAN/Stable-Diffusion-ControlNet-WebUI"},{description:"An application to generate realistic images given photos of a person and a prompt.",id:"InstantX/InstantID"}],summary:"Text-to-image is the task of generating images from input text. These pipelines can also be used to modify and edit images based on text prompts.",widgetModels:["black-forest-labs/FLUX.1-dev"],youtubeId:""}),rb("text-to-speech",{canonicalId:"text-to-audio",datasets:[{description:"10K hours of multi-speaker English dataset.",id:"parler-tts/mls_eng_10k"},{description:"Multi-speaker English dataset.",id:"mythicinfinity/libritts_r"},{description:"Multi-lingual dataset.",id:"facebook/multilingual_librispeech"}],demo:{inputs:[{label:"Input",content:"I love audio models on the Hub!",type:"text"}],outputs:[{filename:"audio.wav",type:"audio"}]},metrics:[{description:"The Mel Cepstral Distortion (MCD) metric is used to calculate the quality of generated speech.",id:"mel cepstral distortion"}],models:[{description:"A prompt based, powerful TTS model.",id:"parler-tts/parler-tts-large-v1"},{description:"A powerful TTS model that supports English and Chinese.",id:"SWivid/F5-TTS"},{description:"A massively multi-lingual TTS model.",id:"fishaudio/fish-speech-1.5"},{description:"A powerful TTS model.",id:"OuteAI/OuteTTS-0.1-350M"},{description:"Small yet powerful TTS model.",id:"hexgrad/Kokoro-82M"}],spaces:[{description:"An application for generate high quality speech in different languages.",id:"hexgrad/Kokoro-TTS"},{description:"A multilingual text-to-speech application.",id:"fishaudio/fish-speech-1"},{description:"An application that generates speech in different styles in English and Chinese.",id:"mrfakename/E2-F5-TTS"},{description:"An application that synthesizes emotional speech for diverse speaker prompts.",id:"parler-tts/parler-tts-expresso"},{description:"An application that generates podcast episodes.",id:"ngxson/kokoro-podcast-generator"}],summary:"Text-to-Speech (TTS) is the task of generating natural sounding speech given text input. TTS models can be extended to have a single model that generates speech for multiple speakers and multiple languages.",widgetModels:["suno/bark"],youtubeId:"NW62DpzJ274"}),rb("text-to-video",{datasets:[{description:"Microsoft Research Video to Text is a large-scale dataset for open domain video captioning",id:"iejMac/CLIP-MSR-VTT"},{description:"UCF101 Human Actions dataset consists of 13,320 video clips from YouTube, with 101 classes.",id:"quchenyuan/UCF101-ZIP"},{description:"A high-quality dataset for human action recognition in YouTube videos.",id:"nateraw/kinetics"},{description:"A dataset of video clips of humans performing pre-defined basic actions with everyday objects.",id:"HuggingFaceM4/something_something_v2"},{description:"This dataset consists of text-video pairs and contains noisy samples with irrelevant video descriptions",id:"HuggingFaceM4/webvid"},{description:"A dataset of short Flickr videos for the temporal localization of events with descriptions.",id:"iejMac/CLIP-DiDeMo"}],demo:{inputs:[{label:"Input",content:"Darth Vader is surfing on the waves.",type:"text"}],outputs:[{filename:"text-to-video-output.gif",type:"img"}]},metrics:[{description:"Inception Score uses an image classification model that predicts class labels and evaluates how distinct and diverse the images are. A higher score indicates better video generation.",id:"is"},{description:"Frechet Inception Distance uses an image classification model to obtain image embeddings. The metric compares mean and standard deviation of the embeddings of real and generated images. A smaller score indicates better video generation.",id:"fid"},{description:"Frechet Video Distance uses a model that captures coherence for changes in frames and the quality of each frame. A smaller score indicates better video generation.",id:"fvd"},{description:"CLIPSIM measures similarity between video frames and text using an image-text similarity model. A higher score indicates better video generation.",id:"clipsim"}],models:[{description:"A strong model for consistent video generation.",id:"tencent/HunyuanVideo"},{description:"A text-to-video model with high fidelity motion and strong prompt adherence.",id:"Lightricks/LTX-Video"},{description:"A text-to-video model focusing on physics-aware applications like robotics.",id:"nvidia/Cosmos-1.0-Diffusion-7B-Text2World"},{description:"A robust model for video generation.",id:"Wan-AI/Wan2.1-T2V-1.3B"}],spaces:[{description:"An application that generates video from text.",id:"VideoCrafter/VideoCrafter"},{description:"Consistent video generation application.",id:"Wan-AI/Wan2.1"},{description:"A cutting edge video generation application.",id:"Pyramid-Flow/pyramid-flow"}],summary:"Text-to-video models can be used in any application that requires generating consistent sequence of images from text. ",widgetModels:["Wan-AI/Wan2.1-T2V-14B"],youtubeId:void 0}),rb("token-classification",ru),rb("translation",{canonicalId:"text-generation",datasets:[{description:"A dataset of copyright-free books translated into 16 different languages.",id:"Helsinki-NLP/opus_books"},{description:"An example of translation between programming languages. This dataset consists of functions in Java and C#.",id:"google/code_x_glue_cc_code_to_code_trans"}],demo:{inputs:[{label:"Input",content:"My name is Omar and I live in Zrich.",type:"text"}],outputs:[{label:"Output",content:"Mein Name ist Omar und ich wohne in Zrich.",type:"text"}]},metrics:[{description:"BLEU score is calculated by counting the number of shared single or subsequent tokens between the generated sequence and the reference. Subsequent n tokens are called n-grams. Unigram refers to a single token while bi-gram refers to token pairs and n-grams refer to n subsequent tokens. The score ranges from 0 to 1, where 1 means the translation perfectly matched and 0 did not match at all",id:"bleu"},{description:"",id:"sacrebleu"}],models:[{description:"Very powerful model that can translate many languages between each other, especially low-resource languages.",id:"facebook/nllb-200-1.3B"},{description:"A general-purpose Transformer that can be used to translate from English to German, French, or Romanian.",id:"google-t5/t5-base"}],spaces:[{description:"An application that can translate between 100 languages.",id:"Iker/Translate-100-languages"},{description:"An application that can translate between many languages.",id:"Geonmo/nllb-translation-demo"}],summary:"Translation is the task of converting text from one language to another.",widgetModels:["facebook/mbart-large-50-many-to-many-mmt"],youtubeId:"1JvfrvZgi6c"}),rb("unconditional-image-generation",{datasets:[{description:"The CIFAR-100 dataset consists of 60000 32x32 colour images in 100 classes, with 600 images per class.",id:"cifar100"},{description:"Multiple images of celebrities, used for facial expression translation.",id:"CelebA"}],demo:{inputs:[{label:"Seed",content:"42",type:"text"},{label:"Number of images to generate:",content:"4",type:"text"}],outputs:[{filename:"unconditional-image-generation-output.jpeg",type:"img"}]},metrics:[{description:"The inception score (IS) evaluates the quality of generated images. It measures the diversity of the generated images (the model predictions are evenly distributed across all possible labels) and their 'distinction' or 'sharpness' (the model confidently predicts a single label for each image).",id:"Inception score (IS)"},{description:"The Frchet Inception Distance (FID) evaluates the quality of images created by a generative model by calculating the distance between feature vectors for real and generated images.",id:"Frehet Inception Distance (FID)"}],models:[{description:"High-quality image generation model trained on the CIFAR-10 dataset. It synthesizes images of the ten classes presented in the dataset using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics.",id:"google/ddpm-cifar10-32"},{description:"High-quality image generation model trained on the 256x256 CelebA-HQ dataset. It synthesizes images of faces using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics.",id:"google/ddpm-celebahq-256"}],spaces:[{description:"An application that can generate realistic faces.",id:"CompVis/celeba-latent-diffusion"}],summary:"Unconditional image generation is the task of generating images with no condition in any context (like a prompt text or another image). Once trained, the model will create images that resemble its training data distribution.",widgetModels:[""],youtubeId:""}),rb("video-text-to-text",{datasets:[{description:"Multiple-choice questions and answers about videos.",id:"lmms-lab/Video-MME"},{description:"A dataset of instructions and question-answer pairs about videos.",id:"lmms-lab/VideoChatGPT"},{description:"Large video understanding dataset.",id:"HuggingFaceFV/finevideo"}],demo:{inputs:[{filename:"video-text-to-text-input.gif",type:"img"},{label:"Text Prompt",content:"What is happening in this video?",type:"text"}],outputs:[{label:"Answer",content:"The video shows a series of images showing a fountain with water jets and a variety of colorful flowers and butterflies in the background.",type:"text"}]},metrics:[],models:[{description:"A robust video-text-to-text model.",id:"Vision-CAIR/LongVU_Qwen2_7B"},{description:"Strong video-text-to-text model with reasoning capabilities.",id:"GoodiesHere/Apollo-LMMs-Apollo-7B-t32"},{description:"Strong video-text-to-text model.",id:"HuggingFaceTB/SmolVLM2-2.2B-Instruct"}],spaces:[{description:"An application to chat with a video-text-to-text model.",id:"llava-hf/video-llava"},{description:"A leaderboard for various video-text-to-text models.",id:"opencompass/openvlm_video_leaderboard"},{description:"An application to generate highlights from a video.",id:"HuggingFaceTB/SmolVLM2-HighlightGenerator"}],summary:"Video-text-to-text models take in a video and a text prompt and output text. These models are also called video-language models.",widgetModels:[""],youtubeId:""}),rb("video-to-video",ra),rb("visual-question-answering",rm),rb("zero-shot-classification",rh),rb("zero-shot-image-classification",rg),rb("zero-shot-object-detection",{datasets:[],demo:{inputs:[{filename:"zero-shot-object-detection-input.jpg",type:"img"},{label:"Classes",content:"cat, dog, bird",type:"text"}],outputs:[{filename:"zero-shot-object-detection-output.jpg",type:"img"}]},metrics:[{description:"The Average Precision (AP) metric is the Area Under the PR Curve (AUC-PR). It is calculated for each class separately",id:"Average Precision"},{description:"The Mean Average Precision (mAP) metric is the overall average of the AP values",id:"Mean Average Precision"},{description:"The AP metric is the Average Precision at the IoU threshold of a  value, for example, AP50 and AP75",id:"AP"}],models:[{description:"Solid zero-shot object detection model.",id:"IDEA-Research/grounding-dino-base"},{description:"Cutting-edge zero-shot object detection model.",id:"google/owlv2-base-patch16-ensemble"}],spaces:[{description:"A demo to try the state-of-the-art zero-shot object detection model, OWLv2.",id:"merve/owlv2"},{description:"A demo that combines a zero-shot object detection and mask generation model for zero-shot segmentation.",id:"merve/OWLSAM"}],summary:"Zero-shot object detection is a computer vision task to detect objects and their classes in images, without any prior training or knowledge of the classes. Zero-shot object detection models receive an image as input, as well as a list of candidate classes, and output the bounding boxes and labels where the objects have been detected.",widgetModels:[],youtubeId:""}),rb("text-to-3d",{datasets:[{description:"A large dataset of over 10 million 3D objects.",id:"allenai/objaverse-xl"},{description:"Descriptive captions for 3D objects in Objaverse.",id:"tiange/Cap3D"}],demo:{inputs:[{label:"Prompt",content:"a cat statue",type:"text"}],outputs:[{label:"Result",content:"text-to-3d-3d-output-filename.glb",type:"text"}]},metrics:[],models:[{description:"Text-to-3D mesh model by OpenAI",id:"openai/shap-e"},{description:"Generative 3D gaussian splatting model.",id:"ashawkey/LGM"}],spaces:[{description:"Text-to-3D demo with mesh outputs.",id:"hysts/Shap-E"},{description:"Text/image-to-3D demo with splat outputs.",id:"ashawkey/LGM"}],summary:"Text-to-3D models take in text input and produce 3D output.",widgetModels:[],youtubeId:""}),rb("image-to-3d",{datasets:[{description:"A large dataset of over 10 million 3D objects.",id:"allenai/objaverse-xl"},{description:"A dataset of isolated object images for evaluating image-to-3D models.",id:"dylanebert/iso3d"}],demo:{inputs:[{filename:"image-to-3d-image-input.png",type:"img"}],outputs:[{label:"Result",content:"image-to-3d-3d-output-filename.glb",type:"text"}]},metrics:[],models:[{description:"Fast image-to-3D mesh model by Tencent.",id:"TencentARC/InstantMesh"},{description:"Fast image-to-3D mesh model by StabilityAI",id:"stabilityai/TripoSR"},{description:"A scaled up image-to-3D mesh model derived from TripoSR.",id:"hwjiang/Real3D"},{description:"Consistent image-to-3d generation model.",id:"stabilityai/stable-point-aware-3d"}],spaces:[{description:"Leaderboard to evaluate image-to-3D models.",id:"dylanebert/3d-arena"},{description:"Image-to-3D demo with mesh outputs.",id:"TencentARC/InstantMesh"},{description:"Image-to-3D demo.",id:"stabilityai/stable-point-aware-3d"},{description:"Image-to-3D demo with mesh outputs.",id:"hwjiang/Real3D"},{description:"Image-to-3D demo with splat outputs.",id:"dylanebert/LGM-mini"}],summary:"Image-to-3D models take in image input and produce 3D output.",widgetModels:[],youtubeId:""});const rv=e=>e.tags.includes("conversational")?"text-generation"===e.pipeline_tag?[{role:"user",content:"What is the capital of France?"}]:[{role:"user",content:[{type:"text",text:"Describe this image in one sentence."},{type:"image_url",image_url:{url:"https://cdn.britannica.com/61/93061-050-99147DCE/Statue-of-Liberty-Island-New-York-Bay.jpg"}}]}]:'"Can you please let us know more details about your "',rw=()=>'\'{"Height":[11.52,12.48],"Length1":[23.2,24.0],"Length2":[25.4,26.3],"Species": ["Bream","Bream"]}\'',r_={"audio-to-audio":()=>'"sample1.flac"',"audio-classification":()=>'"sample1.flac"',"automatic-speech-recognition":()=>'"sample1.flac"',"document-question-answering":()=>`{
        "image": "cat.png",
        "question": "What is in this image?"
    }`,"feature-extraction":()=>'"Today is a sunny day and I will get some ice cream."',"fill-mask":e=>`"The answer to the universe is ${e.mask_token}."`,"image-classification":()=>'"cats.jpg"',"image-to-text":()=>'"cats.jpg"',"image-to-image":()=>`{
    "image": "cat.png",
    "prompt": "Turn the cat into a tiger."
}`,"image-to-video":()=>`{
    "image": "cat.png",
    "prompt": "The cat starts to dance"
}`,"image-segmentation":()=>'"cats.jpg"',"object-detection":()=>'"cats.jpg"',"question-answering":()=>`{
    "question": "What is my name?",
    "context": "My name is Clara and I live in Berkeley."
}`,"sentence-similarity":()=>`{
    "source_sentence": "That is a happy person",
    "sentences": [
        "That is a happy dog",
        "That is a very happy person",
        "Today is a sunny day"
    ]
}`,summarization:()=>'"The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side. During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. It was the first structure to reach a height of 300 metres. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct."',"table-question-answering":()=>`{
    "query": "How many stars does the transformers repository have?",
    "table": {
        "Repository": ["Transformers", "Datasets", "Tokenizers"],
        "Stars": ["36542", "4512", "3934"],
        "Contributors": ["651", "77", "34"],
        "Programming language": [
            "Python",
            "Python",
            "Rust, Python and NodeJS"
        ]
    }
}`,"tabular-regression":rw,"tabular-classification":rw,"text-classification":()=>'"I like you. I love you"',"text-generation":rv,"image-text-to-text":rv,"text-to-image":()=>'"Astronaut riding a horse"',"text-to-video":()=>'"A young man walking on the street"',"text-to-speech":()=>'"The answer to the universe is 42"',"text-to-audio":()=>'"liquid drum and bass, atmospheric synths, airy sounds"',"token-classification":()=>'"My name is Sarah Jessica Parker but you can call me Jessica"',translation:()=>`"\u{41C}\u{435}\u{43D}\u{44F} \u{437}\u{43E}\u{432}\u{443}\u{442} \u{412}\u{43E}\u{43B}\u{44C}\u{444}\u{433}\u{430}\u{43D}\u{433} \u{438} \u{44F} \u{436}\u{438}\u{432}\u{443} \u{432} \u{411}\u{435}\u{440}\u{43B}\u{438}\u{43D}\u{435}"`,"zero-shot-classification":()=>'"Hi, I recently bought a device from your company but it is not working as advertised and I would like to get reimbursed!"',"zero-shot-image-classification":()=>'"cats.jpg"'};function rk(e,t=!1,n=!1){if(e.pipeline_tag){let r=r_[e.pipeline_tag];if(r){let a=r(e);if("string"==typeof a&&(t&&(a=a.replace(/(?:(?:\r?\n|\r)\t*)|\t+/g," ")),n)){let e=a.match(/^"(.+)"$/s);a=e?e[1]:a}return a}}return"No input example has been defined for this model task."}const rx="custom_code";function rS(e){let t=e.split("/");return 1===t.length?t[0]:t[1]}function rA(e){return e.cardData?.base_model?.toString()??"fill-in-base-model"}function rT(e){let t=e.widgetData?.[0]?.text??e.cardData?.instance_prompt;if(t)return JSON.stringify(t).slice(1,-1)}const rE="Astronaut in a jungle, cold color palette, muted colors, detailed, 8k",rI="Turn this cat into a dog",rC="A man with short gray hair plays a red electric guitar.",rP={CausalLM:e=>`
import keras_hub

# Load CausalLM model (optional: use half precision for inference)
causal_lm = keras_hub.models.CausalLM.from_preset("hf://${e}", dtype="bfloat16")
causal_lm.compile(sampler="greedy")  # (optional) specify a sampler

# Generate text
causal_lm.generate("Keras: deep learning for", max_length=64)
`,TextToImage:e=>`
import keras_hub

# Load TextToImage model (optional: use half precision for inference)
text_to_image = keras_hub.models.TextToImage.from_preset("hf://${e}", dtype="bfloat16")

# Generate images with a TextToImage model.
text_to_image.generate("Astronaut in a jungle")
`,TextClassifier:e=>`
import keras_hub

# Load TextClassifier model
text_classifier = keras_hub.models.TextClassifier.from_preset(
    "hf://${e}",
    num_classes=2,
)
# Fine-tune
text_classifier.fit(x=["Thilling adventure!", "Total snoozefest."], y=[1, 0])
# Classify text
text_classifier.predict(["Not my cup of tea."])
`,ImageClassifier:e=>`
import keras_hub
import keras

# Load ImageClassifier model
image_classifier = keras_hub.models.ImageClassifier.from_preset(
    "hf://${e}",
    num_classes=2,
)
# Fine-tune
image_classifier.fit(
    x=keras.random.randint((32, 64, 64, 3), 0, 256),
    y=keras.random.randint((32, 1), 0, 2),
)
# Classify image
image_classifier.predict(keras.random.randint((1, 64, 64, 3), 0, 256))
`},rL=(e,t)=>`
import keras_hub

# Create a ${e} model
task = keras_hub.models.${e}.from_preset("hf://${t}")
`,rR=e=>{let t=e.tags.find(e=>e.match(/^yolov\d+$/)),n=t?`YOLOv${t.slice(4)}`:"YOLOvXX";return[(t?"":`# Couldn't find a valid YOLO version tag.
# Replace XX with the correct version.
`)+`from ultralytics import ${n}

model = ${n}.from_pretrained("${e.id}")
source = 'http://images.cocodataset.org/val2017/000000039769.jpg'
model.predict(source=source, save=True)`]},rM={acestep:{prettyLabel:"ACE-Step",repoName:"ACE-Step",repoUrl:"https://github.com/ace-step/ACE-Step",filter:!1,countDownloads:'path:"ace_step_transformer/config.json"'},"adapter-transformers":{prettyLabel:"Adapters",repoName:"adapters",repoUrl:"https://github.com/Adapter-Hub/adapters",docsUrl:"https://huggingface.co/docs/hub/adapters",snippets:e=>[`from adapters import AutoAdapterModel

model = AutoAdapterModel.from_pretrained("${e.config?.adapter_transformers?.model_name}")
model.load_adapter("${e.id}", set_active=True)`],filter:!0,countDownloads:'path:"adapter_config.json"'},allennlp:{prettyLabel:"AllenNLP",repoName:"AllenNLP",repoUrl:"https://github.com/allenai/allennlp",docsUrl:"https://huggingface.co/docs/hub/allennlp",snippets:e=>{if(e.tags.includes("question-answering"))return[`import allennlp_models
from allennlp.predictors.predictor import Predictor

predictor = Predictor.from_path("hf://${e.id}")
predictor_input = {"passage": "My name is Wolfgang and I live in Berlin", "question": "Where do I live?"}
predictions = predictor.predict_json(predictor_input)`];return[`import allennlp_models
from allennlp.predictors.predictor import Predictor

predictor = Predictor.from_path("hf://${e.id}")`]},filter:!0},anemoi:{prettyLabel:"AnemoI",repoName:"AnemoI",repoUrl:"https://github.com/ecmwf/anemoi-inference",docsUrl:"https://anemoi.readthedocs.io/en/latest/",filter:!1,countDownloads:'path_extension:"ckpt"',snippets:e=>[`from anemoi.inference.runners.default import DefaultRunner
from anemoi.inference.config.run import RunConfiguration
# Create Configuration
config = RunConfiguration(checkpoint = {"huggingface":"${e.id}"})
# Load Runner
runner = DefaultRunner(config)`]},araclip:{prettyLabel:"AraClip",repoName:"AraClip",repoUrl:"https://huggingface.co/Arabic-Clip/araclip",filter:!1,snippets:e=>[`from araclip import AraClip

model = AraClip.from_pretrained("${e.id}")`]},asteroid:{prettyLabel:"Asteroid",repoName:"Asteroid",repoUrl:"https://github.com/asteroid-team/asteroid",docsUrl:"https://huggingface.co/docs/hub/asteroid",snippets:e=>[`from asteroid.models import BaseModel

model = BaseModel.from_pretrained("${e.id}")`],filter:!0,countDownloads:'path:"pytorch_model.bin"'},audiocraft:{prettyLabel:"Audiocraft",repoName:"audiocraft",repoUrl:"https://github.com/facebookresearch/audiocraft",snippets:e=>{if(e.tags.includes("musicgen"))return[`from audiocraft.models import MusicGen

model = MusicGen.get_pretrained("${e.id}")

descriptions = ['happy rock', 'energetic EDM', 'sad jazz']
wav = model.generate(descriptions)  # generates 3 samples.`];if(e.tags.includes("audiogen"))return[`from audiocraft.models import AudioGen
	
model = AudioGen.get_pretrained("${e.id}")
model.set_generation_params(duration=5)  # generate 5 seconds.
descriptions = ['dog barking', 'sirene of an emergency vehicle', 'footsteps in a corridor']
wav = model.generate(descriptions)  # generates 3 samples.`];if(!e.tags.includes("magnet"))return["# Type of model unknown."];return[`from audiocraft.models import MAGNeT
	
model = MAGNeT.get_pretrained("${e.id}")

descriptions = ['disco beat', 'energetic EDM', 'funky groove']
wav = model.generate(descriptions)  # generates 3 samples.`]},filter:!1,countDownloads:'path:"state_dict.bin"'},audioseal:{prettyLabel:"AudioSeal",repoName:"audioseal",repoUrl:"https://github.com/facebookresearch/audioseal",filter:!1,countDownloads:'path_extension:"pth"',snippets:e=>[`# Watermark Generator
from audioseal import AudioSeal

model = AudioSeal.load_generator("${e.id}")
# pass a tensor (tensor_wav) of shape (batch, channels, samples) and a sample rate
wav, sr = tensor_wav, 16000
	
watermark = model.get_watermark(wav, sr)
watermarked_audio = wav + watermark`,`# Watermark Detector
from audioseal import AudioSeal

detector = AudioSeal.load_detector("${e.id}")
	
result, message = detector.detect_watermark(watermarked_audio, sr)`]},"bagel-mot":{prettyLabel:"Bagel",repoName:"Bagel",repoUrl:"https://github.com/ByteDance-Seed/Bagel/",filter:!1,countDownloads:'path:"llm_config.json"'},ben2:{prettyLabel:"BEN2",repoName:"BEN2",repoUrl:"https://github.com/PramaLLC/BEN2",snippets:e=>[`import requests
from PIL import Image
from ben2 import AutoModel

url = "https://huggingface.co/datasets/mishig/sample_images/resolve/main/teapot.jpg"
image = Image.open(requests.get(url, stream=True).raw)

model = AutoModel.from_pretrained("${e.id}")
model.to("cuda").eval()
foreground = model.inference(image)
`],filter:!1},bertopic:{prettyLabel:"BERTopic",repoName:"BERTopic",repoUrl:"https://github.com/MaartenGr/BERTopic",snippets:e=>[`from bertopic import BERTopic

model = BERTopic.load("${e.id}")`],filter:!0},big_vision:{prettyLabel:"Big Vision",repoName:"big_vision",repoUrl:"https://github.com/google-research/big_vision",filter:!1,countDownloads:'path_extension:"npz"'},birder:{prettyLabel:"Birder",repoName:"Birder",repoUrl:"https://gitlab.com/birder/birder",filter:!1,countDownloads:'path_extension:"pt"'},birefnet:{prettyLabel:"BiRefNet",repoName:"BiRefNet",repoUrl:"https://github.com/ZhengPeng7/BiRefNet",snippets:e=>[`# Option 1: use with transformers

from transformers import AutoModelForImageSegmentation
birefnet = AutoModelForImageSegmentation.from_pretrained("${e.id}", trust_remote_code=True)
`,`# Option 2: use with BiRefNet

# Install from https://github.com/ZhengPeng7/BiRefNet

from models.birefnet import BiRefNet
model = BiRefNet.from_pretrained("${e.id}")`],filter:!1},bm25s:{prettyLabel:"BM25S",repoName:"bm25s",repoUrl:"https://github.com/xhluca/bm25s",snippets:e=>[`from bm25s.hf import BM25HF

retriever = BM25HF.load_from_hub("${e.id}")`],filter:!1,countDownloads:'path:"params.index.json"'},champ:{prettyLabel:"Champ",repoName:"Champ",repoUrl:"https://github.com/fudan-generative-vision/champ",countDownloads:'path:"champ/motion_module.pth"'},chatterbox:{prettyLabel:"Chatterbox",repoName:"Chatterbox",repoUrl:"https://github.com/resemble-ai/chatterbox",snippets:()=>[`# pip install chatterbox-tts
import torchaudio as ta
from chatterbox.tts import ChatterboxTTS

model = ChatterboxTTS.from_pretrained(device="cuda")

text = "Ezreal and Jinx teamed up with Ahri, Yasuo, and Teemo to take down the enemy's Nexus in an epic late-game pentakill."
wav = model.generate(text)
ta.save("test-1.wav", wav, model.sr)

# If you want to synthesize with a different voice, specify the audio prompt
AUDIO_PROMPT_PATH="YOUR_FILE.wav"
wav = model.generate(text, audio_prompt_path=AUDIO_PROMPT_PATH)
ta.save("test-2.wav", wav, model.sr)`],countDownloads:'path:"tokenizer.json"',filter:!1},chat_tts:{prettyLabel:"ChatTTS",repoName:"ChatTTS",repoUrl:"https://github.com/2noise/ChatTTS.git",snippets:()=>[`import ChatTTS
import torchaudio

chat = ChatTTS.Chat()
chat.load_models(compile=False) # Set to True for better performance

texts = ["PUT YOUR TEXT HERE",]

wavs = chat.infer(texts, )

torchaudio.save("output1.wav", torch.from_numpy(wavs[0]), 24000)`],filter:!1,countDownloads:'path:"asset/GPT.pt"'},colpali:{prettyLabel:"ColPali",repoName:"ColPali",repoUrl:"https://github.com/ManuelFay/colpali",filter:!1,countDownloads:'path:"adapter_config.json"'},comet:{prettyLabel:"COMET",repoName:"COMET",repoUrl:"https://github.com/Unbabel/COMET/",countDownloads:'path:"hparams.yaml"'},contexttab:{prettyLabel:"ConTextTab",repoName:"ConTextTab",repoUrl:"https://github.com/SAP-samples/contexttab",countDownloads:'path_extension:"pt"',snippets:()=>["pip install git+https://github.com/SAP-samples/contexttab",`# Run a classification task
from sklearn.datasets import load_breast_cancer
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

from contexttab import ConTextTabClassifier

# Load sample data
X, y = load_breast_cancer(return_X_y=True)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)

# Initialize a classifier
# You can omit checkpoint and checkpoint_revision to use the default model
clf = ConTextTabClassifier(checkpoint="l2/base.pt", checkpoint_revision="v1.0.0", bagging=1, max_context_size=2048)

clf.fit(X_train, y_train)

# Predict probabilities
prediction_probabilities = clf.predict_proba(X_test)
# Predict labels
predictions = clf.predict(X_test)
print("Accuracy", accuracy_score(y_test, predictions))`,`# Run a regression task
from sklearn.datasets import fetch_openml
from sklearn.metrics import r2_score
from sklearn.model_selection import train_test_split

from contexttab import ConTextTabRegressor


# Load sample data
df = fetch_openml(data_id=531, as_frame=True)
X = df.data
y = df.target.astype(float)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)

# Initialize the regressor
# You can omit checkpoint and checkpoint_revision to use the default model
regressor = ConTextTabRegressor(checkpoint="l2/base.pt", checkpoint_revision="v1.0.0", bagging=1, max_context_size=2048)

regressor.fit(X_train, y_train)

# Predict on the test set
predictions = regressor.predict(X_test)

r2 = r2_score(y_test, predictions)
print("R\xb2 Score:", r2)`]},cosmos:{prettyLabel:"Cosmos",repoName:"Cosmos",repoUrl:"https://github.com/NVIDIA/Cosmos",countDownloads:'path:"config.json" OR path_extension:"pt"'},"cxr-foundation":{prettyLabel:"CXR Foundation",repoName:"cxr-foundation",repoUrl:"https://github.com/google-health/cxr-foundation",snippets:()=>[`# pip install git+https://github.com/Google-Health/cxr-foundation.git#subdirectory=python

# Load image as grayscale (Stillwaterising, CC0, via Wikimedia Commons)
import requests
from PIL import Image
from io import BytesIO
image_url = "https://upload.wikimedia.org/wikipedia/commons/c/c8/Chest_Xray_PA_3-8-2010.png"
img = Image.open(requests.get(image_url, headers={'User-Agent': 'Demo'}, stream=True).raw).convert('L')

# Run inference
from clientside.clients import make_hugging_face_client
cxr_client = make_hugging_face_client('cxr_model')
print(cxr_client.get_image_embeddings_from_images([img]))`],filter:!1,countDownloads:'path:"precomputed_embeddings/embeddings.npz" OR path:"pax-elixr-b-text/saved_model.pb"'},deepforest:{prettyLabel:"DeepForest",repoName:"deepforest",docsUrl:"https://deepforest.readthedocs.io/en/latest/",repoUrl:"https://github.com/weecology/DeepForest"},"depth-anything-v2":{prettyLabel:"DepthAnythingV2",repoName:"Depth Anything V2",repoUrl:"https://github.com/DepthAnything/Depth-Anything-V2",snippets:e=>{let t,n,r;return t="<ENCODER>",n="<NUMBER_OF_FEATURES>",r="<OUT_CHANNELS>","depth-anything/Depth-Anything-V2-Small"===e.id?(t="vits",n="64",r="[48, 96, 192, 384]"):"depth-anything/Depth-Anything-V2-Base"===e.id?(t="vitb",n="128",r="[96, 192, 384, 768]"):"depth-anything/Depth-Anything-V2-Large"===e.id&&(t="vitl",n="256",r="[256, 512, 1024, 1024"),[`
# Install from https://github.com/DepthAnything/Depth-Anything-V2

# Load the model and infer depth from an image
import cv2
import torch

from depth_anything_v2.dpt import DepthAnythingV2

# instantiate the model
model = DepthAnythingV2(encoder="${t}", features=${n}, out_channels=${r})

# load the weights
filepath = hf_hub_download(repo_id="${e.id}", filename="depth_anything_v2_${t}.pth", repo_type="model")
state_dict = torch.load(filepath, map_location="cpu")
model.load_state_dict(state_dict).eval()

raw_img = cv2.imread("your/image/path")
depth = model.infer_image(raw_img) # HxW raw depth map in numpy
    `]},filter:!1,countDownloads:'path_extension:"pth"'},"depth-pro":{prettyLabel:"Depth Pro",repoName:"Depth Pro",repoUrl:"https://github.com/apple/ml-depth-pro",countDownloads:'path_extension:"pt"',snippets:e=>[`# Download checkpoint
pip install huggingface-hub
huggingface-cli download --local-dir checkpoints ${e.id}`,`import depth_pro

# Load model and preprocessing transform
model, transform = depth_pro.create_model_and_transforms()
model.eval()

# Load and preprocess an image.
image, _, f_px = depth_pro.load_rgb("example.png")
image = transform(image)

# Run inference.
prediction = model.infer(image, f_px=f_px)

# Results: 1. Depth in meters
depth = prediction["depth"]
# Results: 2. Focal length in pixels
focallength_px = prediction["focallength_px"]`],filter:!1},"derm-foundation":{prettyLabel:"Derm Foundation",repoName:"derm-foundation",repoUrl:"https://github.com/google-health/derm-foundation",snippets:()=>[`from huggingface_hub import from_pretrained_keras
import tensorflow as tf, requests

# Load and format input
IMAGE_URL = "https://storage.googleapis.com/dx-scin-public-data/dataset/images/3445096909671059178.png"
input_tensor = tf.train.Example(
    features=tf.train.Features(
        feature={
            "image/encoded": tf.train.Feature(
                bytes_list=tf.train.BytesList(value=[requests.get(IMAGE_URL, stream=True).content])
            )
        }
    )
).SerializeToString()

# Load model and run inference
loaded_model = from_pretrained_keras("google/derm-foundation")
infer = loaded_model.signatures["serving_default"]
print(infer(inputs=tf.constant([input_tensor])))`],filter:!1,countDownloads:'path:"scin_dataset_precomputed_embeddings.npz" OR path:"saved_model.pb"'},"describe-anything":{prettyLabel:"Describe Anything",repoName:"Describe Anything",repoUrl:"https://github.com/NVlabs/describe-anything",snippets:e=>[`# pip install git+https://github.com/NVlabs/describe-anything
from huggingface_hub import snapshot_download
from dam import DescribeAnythingModel

snapshot_download(${e.id}, local_dir="checkpoints")

dam = DescribeAnythingModel(
	model_path="checkpoints",
	conv_mode="v1",
	prompt_mode="focal_prompt",
)`],filter:!1},"dia-tts":{prettyLabel:"Dia",repoName:"Dia",repoUrl:"https://github.com/nari-labs/dia",snippets:e=>[`import soundfile as sf
from dia.model import Dia

model = Dia.from_pretrained("${e.id}")
text = "[S1] Dia is an open weights text to dialogue model. [S2] You get full control over scripts and voices. [S1] Wow. Amazing. (laughs) [S2] Try it now on Git hub or Hugging Face."
output = model.generate(text)

sf.write("simple.mp3", output, 44100)`],filter:!1},diffree:{prettyLabel:"Diffree",repoName:"Diffree",repoUrl:"https://github.com/OpenGVLab/Diffree",filter:!1,countDownloads:'path:"diffree-step=000010999.ckpt"'},diffusers:{prettyLabel:"Diffusers",repoName:"\uD83E\uDD17/diffusers",repoUrl:"https://github.com/huggingface/diffusers",docsUrl:"https://huggingface.co/docs/hub/diffusers",snippets:e=>{if(e.tags.includes("StableDiffusionInpaintPipeline")||e.tags.includes("StableDiffusionXLInpaintPipeline"))return[`import torch
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image

pipe = AutoPipelineForInpainting.from_pretrained("${e.id}", torch_dtype=torch.float16, variant="fp16").to("cuda")

img_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
mask_url = "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"

image = load_image(img_url).resize((1024, 1024))
mask_image = load_image(mask_url).resize((1024, 1024))

prompt = "a tiger sitting on a park bench"
generator = torch.Generator(device="cuda").manual_seed(0)

image = pipe(
  prompt=prompt,
  image=image,
  mask_image=mask_image,
  guidance_scale=8.0,
  num_inference_steps=20,  # steps between 15 and 30 work well for us
  strength=0.99,  # make sure to use \`strength\` below 1.0
  generator=generator,
).images[0]`];if(e.tags.includes("controlnet"))return[`from diffusers import ControlNetModel, StableDiffusionControlNetPipeline

controlnet = ControlNetModel.from_pretrained("${e.id}")
pipe = StableDiffusionControlNetPipeline.from_pretrained(
	"${rA(e)}", controlnet=controlnet
)`];if(e.tags.includes("lora"))if("image-to-image"===e.pipeline_tag)return[`from diffusers import DiffusionPipeline
from diffusers.utils import load_image

pipe = DiffusionPipeline.from_pretrained("${rA(e)}")
pipe.load_lora_weights("${e.id}")

prompt = "${rT(e)??rI}"
input_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/cat.png")

image = pipe(image=input_image, prompt=prompt).images[0]`];else if("image-to-video"===e.pipeline_tag)return[`from diffusers import DiffusionPipeline
from diffusers.utils import load_image, export_to_video

pipe = DiffusionPipeline.from_pretrained("${rA(e)}")
pipe.load_lora_weights("${e.id}")

prompt = "${rT(e)??rC}"
input_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/guitar-man.png")

image = pipe(image=input_image, prompt=prompt).frames[0]
export_to_video(output, "output.mp4")`];else if("text-to-video"===e.pipeline_tag)return[`from diffusers import DiffusionPipeline
from diffusers.utils import export_to_video

pipe = DiffusionPipeline.from_pretrained("${rA(e)}")
pipe.load_lora_weights("${e.id}")

prompt = "${rT(e)??rC}"

output = pipe(prompt=prompt).frames[0]
export_to_video(output, "output.mp4")`];else return[`from diffusers import DiffusionPipeline

pipe = DiffusionPipeline.from_pretrained("${rA(e)}")
pipe.load_lora_weights("${e.id}")

prompt = "${rT(e)??rE}"
image = pipe(prompt).images[0]`];if(e.tags.includes("textual_inversion"))return[`from diffusers import DiffusionPipeline

pipe = DiffusionPipeline.from_pretrained("${rA(e)}")
pipe.load_textual_inversion("${e.id}")`];if(e.tags.includes("FluxFillPipeline"))return[`import torch
from diffusers import FluxFillPipeline
from diffusers.utils import load_image

image = load_image("https://huggingface.co/datasets/diffusers/diffusers-images-docs/resolve/main/cup.png")
mask = load_image("https://huggingface.co/datasets/diffusers/diffusers-images-docs/resolve/main/cup_mask.png")

pipe = FluxFillPipeline.from_pretrained("${e.id}", torch_dtype=torch.bfloat16).to("cuda")
image = pipe(
    prompt="a white paper cup",
    image=image,
    mask_image=mask,
    height=1632,
    width=1232,
    guidance_scale=30,
    num_inference_steps=50,
    max_sequence_length=512,
    generator=torch.Generator("cpu").manual_seed(0)
).images[0]
image.save(f"flux-fill-dev.png")`];else if("image-to-video"===e.pipeline_tag)return[`import torch
from diffusers import DiffusionPipeline
from diffusers.utils import load_image, export_to_video

pipe = DiffusionPipeline.from_pretrained("${e.id}", torch_dtype=torch.float16)
pipe.to("cuda")

prompt = "${rT(e)??rC}"
image = load_image(
    "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/guitar-man.png"
)

output = pipe(image=image, prompt=prompt).frames[0]
export_to_video(output, "output.mp4")`];else if("image-to-image"===e.pipeline_tag)return[`from diffusers import DiffusionPipeline
from diffusers.utils import load_image

pipe = DiffusionPipeline.from_pretrained("${e.id}")

prompt = "${rT(e)??rI}"
input_image = load_image("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/cat.png")

image = pipe(image=input_image, prompt=prompt).images[0]`];else return[`from diffusers import DiffusionPipeline

pipe = DiffusionPipeline.from_pretrained("${e.id}")

prompt = "${rT(e)??rE}"
image = pipe(prompt).images[0]`]},filter:!0},diffusionkit:{prettyLabel:"DiffusionKit",repoName:"DiffusionKit",repoUrl:"https://github.com/argmaxinc/DiffusionKit",snippets:e=>{let t=`# Pipeline for Stable Diffusion 3
from diffusionkit.mlx import DiffusionPipeline

pipeline = DiffusionPipeline(
	shift=3.0,
	use_t5=False,
	model_version=${e.id},
	low_memory_mode=True,
	a16=True,
	w16=True,
)`,n=`# Pipeline for Flux
from diffusionkit.mlx import FluxPipeline

pipeline = FluxPipeline(
  shift=1.0,
  model_version=${e.id},
  low_memory_mode=True,
  a16=True,
  w16=True,
)`,r=`# Image Generation
HEIGHT = 512
WIDTH = 512
NUM_STEPS = ${e.tags.includes("flux")?4:50}
CFG_WEIGHT = ${5*!e.tags.includes("flux")}

image, _ = pipeline.generate_image(
  "a photo of a cat",
  cfg_weight=CFG_WEIGHT,
  num_steps=NUM_STEPS,
  latent_size=(HEIGHT // 8, WIDTH // 8),
)`;return[e.tags.includes("flux")?n:t,r]}},doctr:{prettyLabel:"docTR",repoName:"doctr",repoUrl:"https://github.com/mindee/doctr"},cartesia_pytorch:{prettyLabel:"Cartesia Pytorch",repoName:"Cartesia Pytorch",repoUrl:"https://github.com/cartesia-ai/cartesia_pytorch",snippets:e=>[`# pip install --no-binary :all: cartesia-pytorch
from cartesia_pytorch import ReneLMHeadModel
from transformers import AutoTokenizer

model = ReneLMHeadModel.from_pretrained("${e.id}")
tokenizer = AutoTokenizer.from_pretrained("allenai/OLMo-1B-hf")

in_message = ["Rene Descartes was"]
inputs = tokenizer(in_message, return_tensors="pt")

outputs = model.generate(inputs.input_ids, max_length=50, top_k=100, top_p=0.99)
out_message = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]

print(out_message)
)`]},cartesia_mlx:{prettyLabel:"Cartesia MLX",repoName:"Cartesia MLX",repoUrl:"https://github.com/cartesia-ai/cartesia_mlx",snippets:e=>[`import mlx.core as mx
import cartesia_mlx as cmx

model = cmx.from_pretrained("${e.id}")
model.set_dtype(mx.float32)   

prompt = "Rene Descartes was"

for text in model.generate(
    prompt,
    max_tokens=500,
    eval_every_n=5,
    verbose=True,
    top_p=0.99,
    temperature=0.85,
):
    print(text, end="", flush=True)
`]},clipscope:{prettyLabel:"clipscope",repoName:"clipscope",repoUrl:"https://github.com/Lewington-pitsos/clipscope",filter:!1,countDownloads:'path_extension:"pt"'},cosyvoice:{prettyLabel:"CosyVoice",repoName:"CosyVoice",repoUrl:"https://github.com/FunAudioLLM/CosyVoice",filter:!1,countDownloads:'path_extension:"onnx" OR path_extension:"pt"'},cotracker:{prettyLabel:"CoTracker",repoName:"CoTracker",repoUrl:"https://github.com/facebookresearch/co-tracker",filter:!1,countDownloads:'path_extension:"pth"'},edsnlp:{prettyLabel:"EDS-NLP",repoName:"edsnlp",repoUrl:"https://github.com/aphp/edsnlp",docsUrl:"https://aphp.github.io/edsnlp/latest/",filter:!1,snippets:e=>{let t=rS(e.id).replaceAll("-","_");return[`# Load it from the Hub directly
import edsnlp
nlp = edsnlp.load("${e.id}")
`,`# Or install it as a package
!pip install git+https://huggingface.co/${e.id}

# and import it as a module
import ${t}

nlp = ${t}.load()  # or edsnlp.load("${t}")
`]},countDownloads:'path_filename:"config" AND path_extension:"cfg"'},elm:{prettyLabel:"ELM",repoName:"elm",repoUrl:"https://github.com/slicex-ai/elm",filter:!1,countDownloads:'path_filename:"slicex_elm_config" AND path_extension:"json"'},espnet:{prettyLabel:"ESPnet",repoName:"ESPnet",repoUrl:"https://github.com/espnet/espnet",docsUrl:"https://huggingface.co/docs/hub/espnet",snippets:e=>{if(e.tags.includes("text-to-speech"))return[`from espnet2.bin.tts_inference import Text2Speech

model = Text2Speech.from_pretrained("${e.id}")

speech, *_ = model("text to generate speech from")`];if(e.tags.includes("automatic-speech-recognition"))return[`from espnet2.bin.asr_inference import Speech2Text

model = Speech2Text.from_pretrained(
  "${e.id}"
)

speech, rate = soundfile.read("speech.wav")
text, *_ = model(speech)[0]`];return["unknown model type (must be text-to-speech or automatic-speech-recognition)"]},filter:!0},fairseq:{prettyLabel:"Fairseq",repoName:"fairseq",repoUrl:"https://github.com/pytorch/fairseq",snippets:e=>[`from fairseq.checkpoint_utils import load_model_ensemble_and_task_from_hf_hub

models, cfg, task = load_model_ensemble_and_task_from_hf_hub(
    "${e.id}"
)`],filter:!0},fastai:{prettyLabel:"fastai",repoName:"fastai",repoUrl:"https://github.com/fastai/fastai",docsUrl:"https://huggingface.co/docs/hub/fastai",snippets:e=>[`from huggingface_hub import from_pretrained_fastai

learn = from_pretrained_fastai("${e.id}")`],filter:!0},fasttext:{prettyLabel:"fastText",repoName:"fastText",repoUrl:"https://fasttext.cc/",snippets:e=>[`from huggingface_hub import hf_hub_download
import fasttext

model = fasttext.load_model(hf_hub_download("${e.id}", "model.bin"))`],filter:!0,countDownloads:'path_extension:"bin"'},flair:{prettyLabel:"Flair",repoName:"Flair",repoUrl:"https://github.com/flairNLP/flair",docsUrl:"https://huggingface.co/docs/hub/flair",snippets:e=>[`from flair.models import SequenceTagger

tagger = SequenceTagger.load("${e.id}")`],filter:!0,countDownloads:'path:"pytorch_model.bin"'},fme:{prettyLabel:"Full Model Emulation",repoName:"Full Model Emulation",repoUrl:"https://github.com/ai2cm/ace",docsUrl:"https://ai2-climate-emulator.readthedocs.io/en/latest/",filter:!1,countDownloads:'path_extension:"tar"'},"gemma.cpp":{prettyLabel:"gemma.cpp",repoName:"gemma.cpp",repoUrl:"https://github.com/google/gemma.cpp",filter:!1,countDownloads:'path_extension:"sbs"'},"geometry-crafter":{prettyLabel:"GeometryCrafter",repoName:"GeometryCrafter",repoUrl:"https://github.com/TencentARC/GeometryCrafter",countDownloads:'path:"point_map_vae/diffusion_pytorch_model.safetensors"'},gliner:{prettyLabel:"GLiNER",repoName:"GLiNER",repoUrl:"https://github.com/urchade/GLiNER",snippets:e=>[`from gliner import GLiNER

model = GLiNER.from_pretrained("${e.id}")`],filter:!1,countDownloads:'path:"gliner_config.json"'},"glyph-byt5":{prettyLabel:"Glyph-ByT5",repoName:"Glyph-ByT5",repoUrl:"https://github.com/AIGText/Glyph-ByT5",filter:!1,countDownloads:'path:"checkpoints/byt5_model.pt"'},grok:{prettyLabel:"Grok",repoName:"Grok",repoUrl:"https://github.com/xai-org/grok-1",filter:!1,countDownloads:'path:"ckpt/tensor00000_000" OR path:"ckpt-0/tensor00000_000"'},hallo:{prettyLabel:"Hallo",repoName:"Hallo",repoUrl:"https://github.com/fudan-generative-vision/hallo",countDownloads:'path:"hallo/net.pth"'},hermes:{prettyLabel:"HERMES",repoName:"HERMES",repoUrl:"https://github.com/LMD0311/HERMES",filter:!1,countDownloads:'path:"ckpt/hermes_final.pth"'},hezar:{prettyLabel:"Hezar",repoName:"Hezar",repoUrl:"https://github.com/hezarai/hezar",docsUrl:"https://hezarai.github.io/hezar",countDownloads:'path:"model_config.yaml" OR path:"embedding/embedding_config.yaml"'},htrflow:{prettyLabel:"HTRflow",repoName:"HTRflow",repoUrl:"https://github.com/AI-Riksarkivet/htrflow",docsUrl:"https://ai-riksarkivet.github.io/htrflow",snippets:e=>[`# CLI usage
# see docs: https://ai-riksarkivet.github.io/htrflow/latest/getting_started/quick_start.html
htrflow pipeline <path/to/pipeline.yaml> <path/to/image>`,`# Python usage
from htrflow.pipeline.pipeline import Pipeline
from htrflow.pipeline.steps import Task
from htrflow.models.framework.model import ModelClass

pipeline = Pipeline(
    [
        Task(
            ModelClass, {"model": "${e.id}"}, {}
        ),
    ])`]},"hunyuan-dit":{prettyLabel:"HunyuanDiT",repoName:"HunyuanDiT",repoUrl:"https://github.com/Tencent/HunyuanDiT",countDownloads:'path:"pytorch_model_ema.pt" OR path:"pytorch_model_distill.pt"'},"hunyuan3d-2":{prettyLabel:"Hunyuan3D-2",repoName:"Hunyuan3D-2",repoUrl:"https://github.com/Tencent/Hunyuan3D-2",countDownloads:'path_filename:"model_index" OR path_filename:"config"'},imstoucan:{prettyLabel:"IMS Toucan",repoName:"IMS-Toucan",repoUrl:"https://github.com/DigitalPhonetics/IMS-Toucan",countDownloads:'path:"embedding_gan.pt" OR path:"Vocoder.pt" OR path:"ToucanTTS.pt"'},"index-tts":{prettyLabel:"IndexTTS",repoName:"IndexTTS",repoUrl:"https://github.com/index-tts/index-tts",snippets:e=>[`# Download model
from huggingface_hub import snapshot_download

snapshot_download(${e.id}, local_dir="checkpoints")

from indextts.infer import IndexTTS

# Ensure config.yaml is present in the checkpoints directory
tts = IndexTTS(model_dir="checkpoints", cfg_path="checkpoints/config.yaml")

voice = "path/to/your/reference_voice.wav"  # Path to the voice reference audio file
text = "Hello, how are you?"
output_path = "output_index.wav"

tts.infer(voice, text, output_path)`],filter:!1},"infinite-you":{prettyLabel:"InfiniteYou",repoName:"InfiniteYou",repoUrl:"https://github.com/bytedance/InfiniteYou",filter:!1,countDownloads:'path:"infu_flux_v1.0/sim_stage1/image_proj_model.bin" OR path:"infu_flux_v1.0/aes_stage2/image_proj_model.bin"'},keras:{prettyLabel:"Keras",repoName:"Keras",repoUrl:"https://github.com/keras-team/keras",docsUrl:"https://huggingface.co/docs/hub/keras",snippets:e=>[`# Available backend options are: "jax", "torch", "tensorflow".
import os
os.environ["KERAS_BACKEND"] = "jax"
	
import keras

model = keras.saving.load_model("hf://${e.id}")
`],filter:!0,countDownloads:'path:"config.json" OR path_extension:"keras"'},"tf-keras":{prettyLabel:"TF-Keras",repoName:"TF-Keras",repoUrl:"https://github.com/keras-team/tf-keras",docsUrl:"https://huggingface.co/docs/hub/tf-keras",snippets:e=>[`# Note: 'keras<3.x' or 'tf_keras' must be installed (legacy)
# See https://github.com/keras-team/tf-keras for more details.
from huggingface_hub import from_pretrained_keras

model = from_pretrained_keras("${e.id}")
`],countDownloads:'path:"saved_model.pb"'},"keras-hub":{prettyLabel:"KerasHub",repoName:"KerasHub",repoUrl:"https://github.com/keras-team/keras-hub",docsUrl:"https://keras.io/keras_hub/",snippets:e=>{let t=e.id,n=e.config?.keras_hub?.tasks??[],r=[];for(let[e,a]of Object.entries(rP))n.includes(e)&&r.push(a(t));for(let e of n)Object.keys(rP).includes(e)||r.push(rL(e,t));return r.push(`
import keras_hub

# Create a Backbone model unspecialized for any task
backbone = keras_hub.models.Backbone.from_preset("hf://${t}")
`),r},filter:!0},"kimi-audio":{prettyLabel:"KimiAudio",repoName:"KimiAudio",repoUrl:"https://github.com/MoonshotAI/Kimi-Audio",snippets:e=>[`# Example usage for KimiAudio
# pip install git+https://github.com/MoonshotAI/Kimi-Audio.git

from kimia_infer.api.kimia import KimiAudio

model = KimiAudio(model_path="${e.id}", load_detokenizer=True)

sampling_params = {
    "audio_temperature": 0.8,
    "audio_top_k": 10,
    "text_temperature": 0.0,
    "text_top_k": 5,
}

# For ASR
asr_audio = "asr_example.wav"
messages_asr = [
    {"role": "user", "message_type": "text", "content": "Please transcribe the following audio:"},
    {"role": "user", "message_type": "audio", "content": asr_audio}
]
_, text = model.generate(messages_asr, **sampling_params, output_type="text")
print(text)

# For Q&A
qa_audio = "qa_example.wav"
messages_conv = [{"role": "user", "message_type": "audio", "content": qa_audio}]
wav, text = model.generate(messages_conv, **sampling_params, output_type="both")
sf.write("output_audio.wav", wav.cpu().view(-1).numpy(), 24000)
print(text)
`],filter:!1},kronos:{prettyLabel:"KRONOS",repoName:"KRONOS",repoUrl:"https://github.com/mahmoodlab/KRONOS",filter:!1,countDownloads:'path_extension:"pt"'},k2:{prettyLabel:"K2",repoName:"k2",repoUrl:"https://github.com/k2-fsa/k2"},"lightning-ir":{prettyLabel:"Lightning IR",repoName:"Lightning IR",repoUrl:"https://github.com/webis-de/lightning-ir",snippets:e=>e.tags.includes("bi-encoder")?[`#install from https://github.com/webis-de/lightning-ir

from lightning_ir import BiEncoderModule
model = BiEncoderModule("${e.id}")

model.score("query", ["doc1", "doc2", "doc3"])`]:e.tags.includes("cross-encoder")?[`#install from https://github.com/webis-de/lightning-ir

from lightning_ir import CrossEncoderModule
model = CrossEncoderModule("${e.id}")

model.score("query", ["doc1", "doc2", "doc3"])`]:[`#install from https://github.com/webis-de/lightning-ir

from lightning_ir import BiEncoderModule, CrossEncoderModule

# depending on the model type, use either BiEncoderModule or CrossEncoderModule
model = BiEncoderModule("${e.id}") 
# model = CrossEncoderModule("${e.id}")

model.score("query", ["doc1", "doc2", "doc3"])`]},"litert-lm":{prettyLabel:"LiteRT-LM",repoName:"LiteRT-LM",repoUrl:"https://github.com/google-ai-edge/LiteRT-LM",filter:!1,countDownloads:'path_extension:"litertlm"'},lerobot:{prettyLabel:"LeRobot",repoName:"LeRobot",repoUrl:"https://github.com/huggingface/lerobot",docsUrl:"https://huggingface.co/docs/lerobot",filter:!1,snippets:e=>{if(e.tags.includes("smolvla")){let t=[`# See https://github.com/huggingface/lerobot?tab=readme-ov-file#installation for more details
git clone https://github.com/huggingface/lerobot.git
cd lerobot
pip install -e .[smolvla]`,`# Launch finetuning on your dataset
python lerobot/scripts/train.py \\
--policy.path=${e.id} \\
--dataset.repo_id=lerobot/svla_so101_pickplace \\ 
--batch_size=64 \\
--steps=20000 \\
--output_dir=outputs/train/my_smolvla \\
--job_name=my_smolvla_training \\
--policy.device=cuda \\
--wandb.enable=true`];return"lerobot/smolvla_base"!==e.id&&t.push(`# Run the policy using the record function	
python -m lerobot.record \\
  --robot.type=so101_follower \\
  --robot.port=/dev/ttyACM0 \\ # <- Use your port
  --robot.id=my_blue_follower_arm \\ # <- Use your robot id
  --robot.cameras="{ front: {type: opencv, index_or_path: 8, width: 640, height: 480, fps: 30}}" \\ # <- Use your cameras
  --dataset.single_task="Grasp a lego block and put it in the bin." \\ # <- Use the same task description you used in your dataset recording
  --dataset.repo_id=HF_USER/dataset_name \\  # <- This will be the dataset name on HF Hub
  --dataset.episode_time_s=50 \\
  --dataset.num_episodes=10 \\
  --policy.path=${e.id}`),t}return[]}},liveportrait:{prettyLabel:"LivePortrait",repoName:"LivePortrait",repoUrl:"https://github.com/KwaiVGI/LivePortrait",filter:!1,countDownloads:'path:"liveportrait/landmark.onnx"'},"llama-cpp-python":{prettyLabel:"llama-cpp-python",repoName:"llama-cpp-python",repoUrl:"https://github.com/abetlen/llama-cpp-python",snippets:e=>{let t=[`# !pip install llama-cpp-python

from llama_cpp import Llama

llm = Llama.from_pretrained(
	repo_id="${e.id}",
	filename="{{GGUF_FILE}}",
)
`];if(e.tags.includes("conversational")){var n;let r,a=rk(e);t.push(`llm.create_chat_completion(
	messages = ${(n={attributeKeyQuotes:!0,indent:"	"},r=JSON.stringify(a,null,"	"),n?.indent&&(r=r.replaceAll("\n",`
${n.indent}`)),n?.attributeKeyQuotes||(r=r.replace(/"([^"]+)":/g,"$1:")),n?.customContentEscaper&&(r=n.customContentEscaper(r)),r)}
)`)}else t.push(`output = llm(
	"Once upon a time,",
	max_tokens=512,
	echo=True
)
print(output)`);return t}},"mini-omni2":{prettyLabel:"Mini-Omni2",repoName:"Mini-Omni2",repoUrl:"https://github.com/gpt-omni/mini-omni2",countDownloads:'path:"model_config.yaml"'},mindspore:{prettyLabel:"MindSpore",repoName:"mindspore",repoUrl:"https://github.com/mindspore-ai/mindspore"},"magi-1":{prettyLabel:"MAGI-1",repoName:"MAGI-1",repoUrl:"https://github.com/SandAI-org/MAGI-1",countDownloads:'path:"ckpt/vae/config.json"'},"magenta-realtime":{prettyLabel:"Magenta RT",repoName:"Magenta RT",repoUrl:"https://github.com/magenta/magenta-realtime",countDownloads:'path:"checkpoints/llm_base_x4286_c1860k.tar" OR path:"checkpoints/llm_large_x3047_c1860k.tar" OR path:"checkpoints/llm_large_x3047_c1860k/checkpoint"'},"mamba-ssm":{prettyLabel:"MambaSSM",repoName:"MambaSSM",repoUrl:"https://github.com/state-spaces/mamba",filter:!1,snippets:e=>[`from mamba_ssm import MambaLMHeadModel

model = MambaLMHeadModel.from_pretrained("${e.id}")`]},"mars5-tts":{prettyLabel:"MARS5-TTS",repoName:"MARS5-TTS",repoUrl:"https://github.com/Camb-ai/MARS5-TTS",filter:!1,countDownloads:'path:"mars5_ar.safetensors"',snippets:e=>[`# Install from https://github.com/Camb-ai/MARS5-TTS

from inference import Mars5TTS
mars5 = Mars5TTS.from_pretrained("${e.id}")`]},matanyone:{prettyLabel:"MatAnyone",repoName:"MatAnyone",repoUrl:"https://github.com/pq-yang/MatAnyone",snippets:e=>[`# Install from https://github.com/pq-yang/MatAnyone.git

from matanyone.model.matanyone import MatAnyone
model = MatAnyone.from_pretrained("${e.id}")`,`
from matanyone import InferenceCore
processor = InferenceCore("${e.id}")`],filter:!1},"mesh-anything":{prettyLabel:"MeshAnything",repoName:"MeshAnything",repoUrl:"https://github.com/buaacyw/MeshAnything",filter:!1,countDownloads:'path:"MeshAnything_350m.pth"',snippets:()=>[`# Install from https://github.com/buaacyw/MeshAnything.git

from MeshAnything.models.meshanything import MeshAnything

# refer to https://github.com/buaacyw/MeshAnything/blob/main/main.py#L91 on how to define args
# and https://github.com/buaacyw/MeshAnything/blob/main/app.py regarding usage
model = MeshAnything(args)`]},merlin:{prettyLabel:"Merlin",repoName:"Merlin",repoUrl:"https://github.com/StanfordMIMI/Merlin",filter:!1,countDownloads:'path_extension:"pt"'},medvae:{prettyLabel:"MedVAE",repoName:"MedVAE",repoUrl:"https://github.com/StanfordMIMI/MedVAE",filter:!1,countDownloads:'path_extension:"ckpt"'},mitie:{prettyLabel:"MITIE",repoName:"MITIE",repoUrl:"https://github.com/mit-nlp/MITIE",countDownloads:'path_filename:"total_word_feature_extractor"'},"ml-agents":{prettyLabel:"ml-agents",repoName:"ml-agents",repoUrl:"https://github.com/Unity-Technologies/ml-agents",docsUrl:"https://huggingface.co/docs/hub/ml-agents",snippets:e=>[`mlagents-load-from-hf --repo-id="${e.id}" --local-dir="./download: string[]s"`],filter:!0,countDownloads:'path_extension:"onnx"'},mlx:{prettyLabel:"MLX",repoName:"MLX",repoUrl:"https://github.com/ml-explore/mlx-examples/tree/main",snippets:e=>{if("image-text-to-text"===e.pipeline_tag)return[`# Make sure mlx-vlm is installed
# pip install --upgrade mlx-vlm

from mlx_vlm import load, generate
from mlx_vlm.prompt_utils import apply_chat_template
from mlx_vlm.utils import load_config

# Load the model
model, processor = load("${e.id}")
config = load_config("${e.id}")

# Prepare input
image = ["http://images.cocodataset.org/val2017/000000039769.jpg"]
prompt = "Describe this image."

# Apply chat template
formatted_prompt = apply_chat_template(
    processor, config, prompt, num_images=1
)

# Generate output
output = generate(model, processor, formatted_prompt, image)
print(output)`];if("text-generation"===e.pipeline_tag)if(e.tags.includes("conversational"))return[`# Make sure mlx-lm is installed
# pip install --upgrade mlx-lm

# Generate text with mlx-lm
from mlx_lm import load, generate

model, tokenizer = load("${e.id}")

prompt = "Write a story about Einstein"
messages = [{"role": "user", "content": prompt}]
prompt = tokenizer.apply_chat_template(
    messages, add_generation_prompt=True
)

text = generate(model, tokenizer, prompt=prompt, verbose=True)`];else return[`# Make sure mlx-lm is installed
# pip install --upgrade mlx-lm

# Generate text with mlx-lm
from mlx_lm import load, generate

model, tokenizer = load("${e.id}")

prompt = "Once upon a time in"
text = generate(model, tokenizer, prompt=prompt, verbose=True)`];return[`# Download the model from the Hub
pip install huggingface_hub[hf_xet]

huggingface-cli download --local-dir ${rS(e.id)} ${e.id}`]},filter:!0},"mlx-image":{prettyLabel:"mlx-image",repoName:"mlx-image",repoUrl:"https://github.com/riccardomusmeci/mlx-image",docsUrl:"https://huggingface.co/docs/hub/mlx-image",snippets:e=>[`from mlxim.model import create_model

model = create_model(${e.id})`],filter:!1,countDownloads:'path:"model.safetensors"'},"mlc-llm":{prettyLabel:"MLC-LLM",repoName:"MLC-LLM",repoUrl:"https://github.com/mlc-ai/mlc-llm",docsUrl:"https://llm.mlc.ai/docs/",filter:!1,countDownloads:'path:"mlc-chat-config.json"'},model2vec:{prettyLabel:"Model2Vec",repoName:"model2vec",repoUrl:"https://github.com/MinishLab/model2vec",snippets:e=>[`from model2vec import StaticModel

model = StaticModel.from_pretrained("${e.id}")`],filter:!1},moshi:{prettyLabel:"Moshi",repoName:"Moshi",repoUrl:"https://github.com/kyutai-labs/moshi",filter:!1,countDownloads:'path:"tokenizer-e351c8d8-checkpoint125.safetensors"'},mtvcraft:{prettyLabel:"MTVCraft",repoName:"MTVCraft",repoUrl:"https://github.com/baaivision/MTVCraft",filter:!1,countDownloads:'path:"vae/3d-vae.pt"'},nemo:{prettyLabel:"NeMo",repoName:"NeMo",repoUrl:"https://github.com/NVIDIA/NeMo",snippets:e=>{let t;return e.tags.includes("automatic-speech-recognition")&&(t=[`import nemo.collections.asr as nemo_asr
asr_model = nemo_asr.models.ASRModel.from_pretrained("${e.id}")

transcriptions = asr_model.transcribe(["file.wav"])`]),t??["# tag did not correspond to a valid NeMo domain."]},filter:!0,countDownloads:'path_extension:"nemo" OR path:"model_config.yaml"'},"open-oasis":{prettyLabel:"open-oasis",repoName:"open-oasis",repoUrl:"https://github.com/etched-ai/open-oasis",countDownloads:'path:"oasis500m.safetensors"'},open_clip:{prettyLabel:"OpenCLIP",repoName:"OpenCLIP",repoUrl:"https://github.com/mlfoundations/open_clip",snippets:e=>[`import open_clip

model, preprocess_train, preprocess_val = open_clip.create_model_and_transforms('hf-hub:${e.id}')
tokenizer = open_clip.get_tokenizer('hf-hub:${e.id}')`],filter:!0,countDownloads:`path:"open_clip_model.safetensors"
			OR path:"model.safetensors"
			OR path:"open_clip_pytorch_model.bin"
			OR path:"pytorch_model.bin"`},"open-sora":{prettyLabel:"Open-Sora",repoName:"Open-Sora",repoUrl:"https://github.com/hpcaitech/Open-Sora",filter:!1,countDownloads:'path:"Open_Sora_v2.safetensors"'},outetts:{prettyLabel:"OuteTTS",repoName:"OuteTTS",repoUrl:"https://github.com/edwko/OuteTTS",snippets:e=>{let t=e.tags??[];return t.includes("gguf")||t.includes("onnx")?[]:[`
  import outetts
  
  enum = outetts.Models("${e.id}".split("/", 1)[1])       # VERSION_1_0_SIZE_1B
  cfg  = outetts.ModelConfig.auto_config(enum, outetts.Backend.HF)
  tts  = outetts.Interface(cfg)
  
  speaker = tts.load_default_speaker("EN-FEMALE-1-NEUTRAL")
  tts.generate(
	  outetts.GenerationConfig(
		  text="Hello there, how are you doing?",
		  speaker=speaker,
	  )
  ).save("output.wav")
  `]},filter:!1},paddlenlp:{prettyLabel:"paddlenlp",repoName:"PaddleNLP",repoUrl:"https://github.com/PaddlePaddle/PaddleNLP",docsUrl:"https://huggingface.co/docs/hub/paddlenlp",snippets:e=>{if(!e.config?.architectures?.[0])return[`# \u{26A0}\u{FE0F} Type of model unknown
from paddlenlp.transformers import AutoTokenizer, AutoModel

tokenizer = AutoTokenizer.from_pretrained("${e.id}", from_hf_hub=True)
model = AutoModel.from_pretrained("${e.id}", from_hf_hub=True)`];{let t=e.config.architectures[0];return[`from paddlenlp.transformers import AutoTokenizer, ${t}

tokenizer = AutoTokenizer.from_pretrained("${e.id}", from_hf_hub=True)
model = ${t}.from_pretrained("${e.id}", from_hf_hub=True)`]}},filter:!0,countDownloads:'path:"model_config.json"'},PaddleOCR:{prettyLabel:"PaddleOCR",repoName:"PaddleOCR",repoUrl:"https://github.com/PaddlePaddle/PaddleOCR",snippets:e=>{let t={textline_detection:{className:"TextDetection"},textline_recognition:{className:"TextRecognition"},seal_text_detection:{className:"SealTextDetection"},doc_img_unwarping:{className:"TextImageUnwarping"},doc_img_orientation_classification:{className:"DocImgOrientationClassification"},textline_orientation_classification:{className:"TextLineOrientationClassification"},chart_parsing:{className:"ChartParsing"},formula_recognition:{className:"FormulaRecognition"},layout_detection:{className:"LayoutDetection"},table_cells_detection:{className:"TableCellsDetection"},wired_table_classification:{className:"TableClassification"},table_structure_recognition:{className:"TableStructureRecognition"}};if(e.tags.includes("doc_vlm"))return[`# pip install paddleocr
from paddleocr import DocVLM
model = DocVLM(model_name="${e.id}")
output = model.predict(
    input={"image": "path/to/image.png", "query": "Parsing this image and output the content in Markdown format."},
    batch_size=1
)
for res in output:
    res.print()
    res.save_to_img(save_path="./output/")
    res.save_to_json(save_path="./output/res.json")`];for(let n of e.tags)if(n in t){let{className:r}=t[n];return[`# pip install paddleocr
from paddleocr import ${r}
model = ${r}(model_name="${e.id}")
output = model.predict(input="path/to/image.png", batch_size=1)
for res in output:
    res.print()
    res.save_to_img(save_path="./output/")
    res.save_to_json(save_path="./output/res.json")`]}return[`# Please refer to the document for information on how to use the model. 
# https://paddlepaddle.github.io/PaddleOCR/latest/en/version3.x/module_usage/module_overview.html`]},filter:!0},peft:{prettyLabel:"PEFT",repoName:"PEFT",repoUrl:"https://github.com/huggingface/peft",snippets:e=>{let{base_model_name_or_path:t,task_type:n}=e.config?.peft??{},r=(e=>{switch(e){case"CAUSAL_LM":return"CausalLM";case"SEQ_2_SEQ_LM":return"Seq2SeqLM";case"TOKEN_CLS":return"TokenClassification";case"SEQ_CLS":return"SequenceClassification";default:return}})(n);return r?t?[`from peft import PeftModel
from transformers import AutoModelFor${r}

base_model = AutoModelFor${r}.from_pretrained("${t}")
model = PeftModel.from_pretrained(base_model, "${e.id}")`]:["Base model is not found."]:["Task type is invalid."]},filter:!0,countDownloads:'path:"adapter_config.json"'},"perception-encoder":{prettyLabel:"PerceptionEncoder",repoName:"PerceptionModels",repoUrl:"https://github.com/facebookresearch/perception_models",filter:!1,snippets:e=>{let t=`# Use PE-Core models as CLIP models
import core.vision_encoder.pe as pe

model = pe.CLIP.from_config("${e.id}", pretrained=True)`,n=`# Use any PE model as a vision encoder
import core.vision_encoder.pe as pe

model = pe.VisionTransformer.from_config("${e.id}", pretrained=True)`;return e.id.includes("Core")?[t,n]:[n]},countDownloads:'path_extension:"pt"'},"phantom-wan":{prettyLabel:"Phantom",repoName:"Phantom",repoUrl:"https://github.com/Phantom-video/Phantom",snippets:e=>[`from huggingface_hub import snapshot_download
from phantom_wan import WANI2V, configs

checkpoint_dir = snapshot_download("${e.id}")
wan_i2v = WanI2V(
            config=configs.WAN_CONFIGS['i2v-14B'],
            checkpoint_dir=checkpoint_dir,
        )
 video = wan_i2v.generate(text_prompt, image_prompt)`],filter:!1,countDownloads:'path_extension:"pth"'},pxia:{prettyLabel:"pxia",repoName:"pxia",repoUrl:"https://github.com/not-lain/pxia",snippets:e=>[`from pxia import AutoModel

model = AutoModel.from_pretrained("${e.id}")`],filter:!1},"pyannote-audio":{prettyLabel:"pyannote.audio",repoName:"pyannote-audio",repoUrl:"https://github.com/pyannote/pyannote-audio",snippets:e=>{if(e.tags.includes("pyannote-audio-pipeline"))return[`from pyannote.audio import Pipeline
  
pipeline = Pipeline.from_pretrained("${e.id}")

# inference on the whole file
pipeline("file.wav")

# inference on an excerpt
from pyannote.core import Segment
excerpt = Segment(start=2.0, end=5.0)

from pyannote.audio import Audio
waveform, sample_rate = Audio().crop("file.wav", excerpt)
pipeline({"waveform": waveform, "sample_rate": sample_rate})`];return[`from pyannote.audio import Model, Inference

model = Model.from_pretrained("${e.id}")
inference = Inference(model)

# inference on the whole file
inference("file.wav")

# inference on an excerpt
from pyannote.core import Segment
excerpt = Segment(start=2.0, end=5.0)
inference.crop("file.wav", excerpt)`]},filter:!0},"py-feat":{prettyLabel:"Py-Feat",repoName:"Py-Feat",repoUrl:"https://github.com/cosanlab/py-feat",docsUrl:"https://py-feat.org/",filter:!1},pythae:{prettyLabel:"pythae",repoName:"pythae",repoUrl:"https://github.com/clementchadebec/benchmark_VAE",snippets:e=>[`from pythae.models import AutoModel

model = AutoModel.load_from_hf_hub("${e.id}")`],filter:!1},recurrentgemma:{prettyLabel:"RecurrentGemma",repoName:"recurrentgemma",repoUrl:"https://github.com/google-deepmind/recurrentgemma",filter:!1,countDownloads:'path:"tokenizer.model"'},relik:{prettyLabel:"Relik",repoName:"Relik",repoUrl:"https://github.com/SapienzaNLP/relik",snippets:e=>[`from relik import Relik
 
relik = Relik.from_pretrained("${e.id}")`],filter:!1},refiners:{prettyLabel:"Refiners",repoName:"Refiners",repoUrl:"https://github.com/finegrain-ai/refiners",docsUrl:"https://refine.rs/",filter:!1,countDownloads:'path:"model.safetensors"'},renderformer:{prettyLabel:"RenderFormer",repoName:"RenderFormer",repoUrl:"https://github.com/microsoft/renderformer",snippets:e=>[`# Install from https://github.com/microsoft/renderformer

from renderformer import RenderFormerRenderingPipeline
pipeline = RenderFormerRenderingPipeline.from_pretrained("${e.id}")`],filter:!1},reverb:{prettyLabel:"Reverb",repoName:"Reverb",repoUrl:"https://github.com/revdotcom/reverb",filter:!1},saelens:{prettyLabel:"SAELens",repoName:"SAELens",repoUrl:"https://github.com/jbloomAus/SAELens",snippets:()=>[`# pip install sae-lens
from sae_lens import SAE

sae, cfg_dict, sparsity = SAE.from_pretrained(
    release = "RELEASE_ID", # e.g., "gpt2-small-res-jb". See other options in https://github.com/jbloomAus/SAELens/blob/main/sae_lens/pretrained_saes.yaml
    sae_id = "SAE_ID", # e.g., "blocks.8.hook_resid_pre". Won't always be a hook point
)`],filter:!1},sam2:{prettyLabel:"sam2",repoName:"sam2",repoUrl:"https://github.com/facebookresearch/segment-anything-2",filter:!1,snippets:e=>[`# Use SAM2 with images
import torch
from sam2.sam2_image_predictor import SAM2ImagePredictor

predictor = SAM2ImagePredictor.from_pretrained(${e.id})

with torch.inference_mode(), torch.autocast("cuda", dtype=torch.bfloat16):
    predictor.set_image(<your_image>)
    masks, _, _ = predictor.predict(<input_prompts>)`,`# Use SAM2 with videos
import torch
from sam2.sam2_video_predictor import SAM2VideoPredictor
	
predictor = SAM2VideoPredictor.from_pretrained(${e.id})

with torch.inference_mode(), torch.autocast("cuda", dtype=torch.bfloat16):
    state = predictor.init_state(<your_video>)

    # add new prompts and instantly get the output on the same frame
    frame_idx, object_ids, masks = predictor.add_new_points(state, <your_prompts>):

    # propagate the prompts to get masklets throughout the video
    for frame_idx, object_ids, masks in predictor.propagate_in_video(state):
        ...`],countDownloads:'path_extension:"pt"'},"sample-factory":{prettyLabel:"sample-factory",repoName:"sample-factory",repoUrl:"https://github.com/alex-petrenko/sample-factory",docsUrl:"https://huggingface.co/docs/hub/sample-factory",snippets:e=>[`python -m sample_factory.huggingface.load_from_hub -r ${e.id} -d ./train_dir`],filter:!0,countDownloads:'path:"cfg.json"'},sapiens:{prettyLabel:"sapiens",repoName:"sapiens",repoUrl:"https://github.com/facebookresearch/sapiens",filter:!1,countDownloads:'path_extension:"pt2" OR path_extension:"pth" OR path_extension:"onnx"'},seedvr:{prettyLabel:"SeedVR",repoName:"SeedVR",repoUrl:"https://github.com/ByteDance-Seed/SeedVR",filter:!1,countDownloads:'path_extension:"pth"'},"sentence-transformers":{prettyLabel:"sentence-transformers",repoName:"sentence-transformers",repoUrl:"https://github.com/UKPLab/sentence-transformers",docsUrl:"https://huggingface.co/docs/hub/sentence-transformers",snippets:e=>{let t=e.tags.includes(rx)?", trust_remote_code=True":"";if(e.tags.includes("cross-encoder")||"text-ranking"==e.pipeline_tag)return[`from sentence_transformers import CrossEncoder

model = CrossEncoder("${e.id}"${t})

query = "Which planet is known as the Red Planet?"
passages = [
	"Venus is often called Earth's twin because of its similar size and proximity.",
	"Mars, known for its reddish appearance, is often referred to as the Red Planet.",
	"Jupiter, the largest planet in our solar system, has a prominent red spot.",
	"Saturn, famous for its rings, is sometimes mistaken for the Red Planet."
]

scores = model.predict([(query, passage) for passage in passages])
print(scores)`];let n=function(e){let t=e.widgetData?.[0];if(t?.source_sentence&&t?.sentences?.length)return[t.source_sentence,...t.sentences]}(e)??["The weather is lovely today.","It's so sunny outside!","He drove to the stadium."];return[`from sentence_transformers import SentenceTransformer

model = SentenceTransformer("${e.id}"${t})

sentences = ${JSON.stringify(n,null,4)}
embeddings = model.encode(sentences)

similarities = model.similarity(embeddings, embeddings)
print(similarities.shape)
# [${n.length}, ${n.length}]`]},filter:!0},setfit:{prettyLabel:"setfit",repoName:"setfit",repoUrl:"https://github.com/huggingface/setfit",docsUrl:"https://huggingface.co/docs/hub/setfit",snippets:e=>[`from setfit import SetFitModel

model = SetFitModel.from_pretrained("${e.id}")`],filter:!0},sklearn:{prettyLabel:"Scikit-learn",repoName:"Scikit-learn",repoUrl:"https://github.com/scikit-learn/scikit-learn",snippets:e=>{if(e.tags.includes("skops")){let t=e.config?.sklearn?.model?.file,n=e.config?.sklearn?.model_format;if(!t)return[`# \u{26A0}\u{FE0F} Model filename not specified in config.json`];if("pickle"===n)return[`import joblib
from skops.hub_utils import download
download("${e.id}", "path_to_folder")
model = joblib.load(
	"${t}"
)
# only load pickle files from sources you trust
# read more about it here https://skops.readthedocs.io/en/stable/persistence.html`];return[`from skops.hub_utils import download
from skops.io import load
download("${e.id}", "path_to_folder")
# make sure model file is in skops format
# if model is a pickle file, make sure it's from a source you trust
model = load("path_to_folder/${t}")`]}return[`from huggingface_hub import hf_hub_download
import joblib
model = joblib.load(
	hf_hub_download("${e.id}", "sklearn_model.joblib")
)
# only load pickle files from sources you trust
# read more about it here https://skops.readthedocs.io/en/stable/persistence.html`]},filter:!0,countDownloads:'path:"sklearn_model.joblib"'},spacy:{prettyLabel:"spaCy",repoName:"spaCy",repoUrl:"https://github.com/explosion/spaCy",docsUrl:"https://huggingface.co/docs/hub/spacy",snippets:e=>[`!pip install https://huggingface.co/${e.id}/resolve/main/${rS(e.id)}-any-py3-none-any.whl

# Using spacy.load().
import spacy
nlp = spacy.load("${rS(e.id)}")

# Importing as module.
import ${rS(e.id)}
nlp = ${rS(e.id)}.load()`],filter:!0,countDownloads:'path_extension:"whl"'},"span-marker":{prettyLabel:"SpanMarker",repoName:"SpanMarkerNER",repoUrl:"https://github.com/tomaarsen/SpanMarkerNER",docsUrl:"https://huggingface.co/docs/hub/span_marker",snippets:e=>[`from span_marker import SpanMarkerModel

model = SpanMarkerModel.from_pretrained("${e.id}")`],filter:!0},speechbrain:{prettyLabel:"speechbrain",repoName:"speechbrain",repoUrl:"https://github.com/speechbrain/speechbrain",docsUrl:"https://huggingface.co/docs/hub/speechbrain",snippets:e=>{let t=e.config?.speechbrain?.speechbrain_interface;if(void 0===t)return["# interface not specified in config.json"];let n=(e=>{switch(e){case"EncoderClassifier":return"classify_file";case"EncoderDecoderASR":case"EncoderASR":return"transcribe_file";case"SpectralMaskEnhancement":return"enhance_file";case"SepformerSeparation":return"separate_file";default:return}})(t);return void 0===n?["# interface in config.json invalid"]:[`from speechbrain.pretrained import ${t}
model = ${t}.from_hparams(
  "${e.id}"
)
model.${n}("file.wav")`]},filter:!0,countDownloads:'path:"hyperparams.yaml"'},"ssr-speech":{prettyLabel:"SSR-Speech",repoName:"SSR-Speech",repoUrl:"https://github.com/WangHelin1997/SSR-Speech",filter:!1,countDownloads:'path_extension:".pth"'},"stable-audio-tools":{prettyLabel:"Stable Audio Tools",repoName:"stable-audio-tools",repoUrl:"https://github.com/Stability-AI/stable-audio-tools.git",filter:!1,countDownloads:'path:"model.safetensors"',snippets:e=>[`import torch
import torchaudio
from einops import rearrange
from stable_audio_tools import get_pretrained_model
from stable_audio_tools.inference.generation import generate_diffusion_cond

device = "cuda" if torch.cuda.is_available() else "cpu"

# Download model
model, model_config = get_pretrained_model("${e.id}")
sample_rate = model_config["sample_rate"]
sample_size = model_config["sample_size"]

model = model.to(device)

# Set up text and timing conditioning
conditioning = [{
	"prompt": "128 BPM tech house drum loop",
}]

# Generate stereo audio
output = generate_diffusion_cond(
	model,
	conditioning=conditioning,
	sample_size=sample_size,
	device=device
)

# Rearrange audio batch to a single sequence
output = rearrange(output, "b d n -> d (b n)")

# Peak normalize, clip, convert to int16, and save to file
output = output.to(torch.float32).div(torch.max(torch.abs(output))).clamp(-1, 1).mul(32767).to(torch.int16).cpu()
torchaudio.save("output.wav", output, sample_rate)`]},monkeyocr:{prettyLabel:"MonkeyOCR",repoName:"monkeyocr",repoUrl:"https://github.com/Yuliang-Liu/MonkeyOCR",filter:!1,countDownloads:'path:"Recognition/config.json"'},"diffusion-single-file":{prettyLabel:"Diffusion Single File",repoName:"diffusion-single-file",repoUrl:"https://github.com/comfyanonymous/ComfyUI",filter:!1,countDownloads:'path_extension:"safetensors"'},"seed-story":{prettyLabel:"SEED-Story",repoName:"SEED-Story",repoUrl:"https://github.com/TencentARC/SEED-Story",filter:!1,countDownloads:'path:"cvlm_llama2_tokenizer/tokenizer.model"',snippets:()=>[`# seed_story_cfg_path refers to 'https://github.com/TencentARC/SEED-Story/blob/master/configs/clm_models/agent_7b_sft.yaml'
# llm_cfg_path refers to 'https://github.com/TencentARC/SEED-Story/blob/master/configs/clm_models/llama2chat7b_lora.yaml'
from omegaconf import OmegaConf
import hydra

# load Llama2
llm_cfg = OmegaConf.load(llm_cfg_path)
llm = hydra.utils.instantiate(llm_cfg, torch_dtype="fp16")

# initialize seed_story
seed_story_cfg = OmegaConf.load(seed_story_cfg_path)
seed_story = hydra.utils.instantiate(seed_story_cfg, llm=llm) `]},soloaudio:{prettyLabel:"SoloAudio",repoName:"SoloAudio",repoUrl:"https://github.com/WangHelin1997/SoloAudio",filter:!1,countDownloads:'path:"soloaudio_v2.pt"'},songbloom:{prettyLabel:"SongBloom",repoName:"SongBloom",repoUrl:"https://github.com/Cypress-Yang/SongBloom",filter:!1,countDownloads:'path_extension:"pt"'},"stable-baselines3":{prettyLabel:"stable-baselines3",repoName:"stable-baselines3",repoUrl:"https://github.com/huggingface/huggingface_sb3",docsUrl:"https://huggingface.co/docs/hub/stable-baselines3",snippets:e=>[`from huggingface_sb3 import load_from_hub
checkpoint = load_from_hub(
	repo_id="${e.id}",
	filename="{MODEL FILENAME}.zip",
)`],filter:!0,countDownloads:'path_extension:"zip"'},stanza:{prettyLabel:"Stanza",repoName:"stanza",repoUrl:"https://github.com/stanfordnlp/stanza",docsUrl:"https://huggingface.co/docs/hub/stanza",snippets:e=>[`import stanza

stanza.download("${rS(e.id).replace("stanza-","")}")
nlp = stanza.Pipeline("${rS(e.id).replace("stanza-","")}")`],filter:!0,countDownloads:'path:"models/default.zip"'},swarmformer:{prettyLabel:"SwarmFormer",repoName:"SwarmFormer",repoUrl:"https://github.com/takara-ai/SwarmFormer",snippets:e=>[`from swarmformer import SwarmFormerModel

model = SwarmFormerModel.from_pretrained("${e.id}")
`],filter:!1},"f5-tts":{prettyLabel:"F5-TTS",repoName:"F5-TTS",repoUrl:"https://github.com/SWivid/F5-TTS",filter:!1,countDownloads:'path_extension:"safetensors" OR path_extension:"pt"'},genmo:{prettyLabel:"Genmo",repoName:"Genmo",repoUrl:"https://github.com/genmoai/models",filter:!1,countDownloads:'path:"vae_stats.json"'},"tencent-song-generation":{prettyLabel:"SongGeneration",repoName:"SongGeneration",repoUrl:"https://github.com/tencent-ailab/songgeneration",filter:!1,countDownloads:'path:"ckpt/songgeneration_base/model.pt"'},tensorflowtts:{prettyLabel:"TensorFlowTTS",repoName:"TensorFlowTTS",repoUrl:"https://github.com/TensorSpeech/TensorFlowTTS",snippets:e=>{if(e.tags.includes("text-to-mel"))return[`from tensorflow_tts.inference import AutoProcessor, TFAutoModel

processor = AutoProcessor.from_pretrained("${e.id}")
model = TFAutoModel.from_pretrained("${e.id}")
`];if(e.tags.includes("mel-to-wav"))return[`from tensorflow_tts.inference import TFAutoModel

model = TFAutoModel.from_pretrained("${e.id}")
audios = model.inference(mels)
`];return[`from tensorflow_tts.inference import TFAutoModel

model = TFAutoModel.from_pretrained("${e.id}")
`]}},tabpfn:{prettyLabel:"TabPFN",repoName:"TabPFN",repoUrl:"https://github.com/PriorLabs/TabPFN"},terratorch:{prettyLabel:"TerraTorch",repoName:"TerraTorch",repoUrl:"https://github.com/IBM/terratorch",docsUrl:"https://ibm.github.io/terratorch/",filter:!1,countDownloads:'path_extension:"pt"',snippets:e=>[`from terratorch.registry import BACKBONE_REGISTRY

model = BACKBONE_REGISTRY.build("${e.id}")`]},"tic-clip":{prettyLabel:"TiC-CLIP",repoName:"TiC-CLIP",repoUrl:"https://github.com/apple/ml-tic-clip",filter:!1,countDownloads:'path_extension:"pt" AND path_prefix:"checkpoints/"'},timesfm:{prettyLabel:"TimesFM",repoName:"timesfm",repoUrl:"https://github.com/google-research/timesfm",filter:!1,countDownloads:'path:"checkpoints/checkpoint_1100000/state/checkpoint" OR path:"checkpoints/checkpoint_2150000/state/checkpoint" OR path_extension:"ckpt"'},timm:{prettyLabel:"timm",repoName:"pytorch-image-models",repoUrl:"https://github.com/rwightman/pytorch-image-models",docsUrl:"https://huggingface.co/docs/hub/timm",snippets:e=>[`import timm

model = timm.create_model("hf_hub:${e.id}", pretrained=True)`],filter:!0,countDownloads:'path:"pytorch_model.bin" OR path:"model.safetensors"'},tirex:{prettyLabel:"TiRex",repoName:"TiRex",repoUrl:"https://github.com/NX-AI/tirex",countDownloads:'path_extension:"ckpt"'},torchgeo:{prettyLabel:"TorchGeo",repoName:"TorchGeo",repoUrl:"https://github.com/microsoft/torchgeo",docsUrl:"https://torchgeo.readthedocs.io/",filter:!1,countDownloads:'path_extension:"pt" OR path_extension:"pth"'},transformers:{prettyLabel:"Transformers",repoName:"\uD83E\uDD17/transformers",repoUrl:"https://github.com/huggingface/transformers",docsUrl:"https://huggingface.co/docs/hub/transformers",snippets:e=>{let t=e.transformersInfo;if(!t)return[`# \u{26A0}\u{FE0F} Type of model unknown`];let n=e.tags.includes(rx)?", trust_remote_code=True":"",r=[];if(t.processor){let a="AutoTokenizer"===t.processor?"tokenizer":"AutoFeatureExtractor"===t.processor?"extractor":"processor";r.push("# Load model directly",`from transformers import ${t.processor}, ${t.auto_model}`,"",`${a} = ${t.processor}.from_pretrained("${e.id}"`+n+")",`model = ${t.auto_model}.from_pretrained("${e.id}"`+n+")"),e.tags.includes("conversational")&&(e.tags.includes("image-text-to-text")?r.push("messages = [",'    {\n        "role": "user",\n        "content": [\n            {"type": "image", "url": "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/p-blog/candy.JPG"},\n            {"type": "text", "text": "What animal is on the candy?"}\n        ]\n    },',"]"):r.push("messages = [",'    {"role": "user", "content": "Who are you?"},',"]"),r.push(`inputs = ${a}.apply_chat_template(`,"	messages,","	add_generation_prompt=True,","	tokenize=True,","	return_dict=True,",'	return_tensors="pt",',").to(model.device)","","outputs = model.generate(**inputs, max_new_tokens=40)",`print(${a}.decode(outputs[0][inputs["input_ids"].shape[-1]:]))`))}else r.push("# Load model directly",`from transformers import ${t.auto_model}`,`model = ${t.auto_model}.from_pretrained("${e.id}"`+n+', torch_dtype="auto"),');if(e.pipeline_tag&&n8?.includes(e.pipeline_tag)){let t=["# Use a pipeline as a high-level helper","from transformers import pipeline","",`pipe = pipeline("${e.pipeline_tag}", model="${e.id}"`+n+")"];return e.tags.includes("conversational")?e.tags.includes("image-text-to-text")?(t.push("messages = [",'    {\n        "role": "user",\n        "content": [\n            {"type": "image", "url": "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/p-blog/candy.JPG"},\n            {"type": "text", "text": "What animal is on the candy?"}\n        ]\n    },',"]"),t.push("pipe(text=messages)")):(t.push("messages = [",'    {"role": "user", "content": "Who are you?"},',"]"),t.push("pipe(messages)")):"zero-shot-image-classification"===e.pipeline_tag?t.push("pipe(",'    "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/parrots.png",','    candidate_labels=["animals", "humans", "landscape"],',")"):"image-classification"===e.pipeline_tag&&t.push('pipe("https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/parrots.png")'),[t.join("\n"),r.join("\n")]}return[r.join("\n")]},filter:!0},"transformers.js":{prettyLabel:"Transformers.js",repoName:"transformers.js",repoUrl:"https://github.com/huggingface/transformers.js",docsUrl:"https://huggingface.co/docs/hub/transformers-js",snippets:e=>{if(!e.pipeline_tag)return[`// \u{26A0}\u{FE0F} Unknown pipeline tag`];let t="@huggingface/transformers";return[`// npm i ${t}
import { pipeline } from '${t}';

// Allocate pipeline
const pipe = await pipeline('${e.pipeline_tag}', '${e.id}');`]},filter:!0},trellis:{prettyLabel:"Trellis",repoName:"Trellis",repoUrl:"https://github.com/microsoft/TRELLIS",countDownloads:'path_extension:"safetensors"'},ultralytics:{prettyLabel:"ultralytics",repoName:"ultralytics",repoUrl:"https://github.com/ultralytics/ultralytics",docsUrl:"https://github.com/ultralytics/ultralytics",filter:!1,countDownloads:'path_extension:"pt"',snippets:rR},univa:{prettyLabel:"univa",repoName:"univa",repoUrl:"https://github.com/PKU-YuanGroup/UniWorld-V1",snippets:e=>[`# Follow installation instructions at https://github.com/PKU-YuanGroup/UniWorld-V1

from univa.models.qwen2p5vl.modeling_univa_qwen2p5vl import UnivaQwen2p5VLForConditionalGeneration
	model = UnivaQwen2p5VLForConditionalGeneration.from_pretrained(
        "${e.id}",
        torch_dtype=torch.bfloat16,
        attn_implementation="flash_attention_2",
    ).to("cuda")
	processor = AutoProcessor.from_pretrained("${e.id}")
`],filter:!0,countDownloads:'path:"config.json"'},"uni-3dar":{prettyLabel:"Uni-3DAR",repoName:"Uni-3DAR",repoUrl:"https://github.com/dptech-corp/Uni-3DAR",docsUrl:"https://github.com/dptech-corp/Uni-3DAR",countDownloads:'path_extension:"pt"'},"unity-sentis":{prettyLabel:"unity-sentis",repoName:"unity-sentis",repoUrl:"https://github.com/Unity-Technologies/sentis-samples",snippets:()=>[`string modelName = "[Your model name here].sentis";
Model model = ModelLoader.Load(Application.streamingAssetsPath + "/" + modelName);
IWorker engine = WorkerFactory.CreateWorker(BackendType.GPUCompute, model);
// Please see provided C# file for more details
`],filter:!0,countDownloads:'path_extension:"sentis"'},sana:{prettyLabel:"Sana",repoName:"Sana",repoUrl:"https://github.com/NVlabs/Sana",countDownloads:'path_extension:"pth"',snippets:e=>[`
# Load the model and infer image from text
import torch
from app.sana_pipeline import SanaPipeline
from torchvision.utils import save_image

sana = SanaPipeline("configs/sana_config/1024ms/Sana_1600M_img1024.yaml")
sana.from_pretrained("hf://${e.id}")

image = sana(
    prompt='a cyberpunk cat with a neon sign that says "Sana"',
    height=1024,
    width=1024,
    guidance_scale=5.0,
    pag_guidance_scale=2.0,
    num_inference_steps=18,
) `]},videoprism:{prettyLabel:"VideoPrism",repoName:"VideoPrism",repoUrl:"https://github.com/google-deepmind/videoprism",countDownloads:'path_extension:"npz"',snippets:e=>[`# Install from https://github.com/google-deepmind/videoprism
import jax
from videoprism import models as vp

flax_model = vp.get_model("${e.id}")
loaded_state = vp.load_pretrained_weights("${e.id}")

@jax.jit
def forward_fn(inputs, train=False):
  return flax_model.apply(loaded_state, inputs, train=train)`]},"vfi-mamba":{prettyLabel:"VFIMamba",repoName:"VFIMamba",repoUrl:"https://github.com/MCG-NJU/VFIMamba",countDownloads:'path_extension:"pkl"',snippets:e=>[`from Trainer_finetune import Model

model = Model.from_pretrained("${e.id}")`]},voicecraft:{prettyLabel:"VoiceCraft",repoName:"VoiceCraft",repoUrl:"https://github.com/jasonppy/VoiceCraft",docsUrl:"https://github.com/jasonppy/VoiceCraft",snippets:e=>[`from voicecraft import VoiceCraft

model = VoiceCraft.from_pretrained("${e.id}")`]},vui:{prettyLabel:"Vui",repoName:"Vui",repoUrl:"https://github.com/vui-ai/vui",countDownloads:'path_extension:"pt"',snippets:()=>[`# !pip install git+https://github.com/fluxions-ai/vui

import torchaudio

from vui.inference import render
from vui.model import Vui,

model = Vui.from_pretrained().cuda()
waveform = render(
    model,
    "Hey, here is some random stuff, usually something quite long as the shorter the text the less likely the model can cope!",
)
print(waveform.shape)
torchaudio.save("out.opus", waveform[0], 22050)
`]},wham:{prettyLabel:"WHAM",repoName:"wham",repoUrl:"https://huggingface.co/microsoft/wham",docsUrl:"https://huggingface.co/microsoft/wham/blob/main/README.md",countDownloads:'path_extension:"ckpt"'},whisperkit:{prettyLabel:"WhisperKit",repoName:"WhisperKit",repoUrl:"https://github.com/argmaxinc/WhisperKit",docsUrl:"https://github.com/argmaxinc/WhisperKit?tab=readme-ov-file#homebrew",snippets:()=>[`# Install CLI with Homebrew on macOS device
brew install whisperkit-cli

# View all available inference options
whisperkit-cli transcribe --help
	
# Download and run inference using whisper base model
whisperkit-cli transcribe --audio-path /path/to/audio.mp3

# Or use your preferred model variant
whisperkit-cli transcribe --model "large-v3" --model-prefix "distil" --audio-path /path/to/audio.mp3 --verbose`],countDownloads:'path_filename:"model" AND path_extension:"mil" AND _exists_:"path_prefix"'},yolov10:{prettyLabel:"YOLOv10",repoName:"YOLOv10",repoUrl:"https://github.com/THU-MIG/yolov10",docsUrl:"https://github.com/THU-MIG/yolov10",countDownloads:'path_extension:"pt" OR path_extension:"safetensors"',snippets:rR},zonos:{prettyLabel:"Zonos",repoName:"Zonos",repoUrl:"https://github.com/Zyphra/Zonos",docsUrl:"https://github.com/Zyphra/Zonos",snippets:e=>[`# pip install git+https://github.com/Zyphra/Zonos.git
import torchaudio
from zonos.model import Zonos
from zonos.conditioning import make_cond_dict

model = Zonos.from_pretrained("${e.id}", device="cuda")

wav, sr = torchaudio.load("speaker.wav")           # 5-10s reference clip
speaker = model.make_speaker_embedding(wav, sr)

cond  = make_cond_dict(text="Hello, world!", speaker=speaker, language="en-us")
codes = model.generate(model.prepare_conditioning(cond))

audio = model.autoencoder.decode(codes)[0].cpu()
torchaudio.save("sample.wav", audio, model.autoencoder.sampling_rate)
`],filter:!1},"3dtopia-xl":{prettyLabel:"3DTopia-XL",repoName:"3DTopia-XL",repoUrl:"https://github.com/3DTopia/3DTopia-XL",filter:!1,countDownloads:'path:"model_vae_fp16.pt"',snippets:e=>[`from threedtopia_xl.models import threedtopia_xl

model = threedtopia_xl.from_pretrained("${e.id}")
model.generate(cond="path/to/image.png")`]}};Object.keys(rM),Object.entries(rM).filter(([e,t])=>t.filter).map(([e])=>e),(n=s||(s={}))[n.F32=0]="F32",n[n.F16=1]="F16",n[n.Q4_0=2]="Q4_0",n[n.Q4_1=3]="Q4_1",n[n.Q4_1_SOME_F16=4]="Q4_1_SOME_F16",n[n.Q4_2=5]="Q4_2",n[n.Q4_3=6]="Q4_3",n[n.Q8_0=7]="Q8_0",n[n.Q5_0=8]="Q5_0",n[n.Q5_1=9]="Q5_1",n[n.Q2_K=10]="Q2_K",n[n.Q3_K_S=11]="Q3_K_S",n[n.Q3_K_M=12]="Q3_K_M",n[n.Q3_K_L=13]="Q3_K_L",n[n.Q4_K_S=14]="Q4_K_S",n[n.Q4_K_M=15]="Q4_K_M",n[n.Q5_K_S=16]="Q5_K_S",n[n.Q5_K_M=17]="Q5_K_M",n[n.Q6_K=18]="Q6_K",n[n.IQ2_XXS=19]="IQ2_XXS",n[n.IQ2_XS=20]="IQ2_XS",n[n.Q2_K_S=21]="Q2_K_S",n[n.IQ3_XS=22]="IQ3_XS",n[n.IQ3_XXS=23]="IQ3_XXS",n[n.IQ1_S=24]="IQ1_S",n[n.IQ4_NL=25]="IQ4_NL",n[n.IQ3_S=26]="IQ3_S",n[n.IQ3_M=27]="IQ3_M",n[n.IQ2_S=28]="IQ2_S",n[n.IQ2_M=29]="IQ2_M",n[n.IQ4_XS=30]="IQ4_XS",n[n.IQ1_M=31]="IQ1_M",n[n.BF16=32]="BF16",n[n.Q4_0_4_4=33]="Q4_0_4_4",n[n.Q4_0_4_8=34]="Q4_0_4_8",n[n.Q4_0_8_8=35]="Q4_0_8_8",n[n.TQ1_0=36]="TQ1_0",n[n.TQ2_0=37]="TQ2_0",n[n.Q2_K_XL=1e3]="Q2_K_XL",n[n.Q3_K_XL=1001]="Q3_K_XL",n[n.Q4_K_XL=1002]="Q4_K_XL",n[n.Q5_K_XL=1003]="Q5_K_XL",n[n.Q6_K_XL=1004]="Q6_K_XL",n[n.Q8_K_XL=1005]="Q8_K_XL";const rN=Object.values(s).filter(e=>"string"==typeof e),rU=RegExp(RegExp(`(?<quant>${rN.join("|")})(_(?<sizeVariation>[A-Z]+))?`),"g");s.F32,s.BF16,s.F16,s.Q8_K_XL,s.Q8_0,s.Q6_K_XL,s.Q6_K,s.Q5_K_XL,s.Q5_K_M,s.Q5_K_S,s.Q5_0,s.Q5_1,s.Q4_K_XL,s.Q4_K_M,s.Q4_K_S,s.IQ4_NL,s.IQ4_XS,s.Q4_0_4_4,s.Q4_0_4_8,s.Q4_0_8_8,s.Q4_1_SOME_F16,s.Q4_0,s.Q4_1,s.Q4_2,s.Q4_3,s.Q3_K_XL,s.Q3_K_L,s.Q3_K_M,s.Q3_K_S,s.IQ3_M,s.IQ3_S,s.IQ3_XS,s.IQ3_XXS,s.Q2_K_XL,s.Q2_K,s.Q2_K_S,s.IQ2_M,s.IQ2_S,s.IQ2_XS,s.IQ2_XXS,s.IQ1_S,s.IQ1_M,s.TQ1_0,s.TQ2_0,(r=l||(l={}))[r.F32=0]="F32",r[r.F16=1]="F16",r[r.Q4_0=2]="Q4_0",r[r.Q4_1=3]="Q4_1",r[r.Q5_0=6]="Q5_0",r[r.Q5_1=7]="Q5_1",r[r.Q8_0=8]="Q8_0",r[r.Q8_1=9]="Q8_1",r[r.Q2_K=10]="Q2_K",r[r.Q3_K=11]="Q3_K",r[r.Q4_K=12]="Q4_K",r[r.Q5_K=13]="Q5_K",r[r.Q6_K=14]="Q6_K",r[r.Q8_K=15]="Q8_K",r[r.IQ2_XXS=16]="IQ2_XXS",r[r.IQ2_XS=17]="IQ2_XS",r[r.IQ3_XXS=18]="IQ3_XXS",r[r.IQ1_S=19]="IQ1_S",r[r.IQ4_NL=20]="IQ4_NL",r[r.IQ3_S=21]="IQ3_S",r[r.IQ2_S=22]="IQ2_S",r[r.IQ4_XS=23]="IQ4_XS",r[r.I8=24]="I8",r[r.I16=25]="I16",r[r.I32=26]="I32",r[r.I64=27]="I64",r[r.F64=28]="F64",r[r.IQ1_M=29]="IQ1_M",r[r.BF16=30]="BF16",r[r.TQ1_0=34]="TQ1_0",r[r.TQ2_0=35]="TQ2_0";const rO=["python","js","sh"],r$={js:{fetch:{basic:'async function query(data) {\n	const response = await fetch(\n		"{{ fullUrl }}",\n		{\n			headers: {\n				Authorization: "{{ authorizationHeader }}",\n				"Content-Type": "application/json",\n{% if billTo %}\n				"X-HF-Bill-To": "{{ billTo }}",\n{% endif %}			},\n			method: "POST",\n			body: JSON.stringify(data),\n		}\n	);\n	const result = await response.json();\n	return result;\n}\n\nquery({ inputs: {{ providerInputs.asObj.inputs }} }).then((response) => {\n    console.log(JSON.stringify(response));\n});',basicAudio:'async function query(data) {\n	const response = await fetch(\n		"{{ fullUrl }}",\n		{\n			headers: {\n				Authorization: "{{ authorizationHeader }}",\n				"Content-Type": "audio/flac",\n{% if billTo %}\n				"X-HF-Bill-To": "{{ billTo }}",\n{% endif %}			},\n			method: "POST",\n			body: JSON.stringify(data),\n		}\n	);\n	const result = await response.json();\n	return result;\n}\n\nquery({ inputs: {{ providerInputs.asObj.inputs }} }).then((response) => {\n    console.log(JSON.stringify(response));\n});',basicImage:'async function query(data) {\n	const response = await fetch(\n		"{{ fullUrl }}",\n		{\n			headers: {\n				Authorization: "{{ authorizationHeader }}",\n				"Content-Type": "image/jpeg",\n{% if billTo %}\n				"X-HF-Bill-To": "{{ billTo }}",\n{% endif %}			},\n			method: "POST",\n			body: JSON.stringify(data),\n		}\n	);\n	const result = await response.json();\n	return result;\n}\n\nquery({ inputs: {{ providerInputs.asObj.inputs }} }).then((response) => {\n    console.log(JSON.stringify(response));\n});',conversational:'async function query(data) {\n	const response = await fetch(\n		"{{ fullUrl }}",\n		{\n			headers: {\n				Authorization: "{{ authorizationHeader }}",\n				"Content-Type": "application/json",\n{% if billTo %}\n				"X-HF-Bill-To": "{{ billTo }}",\n{% endif %}			},\n			method: "POST",\n			body: JSON.stringify(data),\n		}\n	);\n	const result = await response.json();\n	return result;\n}\n\nquery({ \n{{ autoInputs.asTsString }}\n}).then((response) => {\n    console.log(JSON.stringify(response));\n});',imageToImage:'const image = fs.readFileSync("{{inputs.asObj.inputs}}");\n\nasync function query(data) {\n	const response = await fetch(\n		"{{ fullUrl }}",\n		{\n			headers: {\n				Authorization: "{{ authorizationHeader }}",\n				"Content-Type": "image/jpeg",\n{% if billTo %}\n				"X-HF-Bill-To": "{{ billTo }}",\n{% endif %}			},\n			method: "POST",\n			body: {\n				"inputs": `data:image/png;base64,${data.inputs.encode("base64")}`,\n				"parameters": data.parameters,\n			}\n		}\n	);\n	const result = await response.json();\n	return result;\n}\n\nquery({ \n	inputs: image,\n	parameters: {\n		prompt: "{{ inputs.asObj.parameters.prompt }}",\n	}\n}).then((response) => {\n    console.log(JSON.stringify(response));\n});',textToAudio:'{% if model.library_name == "transformers" %}\nasync function query(data) {\n	const response = await fetch(\n		"{{ fullUrl }}",\n		{\n			headers: {\n				Authorization: "{{ authorizationHeader }}",\n				"Content-Type": "application/json",\n{% if billTo %}\n				"X-HF-Bill-To": "{{ billTo }}",\n{% endif %}			},\n			method: "POST",\n			body: JSON.stringify(data),\n		}\n	);\n	const result = await response.blob();\n    return result;\n}\n\nquery({ inputs: {{ providerInputs.asObj.inputs }} }).then((response) => {\n    // Returns a byte object of the Audio wavform. Use it directly!\n});\n{% else %}\nasync function query(data) {\n	const response = await fetch(\n		"{{ fullUrl }}",\n		{\n			headers: {\n				Authorization: "{{ authorizationHeader }}",\n				"Content-Type": "application/json",\n			},\n			method: "POST",\n			body: JSON.stringify(data),\n		}\n	);\n    const result = await response.json();\n    return result;\n}\n\nquery({ inputs: {{ providerInputs.asObj.inputs }} }).then((response) => {\n    console.log(JSON.stringify(response));\n});\n{% endif %} ',textToImage:'async function query(data) {\n	const response = await fetch(\n		"{{ fullUrl }}",\n		{\n			headers: {\n				Authorization: "{{ authorizationHeader }}",\n				"Content-Type": "application/json",\n{% if billTo %}\n				"X-HF-Bill-To": "{{ billTo }}",\n{% endif %}			},\n			method: "POST",\n			body: JSON.stringify(data),\n		}\n	);\n	const result = await response.blob();\n	return result;\n}\n\n\nquery({ {{ providerInputs.asTsString }} }).then((response) => {\n    // Use image\n});',textToSpeech:'{% if model.library_name == "transformers" %}\nasync function query(data) {\n	const response = await fetch(\n		"{{ fullUrl }}",\n		{\n			headers: {\n				Authorization: "{{ authorizationHeader }}",\n				"Content-Type": "application/json",\n{% if billTo %}\n				"X-HF-Bill-To": "{{ billTo }}",\n{% endif %}			},\n			method: "POST",\n			body: JSON.stringify(data),\n		}\n	);\n	const result = await response.blob();\n    return result;\n}\n\nquery({ text: {{ inputs.asObj.inputs }} }).then((response) => {\n    // Returns a byte object of the Audio wavform. Use it directly!\n});\n{% else %}\nasync function query(data) {\n	const response = await fetch(\n		"{{ fullUrl }}",\n		{\n			headers: {\n				Authorization: "{{ authorizationHeader }}",\n				"Content-Type": "application/json",\n			},\n			method: "POST",\n			body: JSON.stringify(data),\n		}\n	);\n    const result = await response.json();\n    return result;\n}\n\nquery({ text: {{ inputs.asObj.inputs }} }).then((response) => {\n    console.log(JSON.stringify(response));\n});\n{% endif %} ',zeroShotClassification:'async function query(data) {\n    const response = await fetch(\n		"{{ fullUrl }}",\n        {\n            headers: {\n				Authorization: "{{ authorizationHeader }}",\n                "Content-Type": "application/json",\n{% if billTo %}\n                "X-HF-Bill-To": "{{ billTo }}",\n{% endif %}         },\n            method: "POST",\n            body: JSON.stringify(data),\n        }\n    );\n    const result = await response.json();\n    return result;\n}\n\nquery({\n    inputs: {{ providerInputs.asObj.inputs }},\n    parameters: { candidate_labels: ["refund", "legal", "faq"] }\n}).then((response) => {\n    console.log(JSON.stringify(response));\n});'},"huggingface.js":{basic:'import { InferenceClient } from "@huggingface/inference";\n\nconst client = new InferenceClient("{{ accessToken }}");\n\nconst output = await client.{{ methodName }}({\n{% if endpointUrl %}\n    endpointUrl: "{{ endpointUrl }}",\n{% endif %}\n	model: "{{ model.id }}",\n	inputs: {{ inputs.asObj.inputs }},\n	provider: "{{ provider }}",\n}{% if billTo %}, {\n	billTo: "{{ billTo }}",\n}{% endif %});\n\nconsole.log(output);',basicAudio:'import { InferenceClient } from "@huggingface/inference";\n\nconst client = new InferenceClient("{{ accessToken }}");\n\nconst data = fs.readFileSync({{inputs.asObj.inputs}});\n\nconst output = await client.{{ methodName }}({\n{% if endpointUrl %}\n    endpointUrl: "{{ endpointUrl }}",\n{% endif %}\n	data,\n	model: "{{ model.id }}",\n	provider: "{{ provider }}",\n}{% if billTo %}, {\n	billTo: "{{ billTo }}",\n}{% endif %});\n\nconsole.log(output);',basicImage:'import { InferenceClient } from "@huggingface/inference";\n\nconst client = new InferenceClient("{{ accessToken }}");\n\nconst data = fs.readFileSync({{inputs.asObj.inputs}});\n\nconst output = await client.{{ methodName }}({\n{% if endpointUrl %}\n    endpointUrl: "{{ endpointUrl }}",\n{% endif %}\n	data,\n	model: "{{ model.id }}",\n	provider: "{{ provider }}",\n}{% if billTo %}, {\n	billTo: "{{ billTo }}",\n}{% endif %});\n\nconsole.log(output);',conversational:'import { InferenceClient } from "@huggingface/inference";\n\nconst client = new InferenceClient("{{ accessToken }}");\n\nconst chatCompletion = await client.chatCompletion({\n{% if endpointUrl %}\n    endpointUrl: "{{ endpointUrl }}",\n{% endif %}\n    provider: "{{ provider }}",\n    model: "{{ model.id }}",\n{{ inputs.asTsString }}\n}{% if billTo %}, {\n    billTo: "{{ billTo }}",\n}{% endif %});\n\nconsole.log(chatCompletion.choices[0].message);',conversationalStream:'import { InferenceClient } from "@huggingface/inference";\n\nconst client = new InferenceClient("{{ accessToken }}");\n\nlet out = "";\n\nconst stream = client.chatCompletionStream({\n{% if endpointUrl %}\n    endpointUrl: "{{ endpointUrl }}",\n{% endif %}\n    provider: "{{ provider }}",\n    model: "{{ model.id }}",\n{{ inputs.asTsString }}\n}{% if billTo %}, {\n    billTo: "{{ billTo }}",\n}{% endif %});\n\nfor await (const chunk of stream) {\n	if (chunk.choices && chunk.choices.length > 0) {\n		const newContent = chunk.choices[0].delta.content;\n		out += newContent;\n		console.log(newContent);\n	}\n}',imageToImage:'import { InferenceClient } from "@huggingface/inference";\n\nconst client = new InferenceClient("{{ accessToken }}");\n\nconst data = fs.readFileSync("{{inputs.asObj.inputs}}");\n\nconst image = await client.imageToImage({\n{% if endpointUrl %}\n	endpointUrl: "{{ endpointUrl }}",\n{% endif %}\n	provider: "{{provider}}",\n	model: "{{model.id}}",\n	inputs: data,\n	parameters: { prompt: "{{inputs.asObj.parameters.prompt}}", },\n}{% if billTo %}, {\n	billTo: "{{ billTo }}",\n}{% endif %});\n/// Use the generated image (it\'s a Blob)\n// For example, you can save it to a file or display it in an image element\n',textToImage:'import { InferenceClient } from "@huggingface/inference";\n\nconst client = new InferenceClient("{{ accessToken }}");\n\nconst image = await client.textToImage({\n{% if endpointUrl %}\n    endpointUrl: "{{ endpointUrl }}",\n{% endif %}\n    provider: "{{ provider }}",\n    model: "{{ model.id }}",\n	inputs: {{ inputs.asObj.inputs }},\n	parameters: { num_inference_steps: 5 },\n}{% if billTo %}, {\n    billTo: "{{ billTo }}",\n}{% endif %});\n/// Use the generated image (it\'s a Blob)',textToSpeech:'import { InferenceClient } from "@huggingface/inference";\n\nconst client = new InferenceClient("{{ accessToken }}");\n\nconst audio = await client.textToSpeech({\n{% if endpointUrl %}\n    endpointUrl: "{{ endpointUrl }}",\n{% endif %}\n    provider: "{{ provider }}",\n    model: "{{ model.id }}",\n	inputs: {{ inputs.asObj.inputs }},\n}{% if billTo %}, {\n    billTo: "{{ billTo }}",\n}{% endif %});\n// Use the generated audio (it\'s a Blob)',textToVideo:'import { InferenceClient } from "@huggingface/inference";\n\nconst client = new InferenceClient("{{ accessToken }}");\n\nconst video = await client.textToVideo({\n{% if endpointUrl %}\n    endpointUrl: "{{ endpointUrl }}",\n{% endif %}\n    provider: "{{ provider }}",\n    model: "{{ model.id }}",\n	inputs: {{ inputs.asObj.inputs }},\n}{% if billTo %}, {\n    billTo: "{{ billTo }}",\n}{% endif %});\n// Use the generated video (it\'s a Blob)'},openai:{conversational:'import { OpenAI } from "openai";\n\nconst client = new OpenAI({\n	baseURL: "{{ baseUrl }}",\n	apiKey: "{{ accessToken }}",\n{% if billTo %}\n	defaultHeaders: {\n		"X-HF-Bill-To": "{{ billTo }}" \n	}\n{% endif %}\n});\n\nconst chatCompletion = await client.chat.completions.create({\n	model: "{{ providerModelId }}",\n{{ inputs.asTsString }}\n});\n\nconsole.log(chatCompletion.choices[0].message);',conversationalStream:'import { OpenAI } from "openai";\n\nconst client = new OpenAI({\n	baseURL: "{{ baseUrl }}",\n	apiKey: "{{ accessToken }}",\n{% if billTo %}\n    defaultHeaders: {\n		"X-HF-Bill-To": "{{ billTo }}" \n	}\n{% endif %}\n});\n\nconst stream = await client.chat.completions.create({\n    model: "{{ providerModelId }}",\n{{ inputs.asTsString }}\n    stream: true,\n});\n\nfor await (const chunk of stream) {\n    process.stdout.write(chunk.choices[0]?.delta?.content || "");\n}'}},python:{fal_client:{imageToImage:'{%if provider == "fal-ai" %}\nimport fal_client\nimport base64\n\ndef on_queue_update(update):\n    if isinstance(update, fal_client.InProgress):\n        for log in update.logs:\n           print(log["message"])\n\nwith open("{{inputs.asObj.inputs}}", "rb") as image_file:\n    image_base_64 = base64.b64encode(image_file.read()).decode(\'utf-8\')\n\nresult = fal_client.subscribe(\n    "fal-ai/flux-kontext/dev",\n    arguments={\n        "prompt": f"data:image/png;base64,{image_base_64}",\n        "image_url": "{{ providerInputs.asObj.inputs }}",\n    },\n    with_logs=True,\n    on_queue_update=on_queue_update,\n)\nprint(result)\n{%endif%}\n',textToImage:'{% if provider == "fal-ai" %}\nimport fal_client\n\n{% if providerInputs.asObj.loras is defined and providerInputs.asObj.loras != none %}\nresult = fal_client.subscribe(\n    "{{ providerModelId }}",\n    arguments={\n        "prompt": {{ inputs.asObj.inputs }},\n        "loras":{{ providerInputs.asObj.loras | tojson }},\n    },\n)\n{% else %}\nresult = fal_client.subscribe(\n    "{{ providerModelId }}",\n    arguments={\n        "prompt": {{ inputs.asObj.inputs }},\n    },\n)\n{% endif %} \nprint(result)\n{% endif %} '},huggingface_hub:{basic:'result = client.{{ methodName }}(\n    {{ inputs.asObj.inputs }},\n    model="{{ model.id }}",\n)',basicAudio:'output = client.{{ methodName }}({{ inputs.asObj.inputs }}, model="{{ model.id }}")',basicImage:'output = client.{{ methodName }}({{ inputs.asObj.inputs }}, model="{{ model.id }}")',conversational:'completion = client.chat.completions.create(\n    model="{{ model.id }}",\n{{ inputs.asPythonString }}\n)\n\nprint(completion.choices[0].message) ',conversationalStream:'stream = client.chat.completions.create(\n    model="{{ model.id }}",\n{{ inputs.asPythonString }}\n    stream=True,\n)\n\nfor chunk in stream:\n    print(chunk.choices[0].delta.content, end="") ',documentQuestionAnswering:'output = client.document_question_answering(\n    "{{ inputs.asObj.image }}",\n    question="{{ inputs.asObj.question }}",\n    model="{{ model.id }}",\n) ',imageToImage:'with open("{{ inputs.asObj.inputs }}", "rb") as image_file:\n   input_image = image_file.read()\n\n# output is a PIL.Image object\nimage = client.image_to_image(\n    input_image,\n    prompt="{{ inputs.asObj.parameters.prompt }}",\n    model="{{ model.id }}",\n) ',importInferenceClient:'from huggingface_hub import InferenceClient\n\nclient = InferenceClient(\n{% if endpointUrl %}\n    base_url="{{ baseUrl }}",\n{% endif %}\n    provider="{{ provider }}",\n    api_key="{{ accessToken }}",\n{% if billTo %}\n    bill_to="{{ billTo }}",\n{% endif %}\n)',questionAnswering:'answer = client.question_answering(\n    question="{{ inputs.asObj.question }}",\n    context="{{ inputs.asObj.context }}",\n    model="{{ model.id }}",\n) ',tableQuestionAnswering:'answer = client.table_question_answering(\n    query="{{ inputs.asObj.query }}",\n    table={{ inputs.asObj.table }},\n    model="{{ model.id }}",\n) ',textToImage:'# output is a PIL.Image object\nimage = client.text_to_image(\n    {{ inputs.asObj.inputs }},\n    model="{{ model.id }}",\n) ',textToSpeech:'# audio is returned as bytes\naudio = client.text_to_speech(\n    {{ inputs.asObj.inputs }},\n    model="{{ model.id }}",\n) \n',textToVideo:'video = client.text_to_video(\n    {{ inputs.asObj.inputs }},\n    model="{{ model.id }}",\n) '},openai:{conversational:'from openai import OpenAI\n\nclient = OpenAI(\n    base_url="{{ baseUrl }}",\n    api_key="{{ accessToken }}",\n{% if billTo %}\n    default_headers={\n        "X-HF-Bill-To": "{{ billTo }}"\n    }\n{% endif %}\n)\n\ncompletion = client.chat.completions.create(\n    model="{{ providerModelId }}",\n{{ inputs.asPythonString }}\n)\n\nprint(completion.choices[0].message) ',conversationalStream:'from openai import OpenAI\n\nclient = OpenAI(\n    base_url="{{ baseUrl }}",\n    api_key="{{ accessToken }}",\n{% if billTo %}\n    default_headers={\n        "X-HF-Bill-To": "{{ billTo }}"\n    }\n{% endif %}\n)\n\nstream = client.chat.completions.create(\n    model="{{ providerModelId }}",\n{{ inputs.asPythonString }}\n    stream=True,\n)\n\nfor chunk in stream:\n    print(chunk.choices[0].delta.content, end="")'},requests:{basic:'def query(payload):\n    response = requests.post(API_URL, headers=headers, json=payload)\n    return response.json()\n\noutput = query({\n    "inputs": {{ providerInputs.asObj.inputs }},\n}) ',basicAudio:'def query(filename):\n    with open(filename, "rb") as f:\n        data = f.read()\n    response = requests.post(API_URL, headers={"Content-Type": "audio/flac", **headers}, data=data)\n    return response.json()\n\noutput = query({{ providerInputs.asObj.inputs }})',basicImage:'def query(filename):\n    with open(filename, "rb") as f:\n        data = f.read()\n    response = requests.post(API_URL, headers={"Content-Type": "image/jpeg", **headers}, data=data)\n    return response.json()\n\noutput = query({{ providerInputs.asObj.inputs }})',conversational:'def query(payload):\n    response = requests.post(API_URL, headers=headers, json=payload)\n    return response.json()\n\nresponse = query({\n{{ autoInputs.asJsonString }}\n})\n\nprint(response["choices"][0]["message"])',conversationalStream:'def query(payload):\n    response = requests.post(API_URL, headers=headers, json=payload, stream=True)\n    for line in response.iter_lines():\n        if not line.startswith(b"data:"):\n            continue\n        if line.strip() == b"data: [DONE]":\n            return\n        yield json.loads(line.decode("utf-8").lstrip("data:").rstrip("/n"))\n\nchunks = query({\n{{ autoInputs.asJsonString }},\n    "stream": True,\n})\n\nfor chunk in chunks:\n    print(chunk["choices"][0]["delta"]["content"], end="")',documentQuestionAnswering:'def query(payload):\n    with open(payload["image"], "rb") as f:\n        img = f.read()\n        payload["image"] = base64.b64encode(img).decode("utf-8")\n    response = requests.post(API_URL, headers=headers, json=payload)\n    return response.json()\n\noutput = query({\n    "inputs": {\n        "image": "{{ inputs.asObj.image }}",\n        "question": "{{ inputs.asObj.question }}",\n    },\n}) ',imageToImage:'with open("{{inputs.asObj.inputs}}", "rb") as image_file:\n    image_base_64 = base64.b64encode(image_file.read()).decode(\'utf-8\')\n\ndef query(payload):\n    with open(payload["inputs"], "rb") as f:\n        img = f.read()\n        payload["inputs"] = base64.b64encode(img).decode("utf-8")\n    response = requests.post(API_URL, headers=headers, json=payload)\n    return response.content\n\nimage_bytes = query({\n{{ providerInputs.asJsonString }}\n})\n\n# You can access the image with PIL.Image for example\nimport io\nfrom PIL import Image\nimage = Image.open(io.BytesIO(image_bytes)) ',importRequests:'{% if importBase64 %}\nimport base64\n{% endif %}\n{% if importJson %}\nimport json\n{% endif %}\nimport requests\n\nAPI_URL = "{{ fullUrl }}"\nheaders = {\n    "Authorization": "{{ authorizationHeader }}",\n{% if billTo %}\n    "X-HF-Bill-To": "{{ billTo }}"\n{% endif %}\n}',tabular:'def query(payload):\n    response = requests.post(API_URL, headers=headers, json=payload)\n    return response.content\n\nresponse = query({\n    "inputs": {\n        "data": {{ providerInputs.asObj.inputs }}\n    },\n}) ',textToAudio:'{% if model.library_name == "transformers" %}\ndef query(payload):\n    response = requests.post(API_URL, headers=headers, json=payload)\n    return response.content\n\naudio_bytes = query({\n    "inputs": {{ inputs.asObj.inputs }},\n})\n# You can access the audio with IPython.display for example\nfrom IPython.display import Audio\nAudio(audio_bytes)\n{% else %}\ndef query(payload):\n    response = requests.post(API_URL, headers=headers, json=payload)\n    return response.json()\n\naudio, sampling_rate = query({\n    "inputs": {{ inputs.asObj.inputs }},\n})\n# You can access the audio with IPython.display for example\nfrom IPython.display import Audio\nAudio(audio, rate=sampling_rate)\n{% endif %} ',textToImage:'{% if provider == "hf-inference" %}\ndef query(payload):\n    response = requests.post(API_URL, headers=headers, json=payload)\n    return response.content\n\nimage_bytes = query({\n    "inputs": {{ providerInputs.asObj.inputs }},\n})\n\n# You can access the image with PIL.Image for example\nimport io\nfrom PIL import Image\nimage = Image.open(io.BytesIO(image_bytes))\n{% endif %}',textToSpeech:'{% if model.library_name == "transformers" %}\ndef query(payload):\n    response = requests.post(API_URL, headers=headers, json=payload)\n    return response.content\n\naudio_bytes = query({\n    "text": {{ inputs.asObj.inputs }},\n})\n# You can access the audio with IPython.display for example\nfrom IPython.display import Audio\nAudio(audio_bytes)\n{% else %}\ndef query(payload):\n    response = requests.post(API_URL, headers=headers, json=payload)\n    return response.json()\n\naudio, sampling_rate = query({\n    "text": {{ inputs.asObj.inputs }},\n})\n# You can access the audio with IPython.display for example\nfrom IPython.display import Audio\nAudio(audio, rate=sampling_rate)\n{% endif %} ',zeroShotClassification:'def query(payload):\n    response = requests.post(API_URL, headers=headers, json=payload)\n    return response.json()\n\noutput = query({\n    "inputs": {{ providerInputs.asObj.inputs }},\n    "parameters": {"candidate_labels": ["refund", "legal", "faq"]},\n}) ',zeroShotImageClassification:'def query(data):\n    with open(data["image_path"], "rb") as f:\n        img = f.read()\n    payload={\n        "parameters": data["parameters"],\n        "inputs": base64.b64encode(img).decode("utf-8")\n    }\n    response = requests.post(API_URL, headers=headers, json=payload)\n    return response.json()\n\noutput = query({\n    "image_path": {{ providerInputs.asObj.inputs }},\n    "parameters": {"candidate_labels": ["cat", "dog", "llama"]},\n}) '}},sh:{curl:{basic:"curl {{ fullUrl }} \\\n    -X POST \\\n    -H 'Authorization: {{ authorizationHeader }}' \\\n    -H 'Content-Type: application/json' \\\n{% if billTo %}\n    -H 'X-HF-Bill-To: {{ billTo }}' \\\n{% endif %}\n    -d '{\n{{ providerInputs.asCurlString }}\n    }'",basicAudio:"curl {{ fullUrl }} \\\n    -X POST \\\n    -H 'Authorization: {{ authorizationHeader }}' \\\n    -H 'Content-Type: audio/flac' \\\n{% if billTo %}\n    -H 'X-HF-Bill-To: {{ billTo }}' \\\n{% endif %}\n    --data-binary @{{ providerInputs.asObj.inputs }}",basicImage:"curl {{ fullUrl }} \\\n    -X POST \\\n    -H 'Authorization: {{ authorizationHeader }}' \\\n    -H 'Content-Type: image/jpeg' \\\n{% if billTo %}\n    -H 'X-HF-Bill-To: {{ billTo }}' \\\n{% endif %}\n    --data-binary @{{ providerInputs.asObj.inputs }}",conversational:"curl {{ fullUrl }} \\\n    -H 'Authorization: {{ authorizationHeader }}' \\\n    -H 'Content-Type: application/json' \\\n{% if billTo %}\n    -H 'X-HF-Bill-To: {{ billTo }}' \\\n{% endif %}\n    -d '{\n{{ autoInputs.asCurlString }},\n        \"stream\": false\n    }'",conversationalStream:"curl {{ fullUrl }} \\\n    -H 'Authorization: {{ authorizationHeader }}' \\\n    -H 'Content-Type: application/json' \\\n{% if billTo %}\n    -H 'X-HF-Bill-To: {{ billTo }}' \\\n{% endif %}\n    -d '{\n{{ autoInputs.asCurlString }},\n        \"stream\": true\n    }'",zeroShotClassification:'curl {{ fullUrl }} \\\n    -X POST \\\n    -d \'{"inputs": {{ providerInputs.asObj.inputs }}, "parameters": {"candidate_labels": ["refund", "legal", "faq"]}}\' \\\n    -H \'Content-Type: application/json\' \\\n    -H \'Authorization: {{ authorizationHeader }}\'\n{% if billTo %} \\\n    -H \'X-HF-Bill-To: {{ billTo }}\'\n{% endif %}'}}},rj={js:["fetch","huggingface.js","openai"],python:["huggingface_hub","fal_client","requests","openai"],sh:["curl"]},rD={js:["huggingface.js"],python:["huggingface_hub"]},rz=(e,t,n)=>{let r=r$[e]?.[t]?.[n];if(!r)throw Error(`Template not found: ${e}/${t}/${n}`);return e=>new n5(r).render({...e})},rF=rz("python","huggingface_hub","importInferenceClient"),rB=rz("python","requests","importRequests"),rq={"audio-classification":"audio_classification","audio-to-audio":"audio_to_audio","automatic-speech-recognition":"automatic_speech_recognition","document-question-answering":"document_question_answering","feature-extraction":"feature_extraction","fill-mask":"fill_mask","image-classification":"image_classification","image-segmentation":"image_segmentation","image-to-image":"image_to_image","image-to-text":"image_to_text","object-detection":"object_detection","question-answering":"question_answering","sentence-similarity":"sentence_similarity",summarization:"summarization","table-question-answering":"table_question_answering","tabular-classification":"tabular_classification","tabular-regression":"tabular_regression","text-classification":"text_classification","text-generation":"text_generation","text-to-image":"text_to_image","text-to-speech":"text_to_speech","text-to-video":"text_to_video","token-classification":"token_classification",translation:"translation","visual-question-answering":"visual_question_answering","zero-shot-classification":"zero_shot_classification","zero-shot-image-classification":"zero_shot_image_classification"},rV={"automatic-speech-recognition":"automaticSpeechRecognition","feature-extraction":"featureExtraction","fill-mask":"fillMask","image-classification":"imageClassification","question-answering":"questionAnswering","sentence-similarity":"sentenceSimilarity",summarization:"summarization","table-question-answering":"tableQuestionAnswering","text-classification":"textClassification","text-generation":"textGeneration","token-classification":"tokenClassification","text-to-speech":"textToSpeech",translation:"translation"},rH=(e,t)=>(n,r,a,i)=>{var o,s;let l,u=a?.providerId??n.id,c=n.pipeline_tag;n.pipeline_tag&&["text-generation","image-text-to-text"].includes(n.pipeline_tag)&&n.tags.includes("conversational")&&(e=i?.streaming?"conversationalStream":"conversational",t=rQ,c="conversational");try{l=eX(r,c)}catch(e){return eC.error(`Failed to get provider helper for ${r} (${c})`,e),[]}let d=i?.directRequest?"not_hf_token_placeholder":"hf_token_placeholder",p=i?.accessToken??d,f=i?.inputs?{inputs:i.inputs}:t?t(n,i):{inputs:rk(n)},m=eZ(u,l,{accessToken:p,provider:r,endpointUrl:i?.endpointUrl??("auto"===r?k:void 0),...f},a,{task:c,billTo:i?.billTo}),h=f,g=m.info.body;if("string"==typeof g)try{h=JSON.parse(g)}catch(e){eC.error("Failed to parse body as JSON",e)}let y=i?.endpointUrl||i?.directRequest?h:"auto"!==r?{...f,model:`${n.id}:${r}`}:{...f,model:`${n.id}`},b={accessToken:p,authorizationHeader:m.info.headers?.Authorization,baseUrl:"conversational"!==c||i?.endpointUrl||i?.directRequest?(o=m.url,s="/chat/completions",o.endsWith(s)?o.slice(0,-s.length):o):k,fullUrl:"conversational"!==c||i?.endpointUrl||i?.directRequest?m.url:k+"/chat/completions",inputs:{asObj:f,asCurlString:rW(f,"curl"),asJsonString:rW(f,"json"),asPythonString:rW(f,"python"),asTsString:rW(f,"ts")},providerInputs:{asObj:h,asCurlString:rW(h,"curl"),asJsonString:rW(h,"json"),asPythonString:rW(h,"python"),asTsString:rW(h,"ts")},autoInputs:{asObj:y,asCurlString:rW(y,"curl"),asJsonString:rW(y,"json"),asPythonString:rW(y,"python"),asTsString:rW(y,"ts")},model:n,provider:r,providerModelId:"conversational"!==c||i?.endpointUrl||i?.directRequest?u??n.id:"auto"!==r?`${n.id}:${r}`:n.id,billTo:i?.billTo,endpointUrl:i?.endpointUrl},v="auto"===r&&"conversational"!==c?rD:rj;return rO.map(t=>(v[t]??[]).map(a=>{let o;if(o=e,r$[t]?.[a]?.[o]===void 0)return;let s=rz(t,a,e);if("huggingface_hub"===a&&e.includes("basic")){if(!(n.pipeline_tag&&n.pipeline_tag in rq))return;b.methodName=rq[n.pipeline_tag]}if("huggingface.js"===a&&e.includes("basic")){if(!(n.pipeline_tag&&n.pipeline_tag in rV))return;b.methodName=rV[n.pipeline_tag]}let l=s(b).trim();if(l){if("huggingface_hub"===a){let e=rF({...b});l=`${e}

${l}`}else if("requests"===a){let e=rB({...b,importBase64:l.includes("base64"),importJson:l.includes("json.")});l=`${e}

${l}`}return l.includes(d)&&(l=function(e,t,n,r,a,i){let o=!i&&("hf-inference"==a||!e&&(n.includes("InferenceClient")||n.includes("https://router.huggingface.co")))?"HF_TOKEN":i?"API_TOKEN":a.toUpperCase().replace("-","_")+"_API_KEY";return"sh"===r?n=n.replace(`'Authorization: Bearer ${t}'`,`"Authorization: Bearer $${o}"`):"python"===r?n=(n=(n=(n=(n="import os\n"+n).replace(`"${t}"`,`os.environ["${o}"]`)).replace(`"Bearer ${t}"`,`f"Bearer {os.environ['${o}']}"`)).replace(`"Key ${t}"`,`f"Key {os.environ['${o}']}"`)).replace(`"X-Key ${t}"`,`f"X-Key {os.environ['${o}']}"`):"js"===r&&(n=(n=(n=(n=n.replace(`"${t}"`,`process.env.${o}`)).replace(`Authorization: "Bearer ${t}",`,`Authorization: \`Bearer $\{process.env.${o}}\`,`)).replace(`Authorization: "Key ${t}",`,`Authorization: \`Key $\{process.env.${o}}\`,`)).replace(`Authorization: "X-Key ${t}",`,`Authorization: \`X-Key $\{process.env.${o}}\`,`)),n}(i?.directRequest,d,l,t,r,i?.endpointUrl)),{language:t,client:a,content:l}}}).filter(e=>void 0!==e)).flat()},rQ=(e,t)=>({messages:t?.messages??rk(e),...t?.temperature?{temperature:t?.temperature}:void 0,...t?.max_tokens?{max_tokens:t?.max_tokens}:void 0,...t?.top_p?{top_p:t?.top_p}:void 0});function rW(e,t){switch(t){case"curl":return rG(rW(e,"json"));case"json":return JSON.stringify(e,null,4).split("\n").slice(1,-1).join("\n");case"python":return rG(Object.entries(e).map(([e,t])=>{let n=JSON.stringify(t,null,4).replace(/"/g,'"');return`${e}=${n},`}).join("\n"));case"ts":return(function e(t,n){if(n=n??0,"object"!=typeof t||null===t)return JSON.stringify(t);if(Array.isArray(t)){let r=t.map(t=>{let r=e(t,n+1);return`${" ".repeat(4*(n+1))}${r},`}).join("\n");return`[
${r}
${" ".repeat(4*n)}]`}let r=Object.entries(t).map(([t,r])=>{let a=e(r,n+1),i=/^[a-zA-Z_$][a-zA-Z0-9_$]*$/.test(t)?t:`"${t}"`;return`${" ".repeat(4*(n+1))}${i}: ${a},`}).join("\n");return`{
${r}
${" ".repeat(4*n)}}`})(e).split("\n").slice(1,-1).join("\n");default:throw Error(`Unsupported format: ${t}`)}}function rG(e){return e.split("\n").map(e=>" ".repeat(4)+e).join("\n")}rH("basicAudio"),rH("basicAudio"),rH("basicAudio"),rH("documentQuestionAnswering",e=>JSON.parse(rk(e))),rH("basic"),rH("basic"),rH("basicImage"),rH("basicImage"),rH("conversational"),rH("imageToImage",e=>{let t=JSON.parse(rk(e));return{inputs:t.image,parameters:{prompt:t.prompt}}}),rH("basicImage"),rH("basicImage"),rH("questionAnswering",e=>{let t=JSON.parse(rk(e));return{question:t.question,context:t.context}}),rH("basic"),rH("basic"),rH("tabular"),rH("tabular"),rH("tableQuestionAnswering",e=>{let t=JSON.parse(rk(e));return{query:t.query,table:JSON.stringify(t.table)}}),rH("basic"),rH("basic"),rH("textToAudio"),rH("textToImage"),rH("textToSpeech"),rH("textToVideo"),rH("basic"),rH("basic"),rH("zeroShotClassification"),rH("zeroShotImageClassification");const rK=async e=>{let t=new ne(localStorage.getItem("nai-token"));return(await t.chatCompletion({model:"meta-llama/Meta-Llama-3.1-8B-Instruct",messages:[{role:"system",content:""},{role:"user",content:e}],max_tokens:128,temperature:.7})).choices[0].message.content},rX="\n\n- \n- \n- \n\n- \n- \n- \n\n- \n- \n- \n\n\n\n";(0,h.createRoot)(document.getElementById("app")).render((0,m.jsx)(()=>{let[e,t]=(0,g.useState)(!1),[n,r,a,i,o]=[(0,g.useRef)(),(0,g.useRef)(),(0,g.useRef)(),(0,g.useRef)(),(0,g.useRef)()];return(0,g.useEffect)(()=>{let e=localStorage.getItem("nai-template");e?n.current?.(e):n.current(rX)},[]),(0,m.jsx)(m.Fragment,{children:(0,m.jsxs)("div",{className:"container",children:[(0,m.jsx)("hr",{}),(0,m.jsx)("pre",{children:`-- 
1. Hugging Face API 
2. localStorage.setItem("nai-token", \u{3053}\u{3053}\u{306B}\u{30C8}\u{30FC}\u{30AF}\u{30F3}) \u{3092}\u{5B9F}\u{884C}\u{3059}\u{308B}
3. 

-- 
1. 
2. 
3. 

-- ${localStorage.getItem("nai-token")?"":""} --`}),(0,m.jsx)(y,{ref:n,id:"a",name:"",rows:10}),(0,m.jsx)(y,{ref:r,id:"b",name:""}),(0,m.jsx)(y,{ref:a,id:"c",name:""}),(0,m.jsx)(y,{ref:i,id:"d",name:""}),(0,m.jsx)("button",{type:"button",className:"btn btn-secondary",onClick:()=>{let[e,s,l,u]=[n.current?.(),r.current?.(),a.current?.(),i.current?.()],c=e||rX,d=o.current;if(""===s||""===l)return void alert("\n");let p=["","","",s,"",l,...u?["",u]:[],"",new Date().toLocaleDateString(),"","--  --",c].join("\n");localStorage.setItem("nai-template",c),t(!0),rK(p).then(e=>{console.log({prompt:p,res:e}),d(e)}).catch(e=>{alert(""),d(e.toString()),console.log({prompt:p,error:e})}).finally(()=>{t(!1)})},disabled:e,style:{marginRight:8},children:e?"...":""}),(0,m.jsx)("button",{type:"button",className:"btn btn-secondary",onClick:()=>localStorage.setItem("nai-template",n.current?.()),children:""}),(0,m.jsx)("hr",{}),(0,m.jsx)(y,{ref:o,id:"e",name:"",rows:10})]})})},{}));